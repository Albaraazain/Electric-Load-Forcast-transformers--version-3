{
    "sourceFile": "config.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 0,
            "patches": [
                {
                    "date": 1733004949776,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                }
            ],
            "date": 1733004949776,
            "name": "Commit-0",
            "content": "# # config.py\r\n# from dataclasses import dataclass\r\n# from datetime import date\r\n# from pathlib import Path\r\n# from typing import Union\r\n# from sklearn.preprocessing import StandardScaler\r\n# from data_loading.base.base_dataset import DatasetConfig\r\n# from models.config.model_config import ModelConfig\r\n# from training.config import TransformerTrainingConfig\r\n# from pipeline.config.pipeline_config import PipelineConfig\r\n# from models.registry.model_types import ModelType\r\n# def create_transformer_config(data_path: Union[str, Path]) -> PipelineConfig:\r\n#     \"\"\"Create configuration for transformer model training.\"\"\"\r\n    \r\n#     dataset_config = DatasetConfig(\r\n#         time_variable='utc_timestamp',\r\n#         target_variable='DE_KN_residential1_grid_import',\r\n#         time_series_window_in_hours=24,\r\n#         forecasting_horizon_in_hours=12,\r\n#         is_single_time_point_prediction=False,\r\n#         include_time_information=True,\r\n#         time_series_scaler=StandardScaler(),\r\n#         is_training_set=True,\r\n#         labels_count=12,\r\n#         one_hot_time_variables=False\r\n#     )\r\n\r\n#     model_config = ModelConfig(\r\n#         model_type=ModelType.VANILLA_TRANSFORMER,\r\n#         input_features=1,\r\n#         d_model=64,\r\n#         n_heads=4,\r\n#         n_encoder_layers=3,\r\n#         n_decoder_layers=3,\r\n#         d_ff=256,\r\n#         dropout=0.1\r\n#     )\r\n\r\n#     training_config = TransformerTrainingConfig(\r\n#         learning_rate=0.001,\r\n#         max_epochs=100,\r\n#         use_early_stopping=True,\r\n#         early_stopping_patience=10,\r\n#         batch_size=32,\r\n#         device='cuda',\r\n#         transformer_labels_count=12,\r\n#         forecasting_horizon=12,\r\n#         transformer_use_teacher_forcing=True\r\n#     )\r\n\r\n#     return PipelineConfig(\r\n#         dataset_config=dataset_config,\r\n#         model_config=model_config,\r\n#         training_config=training_config,\r\n#         data_path=Path(data_path),\r\n#         model_save_path=Path('models/transformer'),\r\n#         experiment_save_path=Path('experiments'),\r\n#         train_dates=(date(2015, 10, 29), date(2016, 10, 28)),\r\n#         val_dates=(date(2016, 10, 29), date(2017, 1, 28)),\r\n#         test_dates=(date(2017, 1, 29), date(2017, 3, 12))\r\n#     )"
        }
    ]
}