{
    "sourceFile": "data_loading/datasets/transformer_dataset.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 7,
            "patches": [
                {
                    "date": 1733005186538,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1733005260749,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -35,14 +35,20 @@\n \r\n         input_seq = self.rows[\r\n                     index:index + self.config.time_series_window_in_hours\r\n                     ]\r\n-\r\n+        \r\n         target_seq = self.rows[\r\n                     index + self.config.time_series_window_in_hours:\r\n                     index + self.config.time_series_window_in_hours + self.config.forecasting_horizon_in_hours\r\n                     ]\r\n \r\n+        print(f\"\\nDebug - Dataset __getitem__:\")\r\n+        print(f\"Input sequence shape: {input_seq.shape}\")\r\n+        print(f\"Target sequence shape: {target_seq.shape}\")\r\n+        print(f\"Input sequence value range: [{input_seq.min():.2f}, {input_seq.max():.2f}]\")\r\n+        print(f\"Target sequence value range: [{target_seq.min():.2f}, {target_seq.max():.2f}]\")\r\n+\r\n         return input_seq, target_seq\r\n \r\n     def _prepare_time_series_data(self) -> None:\r\n         \"\"\"Prepare time series data for model input\"\"\"\r\n"
                },
                {
                    "date": 1733005889313,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -86,12 +86,18 @@\n                     scaler.fit_transform(load_data)\r\n                     if self.config.is_training_set\r\n                     else scaler.transform(load_data)\r\n                 )\r\n-                print(f\"Debug - After scaling shape: {scaled_data.shape}\")\r\n+                # Add normalization\r\n+                scaled_data = (scaled_data - np.mean(scaled_data)) / np.std(scaled_data)\r\n+                print(f\"Debug - After normalization range: [{scaled_data.min():.2f}, {scaled_data.max():.2f}]\")\r\n             else:\r\n                 scaled_data = load_data\r\n \r\n+            # Add validation check\r\n+            if np.isnan(scaled_data).any() or np.isinf(scaled_data).any():\r\n+                raise ValueError(\"Invalid values detected after scaling\")\r\n+\r\n             # Extract timestamps and prepare features\r\n             time_stamps = transformer.extract_timestamps(\r\n                 self._df,\r\n                 self.config.time_variable\r\n@@ -120,8 +126,14 @@\n \r\n             self.rows = torch.tensor(np.array(sequence_rows, dtype=np.float32))\r\n             print(f\"Debug - Final rows tensor shape: {self.rows.shape}\")\r\n \r\n+            # Add final validation\r\n+            if torch.isnan(self.rows).any() or torch.isinf(self.rows).any():\r\n+                raise ValueError(\"Invalid values detected in final tensor\")\r\n+            \r\n+            print(f\"Debug - Final value range: [{self.rows.min():.2f}, {self.rows.max():.2f}]\")\r\n+\r\n             # Set input and target tensors\r\n             self.prepared_time_series_input = self.rows[\r\n                 :len(self.rows) - self.config.forecasting_horizon_in_hours\r\n             ]\r\n"
                },
                {
                    "date": 1733007333571,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,157 @@\n+# data_loading/datasets/transformer_dataset.py\r\n+import numpy as np\r\n+import pandas as pd\r\n+import torch\r\n+from typing import Tuple, List, Any\r\n+\r\n+from data_loading.base.base_dataset import BaseDataset, DatasetConfig\r\n+from data_loading.features.time_features import CyclicalTimeFeature, WorkdayFeature\r\n+from data_loading.preprocessing.data_scaler import DataScaler\r\n+from data_loading.preprocessing.data_transformer import DataTransformer\r\n+\r\n+class TransformerDataset(BaseDataset):\r\n+    \"\"\"Dataset implementation for transformer models\"\"\"\r\n+\r\n+    def __init__(self, df: pd.DataFrame, config: DatasetConfig):\r\n+        super().__init__(df, config)\r\n+        self.rows: torch.Tensor = torch.empty(0)\r\n+        self._prepare_time_series_data()\r\n+        self._debug_counter = 0  # Add debug counter\r\n+        self._debug_frequency = 1000  # Print debug info every 1000 samples\r\n+\r\n+    def __len__(self) -> int:\r\n+        if self.rows is None:\r\n+            return 0\r\n+        return max(0, len(self.rows) - self.config.time_series_window_in_hours - self.config.forecasting_horizon_in_hours)\r\n+\r\n+    def __getitem__(self, index: int) -> Tuple[torch.Tensor, torch.Tensor]:\r\n+        \"\"\"Get a data item by index\r\n+\r\n+        Returns:\r\n+            Tuple containing:\r\n+            - Input sequence [time_series_window_in_hours, features]\r\n+            - Target sequence [forecasting_horizon_in_hours, features]\r\n+        \"\"\"\r\n+        if self.rows is None:\r\n+            raise ValueError(\"Dataset not properly initialized\")\r\n+\r\n+        input_seq = self.rows[\r\n+                    index:index + self.config.time_series_window_in_hours\r\n+                    ]\r\n+        \r\n+        target_seq = self.rows[\r\n+                    index + self.config.time_series_window_in_hours:\r\n+                    index + self.config.time_series_window_in_hours + self.config.forecasting_horizon_in_hours\r\n+                    ]\r\n+\r\n+        # Print debug info periodically\r\n+        if self._debug_counter % self._debug_frequency == 0:\r\n+            print(f\"\\nDebug - Dataset __getitem__ (sample {self._debug_counter}):\")\r\n+            print(f\"Input sequence shape: {input_seq.shape}\")\r\n+            print(f\"Target sequence shape: {target_seq.shape}\")\r\n+            print(f\"Input sequence value range: [{input_seq.min():.2f}, {input_seq.max():.2f}]\")\r\n+            print(f\"Target sequence value range: [{target_seq.min():.2f}, {target_seq.max():.2f}]\")\r\n+        \r\n+        self._debug_counter += 1\r\n+        return input_seq, target_seq\r\n+\r\n+    def _prepare_time_series_data(self) -> None:\r\n+        \"\"\"Prepare time series data for model input\"\"\"\r\n+        print(f\"\\nDebug - TransformerDataset preparation:\")\r\n+        print(f\"Initial DataFrame shape: {self._df.shape}\")\r\n+        \r\n+        if len(self._df) == 0:\r\n+            raise ValueError(\"Empty dataframe provided\")\r\n+\r\n+        # Initialize processors\r\n+        scaler = DataScaler(self.config.time_series_scaler)\r\n+        transformer = DataTransformer()\r\n+\r\n+        # Make sure we have enough data points\r\n+        min_required = (self.config.time_series_window_in_hours + \r\n+                    self.config.forecasting_horizon_in_hours) * 4  # 4 points per hour\r\n+        print(f\"Debug - Required data points: {min_required}\")\r\n+        print(f\"Debug - Available data points: {len(self._df)}\")\r\n+        \r\n+        if len(self._df) < min_required:\r\n+            raise ValueError(f\"Not enough data points. Need at least {min_required}, got {len(self._df)}\")\r\n+\r\n+        try:\r\n+            # Extract raw data\r\n+            raw_data = np.array(self._df[self.config.target_variable])\r\n+            print(f\"Debug - Raw data shape: {raw_data.shape}\")\r\n+            \r\n+            # Average data\r\n+            load_data = transformer.average_by_window(raw_data, window_size=4)\r\n+            print(f\"Debug - After averaging shape: {load_data.shape}\")\r\n+            \r\n+            # Scale data\r\n+            if self.config.time_series_scaler:\r\n+                scaled_data = (\r\n+                    scaler.fit_transform(load_data)\r\n+                    if self.config.is_training_set\r\n+                    else scaler.transform(load_data)\r\n+                )\r\n+                # Add normalization\r\n+                scaled_data = (scaled_data - np.mean(scaled_data)) / np.std(scaled_data)\r\n+                print(f\"Debug - After normalization range: [{scaled_data.min():.2f}, {scaled_data.max():.2f}]\")\r\n+            else:\r\n+                scaled_data = load_data\r\n+\r\n+            # Add validation check\r\n+            if np.isnan(scaled_data).any() or np.isinf(scaled_data).any():\r\n+                raise ValueError(\"Invalid values detected after scaling\")\r\n+\r\n+            # Extract timestamps and prepare features\r\n+            time_stamps = transformer.extract_timestamps(\r\n+                self._df,\r\n+                self.config.time_variable\r\n+            )\r\n+            print(f\"Debug - Time stamps shape: {time_stamps.shape}\")\r\n+\r\n+            # Initialize feature generators\r\n+            hour_feature = CyclicalTimeFeature(24)\r\n+            week_feature = CyclicalTimeFeature(53)\r\n+            workday_feature = WorkdayFeature()\r\n+\r\n+            sequence_rows = []\r\n+\r\n+            # Generate features for each timestamp\r\n+            print(f\"Debug - Generating features for {len(scaled_data)} time points\")\r\n+            for idx, (load_value, time_stamp) in enumerate(zip(scaled_data, time_stamps)):\r\n+                features = [load_value]\r\n+\r\n+                if self.config.include_time_information:\r\n+                    timestamp_pd = pd.Timestamp(time_stamp)\r\n+                    features.extend(hour_feature.generate(pd.Series([timestamp_pd.hour])))\r\n+                    features.extend(week_feature.generate(pd.Series([timestamp_pd.isocalendar()[1]])))\r\n+                    features.extend(workday_feature.generate(timestamp_pd))\r\n+\r\n+                sequence_rows.append(features)\r\n+\r\n+            self.rows = torch.tensor(np.array(sequence_rows, dtype=np.float32))\r\n+            print(f\"Debug - Final rows tensor shape: {self.rows.shape}\")\r\n+\r\n+            # Add final validation\r\n+            if torch.isnan(self.rows).any() or torch.isinf(self.rows).any():\r\n+                raise ValueError(\"Invalid values detected in final tensor\")\r\n+            \r\n+            print(f\"Debug - Final value range: [{self.rows.min():.2f}, {self.rows.max():.2f}]\")\r\n+\r\n+            # Set input and target tensors\r\n+            self.prepared_time_series_input = self.rows[\r\n+                :len(self.rows) - self.config.forecasting_horizon_in_hours\r\n+            ]\r\n+            self.prepared_time_series_target = self.rows[\r\n+                self.config.time_series_window_in_hours:\r\n+            ]\r\n+\r\n+            print(f\"Debug - Final shapes:\")\r\n+            print(f\"  Input tensor: {self.prepared_time_series_input.shape if self.prepared_time_series_input is not None else None}\")\r\n+            print(f\"  Target tensor: {self.prepared_time_series_target.shape if self.prepared_time_series_target is not None else None}\")\r\n+\r\n+        except Exception as e:\r\n+            print(f\"\\nError preparing time series data: {str(e)}\")\r\n+            print(f\"DataFrame info:\")\r\n+            print(self._df.info())\r\n+            raise\n\\ No newline at end of file\n"
                },
                {
                    "date": 1733007398310,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -16,9 +16,9 @@\n         super().__init__(df, config)\r\n         self.rows: torch.Tensor = torch.empty(0)\r\n         self._prepare_time_series_data()\r\n         self._debug_counter = 0  # Add debug counter\r\n-        self._debug_frequency = 1000  # Print debug info every 1000 samples\r\n+        self._debug_frequency = 10000  # Print debug info every 1000 samples\r\n \r\n     def __len__(self) -> int:\r\n         if self.rows is None:\r\n             return 0\r\n@@ -153,157 +153,5 @@\n         except Exception as e:\r\n             print(f\"\\nError preparing time series data: {str(e)}\")\r\n             print(f\"DataFrame info:\")\r\n             print(self._df.info())\r\n-            raise\n-# data_loading/datasets/transformer_dataset.py\r\n-import numpy as np\r\n-import pandas as pd\r\n-import torch\r\n-from typing import Tuple, List, Any\r\n-\r\n-from data_loading.base.base_dataset import BaseDataset, DatasetConfig\r\n-from data_loading.features.time_features import CyclicalTimeFeature, WorkdayFeature\r\n-from data_loading.preprocessing.data_scaler import DataScaler\r\n-from data_loading.preprocessing.data_transformer import DataTransformer\r\n-\r\n-class TransformerDataset(BaseDataset):\r\n-    \"\"\"Dataset implementation for transformer models\"\"\"\r\n-\r\n-    def __init__(self, df: pd.DataFrame, config: DatasetConfig):\r\n-        super().__init__(df, config)\r\n-        self.rows: torch.Tensor = torch.empty(0)\r\n-        self._prepare_time_series_data()\r\n-\r\n-    def __len__(self) -> int:\r\n-        if self.rows is None:\r\n-            return 0\r\n-        return max(0, len(self.rows) - self.config.time_series_window_in_hours - self.config.forecasting_horizon_in_hours)\r\n-\r\n-    def __getitem__(self, index: int) -> Tuple[torch.Tensor, torch.Tensor]:\r\n-        \"\"\"Get a data item by index\r\n-\r\n-        Returns:\r\n-            Tuple containing:\r\n-            - Input sequence [time_series_window_in_hours, features]\r\n-            - Target sequence [forecasting_horizon_in_hours, features]\r\n-        \"\"\"\r\n-        if self.rows is None:\r\n-            raise ValueError(\"Dataset not properly initialized\")\r\n-\r\n-        input_seq = self.rows[\r\n-                    index:index + self.config.time_series_window_in_hours\r\n-                    ]\r\n-        \r\n-        target_seq = self.rows[\r\n-                    index + self.config.time_series_window_in_hours:\r\n-                    index + self.config.time_series_window_in_hours + self.config.forecasting_horizon_in_hours\r\n-                    ]\r\n-\r\n-        print(f\"\\nDebug - Dataset __getitem__:\")\r\n-        print(f\"Input sequence shape: {input_seq.shape}\")\r\n-        print(f\"Target sequence shape: {target_seq.shape}\")\r\n-        print(f\"Input sequence value range: [{input_seq.min():.2f}, {input_seq.max():.2f}]\")\r\n-        print(f\"Target sequence value range: [{target_seq.min():.2f}, {target_seq.max():.2f}]\")\r\n-\r\n-        return input_seq, target_seq\r\n-\r\n-    def _prepare_time_series_data(self) -> None:\r\n-        \"\"\"Prepare time series data for model input\"\"\"\r\n-        print(f\"\\nDebug - TransformerDataset preparation:\")\r\n-        print(f\"Initial DataFrame shape: {self._df.shape}\")\r\n-        \r\n-        if len(self._df) == 0:\r\n-            raise ValueError(\"Empty dataframe provided\")\r\n-\r\n-        # Initialize processors\r\n-        scaler = DataScaler(self.config.time_series_scaler)\r\n-        transformer = DataTransformer()\r\n-\r\n-        # Make sure we have enough data points\r\n-        min_required = (self.config.time_series_window_in_hours + \r\n-                    self.config.forecasting_horizon_in_hours) * 4  # 4 points per hour\r\n-        print(f\"Debug - Required data points: {min_required}\")\r\n-        print(f\"Debug - Available data points: {len(self._df)}\")\r\n-        \r\n-        if len(self._df) < min_required:\r\n-            raise ValueError(f\"Not enough data points. Need at least {min_required}, got {len(self._df)}\")\r\n-\r\n-        try:\r\n-            # Extract raw data\r\n-            raw_data = np.array(self._df[self.config.target_variable])\r\n-            print(f\"Debug - Raw data shape: {raw_data.shape}\")\r\n-            \r\n-            # Average data\r\n-            load_data = transformer.average_by_window(raw_data, window_size=4)\r\n-            print(f\"Debug - After averaging shape: {load_data.shape}\")\r\n-            \r\n-            # Scale data\r\n-            if self.config.time_series_scaler:\r\n-                scaled_data = (\r\n-                    scaler.fit_transform(load_data)\r\n-                    if self.config.is_training_set\r\n-                    else scaler.transform(load_data)\r\n-                )\r\n-                # Add normalization\r\n-                scaled_data = (scaled_data - np.mean(scaled_data)) / np.std(scaled_data)\r\n-                print(f\"Debug - After normalization range: [{scaled_data.min():.2f}, {scaled_data.max():.2f}]\")\r\n-            else:\r\n-                scaled_data = load_data\r\n-\r\n-            # Add validation check\r\n-            if np.isnan(scaled_data).any() or np.isinf(scaled_data).any():\r\n-                raise ValueError(\"Invalid values detected after scaling\")\r\n-\r\n-            # Extract timestamps and prepare features\r\n-            time_stamps = transformer.extract_timestamps(\r\n-                self._df,\r\n-                self.config.time_variable\r\n-            )\r\n-            print(f\"Debug - Time stamps shape: {time_stamps.shape}\")\r\n-\r\n-            # Initialize feature generators\r\n-            hour_feature = CyclicalTimeFeature(24)\r\n-            week_feature = CyclicalTimeFeature(53)\r\n-            workday_feature = WorkdayFeature()\r\n-\r\n-            sequence_rows = []\r\n-\r\n-            # Generate features for each timestamp\r\n-            print(f\"Debug - Generating features for {len(scaled_data)} time points\")\r\n-            for idx, (load_value, time_stamp) in enumerate(zip(scaled_data, time_stamps)):\r\n-                features = [load_value]\r\n-\r\n-                if self.config.include_time_information:\r\n-                    timestamp_pd = pd.Timestamp(time_stamp)\r\n-                    features.extend(hour_feature.generate(pd.Series([timestamp_pd.hour])))\r\n-                    features.extend(week_feature.generate(pd.Series([timestamp_pd.isocalendar()[1]])))\r\n-                    features.extend(workday_feature.generate(timestamp_pd))\r\n-\r\n-                sequence_rows.append(features)\r\n-\r\n-            self.rows = torch.tensor(np.array(sequence_rows, dtype=np.float32))\r\n-            print(f\"Debug - Final rows tensor shape: {self.rows.shape}\")\r\n-\r\n-            # Add final validation\r\n-            if torch.isnan(self.rows).any() or torch.isinf(self.rows).any():\r\n-                raise ValueError(\"Invalid values detected in final tensor\")\r\n-            \r\n-            print(f\"Debug - Final value range: [{self.rows.min():.2f}, {self.rows.max():.2f}]\")\r\n-\r\n-            # Set input and target tensors\r\n-            self.prepared_time_series_input = self.rows[\r\n-                :len(self.rows) - self.config.forecasting_horizon_in_hours\r\n-            ]\r\n-            self.prepared_time_series_target = self.rows[\r\n-                self.config.time_series_window_in_hours:\r\n-            ]\r\n-\r\n-            print(f\"Debug - Final shapes:\")\r\n-            print(f\"  Input tensor: {self.prepared_time_series_input.shape if self.prepared_time_series_input is not None else None}\")\r\n-            print(f\"  Target tensor: {self.prepared_time_series_target.shape if self.prepared_time_series_target is not None else None}\")\r\n-\r\n-        except Exception as e:\r\n-            print(f\"\\nError preparing time series data: {str(e)}\")\r\n-            print(f\"DataFrame info:\")\r\n-            print(self._df.info())\r\n             raise\n\\ No newline at end of file\n"
                },
                {
                    "date": 1733061971740,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -64,9 +64,8 @@\n             raise ValueError(\"Empty dataframe provided\")\r\n \r\n         # Initialize processors\r\n         scaler = DataScaler(self.config.time_series_scaler)\r\n-        transformer = DataTransformer()\r\n \r\n         # Make sure we have enough data points\r\n         min_required = (self.config.time_series_window_in_hours + \r\n                     self.config.forecasting_horizon_in_hours) * 4  # 4 points per hour\r\n@@ -76,16 +75,12 @@\n         if len(self._df) < min_required:\r\n             raise ValueError(f\"Not enough data points. Need at least {min_required}, got {len(self._df)}\")\r\n \r\n         try:\r\n-            # Extract raw data\r\n-            raw_data = np.array(self._df[self.config.target_variable])\r\n-            print(f\"Debug - Raw data shape: {raw_data.shape}\")\r\n+            # Extract raw data (already in 15-min intervals)\r\n+            load_data = np.array(self._df[self.config.target_variable])\r\n+            print(f\"Debug - Load data shape: {load_data.shape}\")\r\n             \r\n-            # Average data\r\n-            load_data = transformer.average_by_window(raw_data, window_size=4)\r\n-            print(f\"Debug - After averaging shape: {load_data.shape}\")\r\n-            \r\n             # Scale data\r\n             if self.config.time_series_scaler:\r\n                 scaled_data = (\r\n                     scaler.fit_transform(load_data)\r\n"
                },
                {
                    "date": 1733062042304,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -64,8 +64,9 @@\n             raise ValueError(\"Empty dataframe provided\")\r\n \r\n         # Initialize processors\r\n         scaler = DataScaler(self.config.time_series_scaler)\r\n+        transformer = DataTransformer()  # Add this line to instantiate DataTransformer\r\n \r\n         # Make sure we have enough data points\r\n         min_required = (self.config.time_series_window_in_hours + \r\n                     self.config.forecasting_horizon_in_hours) * 4  # 4 points per hour\r\n@@ -96,9 +97,9 @@\n             # Add validation check\r\n             if np.isnan(scaled_data).any() or np.isinf(scaled_data).any():\r\n                 raise ValueError(\"Invalid values detected after scaling\")\r\n \r\n-            # Extract timestamps and prepare features\r\n+            # Extract timestamps and prepare features using the instantiated transformer\r\n             time_stamps = transformer.extract_timestamps(\r\n                 self._df,\r\n                 self.config.time_variable\r\n             )\r\n"
                },
                {
                    "date": 1733062194863,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -21,31 +21,31 @@\n \r\n     def __len__(self) -> int:\r\n         if self.rows is None:\r\n             return 0\r\n-        return max(0, len(self.rows) - self.config.time_series_window_in_hours - self.config.forecasting_horizon_in_hours)\r\n+        total_window = (self.config.time_series_window_in_hours + \r\n+                       self.config.forecasting_horizon_in_hours) * self.config.points_per_hour\r\n+        return max(0, len(self.rows) - total_window)\r\n \r\n     def __getitem__(self, index: int) -> Tuple[torch.Tensor, torch.Tensor]:\r\n-        \"\"\"Get a data item by index\r\n-\r\n-        Returns:\r\n-            Tuple containing:\r\n-            - Input sequence [time_series_window_in_hours, features]\r\n-            - Target sequence [forecasting_horizon_in_hours, features]\r\n-        \"\"\"\r\n+        \"\"\"Get a data item by index\"\"\"\r\n         if self.rows is None:\r\n             raise ValueError(\"Dataset not properly initialized\")\r\n \r\n+        # Adjust window sizes to account for 15-minute intervals\r\n+        input_window = self.config.time_series_window_in_hours * self.config.points_per_hour\r\n+        forecast_window = self.config.forecasting_horizon_in_hours * self.config.points_per_hour\r\n+\r\n         input_seq = self.rows[\r\n-                    index:index + self.config.time_series_window_in_hours\r\n+                    index:index + input_window\r\n                     ]\r\n         \r\n         target_seq = self.rows[\r\n-                    index + self.config.time_series_window_in_hours:\r\n-                    index + self.config.time_series_window_in_hours + self.config.forecasting_horizon_in_hours\r\n+                    index + input_window:\r\n+                    index + input_window + forecast_window\r\n                     ]\r\n \r\n-        # Print debug info periodically\r\n+        # Debug info\r\n         if self._debug_counter % self._debug_frequency == 0:\r\n             print(f\"\\nDebug - Dataset __getitem__ (sample {self._debug_counter}):\")\r\n             print(f\"Input sequence shape: {input_seq.shape}\")\r\n             print(f\"Target sequence shape: {target_seq.shape}\")\r\n"
                }
            ],
            "date": 1733005186538,
            "name": "Commit-0",
            "content": "# data_loading/datasets/transformer_dataset.py\r\nimport numpy as np\r\nimport pandas as pd\r\nimport torch\r\nfrom typing import Tuple, List, Any\r\n\r\nfrom data_loading.base.base_dataset import BaseDataset, DatasetConfig\r\nfrom data_loading.features.time_features import CyclicalTimeFeature, WorkdayFeature\r\nfrom data_loading.preprocessing.data_scaler import DataScaler\r\nfrom data_loading.preprocessing.data_transformer import DataTransformer\r\n\r\nclass TransformerDataset(BaseDataset):\r\n    \"\"\"Dataset implementation for transformer models\"\"\"\r\n\r\n    def __init__(self, df: pd.DataFrame, config: DatasetConfig):\r\n        super().__init__(df, config)\r\n        self.rows: torch.Tensor = torch.empty(0)\r\n        self._prepare_time_series_data()\r\n\r\n    def __len__(self) -> int:\r\n        if self.rows is None:\r\n            return 0\r\n        return max(0, len(self.rows) - self.config.time_series_window_in_hours - self.config.forecasting_horizon_in_hours)\r\n\r\n    def __getitem__(self, index: int) -> Tuple[torch.Tensor, torch.Tensor]:\r\n        \"\"\"Get a data item by index\r\n\r\n        Returns:\r\n            Tuple containing:\r\n            - Input sequence [time_series_window_in_hours, features]\r\n            - Target sequence [forecasting_horizon_in_hours, features]\r\n        \"\"\"\r\n        if self.rows is None:\r\n            raise ValueError(\"Dataset not properly initialized\")\r\n\r\n        input_seq = self.rows[\r\n                    index:index + self.config.time_series_window_in_hours\r\n                    ]\r\n\r\n        target_seq = self.rows[\r\n                    index + self.config.time_series_window_in_hours:\r\n                    index + self.config.time_series_window_in_hours + self.config.forecasting_horizon_in_hours\r\n                    ]\r\n\r\n        return input_seq, target_seq\r\n\r\n    def _prepare_time_series_data(self) -> None:\r\n        \"\"\"Prepare time series data for model input\"\"\"\r\n        print(f\"\\nDebug - TransformerDataset preparation:\")\r\n        print(f\"Initial DataFrame shape: {self._df.shape}\")\r\n        \r\n        if len(self._df) == 0:\r\n            raise ValueError(\"Empty dataframe provided\")\r\n\r\n        # Initialize processors\r\n        scaler = DataScaler(self.config.time_series_scaler)\r\n        transformer = DataTransformer()\r\n\r\n        # Make sure we have enough data points\r\n        min_required = (self.config.time_series_window_in_hours + \r\n                    self.config.forecasting_horizon_in_hours) * 4  # 4 points per hour\r\n        print(f\"Debug - Required data points: {min_required}\")\r\n        print(f\"Debug - Available data points: {len(self._df)}\")\r\n        \r\n        if len(self._df) < min_required:\r\n            raise ValueError(f\"Not enough data points. Need at least {min_required}, got {len(self._df)}\")\r\n\r\n        try:\r\n            # Extract raw data\r\n            raw_data = np.array(self._df[self.config.target_variable])\r\n            print(f\"Debug - Raw data shape: {raw_data.shape}\")\r\n            \r\n            # Average data\r\n            load_data = transformer.average_by_window(raw_data, window_size=4)\r\n            print(f\"Debug - After averaging shape: {load_data.shape}\")\r\n            \r\n            # Scale data\r\n            if self.config.time_series_scaler:\r\n                scaled_data = (\r\n                    scaler.fit_transform(load_data)\r\n                    if self.config.is_training_set\r\n                    else scaler.transform(load_data)\r\n                )\r\n                print(f\"Debug - After scaling shape: {scaled_data.shape}\")\r\n            else:\r\n                scaled_data = load_data\r\n\r\n            # Extract timestamps and prepare features\r\n            time_stamps = transformer.extract_timestamps(\r\n                self._df,\r\n                self.config.time_variable\r\n            )\r\n            print(f\"Debug - Time stamps shape: {time_stamps.shape}\")\r\n\r\n            # Initialize feature generators\r\n            hour_feature = CyclicalTimeFeature(24)\r\n            week_feature = CyclicalTimeFeature(53)\r\n            workday_feature = WorkdayFeature()\r\n\r\n            sequence_rows = []\r\n\r\n            # Generate features for each timestamp\r\n            print(f\"Debug - Generating features for {len(scaled_data)} time points\")\r\n            for idx, (load_value, time_stamp) in enumerate(zip(scaled_data, time_stamps)):\r\n                features = [load_value]\r\n\r\n                if self.config.include_time_information:\r\n                    timestamp_pd = pd.Timestamp(time_stamp)\r\n                    features.extend(hour_feature.generate(pd.Series([timestamp_pd.hour])))\r\n                    features.extend(week_feature.generate(pd.Series([timestamp_pd.isocalendar()[1]])))\r\n                    features.extend(workday_feature.generate(timestamp_pd))\r\n\r\n                sequence_rows.append(features)\r\n\r\n            self.rows = torch.tensor(np.array(sequence_rows, dtype=np.float32))\r\n            print(f\"Debug - Final rows tensor shape: {self.rows.shape}\")\r\n\r\n            # Set input and target tensors\r\n            self.prepared_time_series_input = self.rows[\r\n                :len(self.rows) - self.config.forecasting_horizon_in_hours\r\n            ]\r\n            self.prepared_time_series_target = self.rows[\r\n                self.config.time_series_window_in_hours:\r\n            ]\r\n\r\n            print(f\"Debug - Final shapes:\")\r\n            print(f\"  Input tensor: {self.prepared_time_series_input.shape if self.prepared_time_series_input is not None else None}\")\r\n            print(f\"  Target tensor: {self.prepared_time_series_target.shape if self.prepared_time_series_target is not None else None}\")\r\n\r\n        except Exception as e:\r\n            print(f\"\\nError preparing time series data: {str(e)}\")\r\n            print(f\"DataFrame info:\")\r\n            print(self._df.info())\r\n            raise"
        }
    ]
}