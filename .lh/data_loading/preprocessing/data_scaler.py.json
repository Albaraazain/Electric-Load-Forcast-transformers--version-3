{
    "sourceFile": "data_loading/preprocessing/data_scaler.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 1,
            "patches": [
                {
                    "date": 1733007043433,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1733007053795,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,37 @@\n+import numpy as np\r\n+from sklearn.preprocessing import StandardScaler\r\n+from typing import Optional\r\n+\r\n+class DataScaler:\r\n+    \"\"\"Handles data scaling operations\"\"\"\r\n+\r\n+    def __init__(self, scaler: Optional[StandardScaler] = None):\r\n+        self.scaler = scaler or StandardScaler()\r\n+\r\n+    def fit_transform(self, data: np.ndarray) -> np.ndarray:\r\n+        \"\"\"Fit scaler to data and transform\"\"\"\r\n+        print(f\"\\nDebug - DataScaler fit_transform:\")\r\n+        print(f\"Input data range: [{np.min(data):.2f}, {np.max(data):.2f}]\")\r\n+        \r\n+        if data.ndim == 1:\r\n+            data = data.reshape(-1, 1)\r\n+        \r\n+        scaled_data = self.scaler.fit_transform(data).flatten()\r\n+        print(f\"Output scaled range: [{np.min(scaled_data):.2f}, {np.max(scaled_data):.2f}]\")\r\n+        print(f\"Mean: {np.mean(scaled_data):.2f}, Std: {np.std(scaled_data):.2f}\")\r\n+        \r\n+        return scaled_data\r\n+\r\n+    def transform(self, data: np.ndarray) -> np.ndarray:\r\n+        \"\"\"Transform data using fitted scaler\"\"\"\r\n+        print(f\"\\nDebug - DataScaler transform:\")\r\n+        print(f\"Input data range: [{np.min(data):.2f}, {np.max(data):.2f}]\")\r\n+        \r\n+        if data.ndim == 1:\r\n+            data = data.reshape(-1, 1)\r\n+            \r\n+        scaled_data = self.scaler.transform(data).flatten()\r\n+        print(f\"Output scaled range: [{np.min(scaled_data):.2f}, {np.max(scaled_data):.2f}]\")\r\n+        print(f\"Mean: {np.mean(scaled_data):.2f}, Std: {np.std(scaled_data):.2f}\")\r\n+        \r\n+        return scaled_data\n\\ No newline at end of file\n"
                }
            ],
            "date": 1733007043433,
            "name": "Commit-0",
            "content": "import numpy as np\r\nfrom sklearn.preprocessing import StandardScaler\r\nfrom typing import Optional\r\n\r\nclass DataScaler:\r\n    \"\"\"Handles data scaling operations\"\"\"\r\n\r\n    def __init__(self, scaler: Optional[StandardScaler] = None):\r\n        self.scaler = scaler or StandardScaler()\r\n\r\n    def fit_transform(self, data: np.ndarray) -> np.ndarray:\r\n        \"\"\"Fit scaler to data and transform\"\"\"\r\n        print(f\"\\nDebug - DataScaler fit_transform:\")\r\n        print(f\"Input data range: [{np.min(data):.2f}, {np.max(data):.2f}]\")\r\n        \r\n        if data.ndim == 1:\r\n            data = data.reshape(-1, 1)\r\n        \r\n        scaled_data = self.scaler.fit_transform(data).flatten()\r\n        print(f\"Output scaled range: [{np.min(scaled_data):.2f}, {np.max(scaled_data):.2f}]\")\r\n        print(f\"Mean: {np.mean(scaled_data):.2f}, Std: {np.std(scaled_data):.2f}\")\r\n        \r\n        return scaled_data\r\n\r\n    def transform(self, data: np.ndarray) -> np.ndarray:\r\n        \"\"\"Transform data using fitted scaler\"\"\"\r\n        print(f\"\\nDebug - DataScaler transform:\")\r\n        print(f\"Input data range: [{np.min(data):.2f}, {np.max(data):.2f}]\")\r\n        \r\n        if data.ndim == 1:\r\n            data = data.reshape(-1, 1)\r\n            \r\n        scaled_data = self.scaler.transform(data).flatten()\r\n        print(f\"Output scaled range: [{np.min(scaled_data):.2f}, {np.max(scaled_data):.2f}]\")\r\n        print(f\"Mean: {np.mean(scaled_data):.2f}, Std: {np.std(scaled_data):.2f}\")\r\n        \r\n        return scaled_data"
        }
    ]
}