{
    "sourceFile": "models/architectures/transformers/resolution_specific/subhourly_transformer.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 8,
            "patches": [
                {
                    "date": 1733171820893,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1733171874093,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,9 +2,10 @@\n from typing import Dict, Any, Optional\r\n import torch\r\n from torch import nn, Tensor\r\n \r\n-from ....data_loading.base.interval_types import TimeInterval\r\n+from data_loading.types.interval_types import TimeInterval\r\n+\r\n from .base_resolution_transformer import BaseResolutionTransformer\r\n from ....registry.factory import ModelFactory\r\n from ....registry.model_types import ModelType\r\n from ....components.layers import EncoderLayer, DecoderLayer\r\n"
                },
                {
                    "date": 1733172736454,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,8 +1,10 @@\n-# models/architectures/transformers/resolution_specific/subhourly_transformer.py\r\n from typing import Dict, Any, Optional\r\n+from datetime import datetime\r\n+import pandas as pd\r\n import torch\r\n from torch import nn, Tensor\r\n+import math\r\n \r\n from data_loading.types.interval_types import TimeInterval\r\n \r\n from .base_resolution_transformer import BaseResolutionTransformer\r\n@@ -123,12 +125,28 @@\n             src, tgt,\r\n             src_mask=src_mask,\r\n             tgt_mask=tgt_mask,\r\n             src_key_padding_mask=src_key_padding_mask,\r\n-            tgt_key_padding_mask=tgt_key_padding_mask\r\n+            tgt_key_padding_mask= tgt_key_padding_mask\r\n         )\r\n         \r\n         # Additional processing for sub-hourly predictions if needed\r\n         if hasattr(self, 'output_processing'):\r\n             output = self.output_processing(output)\r\n             \r\n\\ No newline at end of file\n-        return output\n+        return output\r\n+\r\n+    def _handle_temporal_features(\r\n+        self,\r\n+        x: Tensor,\r\n+        timestamps: torch.Tensor\r\n+    ) -> Tensor:\r\n+        \"\"\"Handle temporal features for sub-hourly data.\"\"\"\r\n+        # Convert tensor timestamps to pandas datetime\r\n+        dates = pd.to_datetime(timestamps.cpu().numpy(), unit='s')\r\n+        \r\n+        # Extract temporal features\r\n+        minutes = torch.tensor(dates.minute.values, device=timestamps.device)\r\n+        hours = torch.tensor(dates.hour.values, device=timestamps.device)\r\n+        \r\n+        # Process and return features\r\n+        return x  # This should be implemented with actual feature processing\n\\ No newline at end of file\n"
                },
                {
                    "date": 1733179356480,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -7,11 +7,11 @@\n \r\n from data_loading.types.interval_types import TimeInterval\r\n \r\n from .base_resolution_transformer import BaseResolutionTransformer\r\n-from ....registry.factory import ModelFactory\r\n-from ....registry.model_types import ModelType\r\n-from ....components.layers import EncoderLayer, DecoderLayer\r\n+from models.registry.factory import ModelFactory\r\n+from models.registry.model_types import ModelType\r\n+from models.components.layers import EncoderLayer, DecoderLayer\r\n \r\n @ModelFactory.register(ModelType.SUBHOURLY_TRANSFORMER)\r\n class SubhourlyTransformer(BaseResolutionTransformer):\r\n     \"\"\"Transformer optimized for sub-hourly predictions (≤60 minutes).\"\"\"\r\n"
                },
                {
                    "date": 1733179517695,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,21 +1,18 @@\n from typing import Dict, Any, Optional\r\n-from datetime import datetime\r\n-import pandas as pd\r\n import torch\r\n from torch import nn, Tensor\r\n-import math\r\n+import pandas as pd\r\n \r\n from data_loading.types.interval_types import TimeInterval\r\n-\r\n from .base_resolution_transformer import BaseResolutionTransformer\r\n-from models.registry.factory import ModelFactory\r\n from models.registry.model_types import ModelType\r\n from models.components.layers import EncoderLayer, DecoderLayer\r\n \r\n-@ModelFactory.register(ModelType.SUBHOURLY_TRANSFORMER)\r\n class SubhourlyTransformer(BaseResolutionTransformer):\r\n     \"\"\"Transformer optimized for sub-hourly predictions (≤60 minutes).\"\"\"\r\n+    \r\n+    # ...existing code...\r\n \r\n     def __init__(self, config: Dict[str, Any]):\r\n         # Validate resolution before initialization\r\n         if config.get('forecast_resolution_minutes', 15) > 60:\r\n"
                },
                {
                    "date": 1733179646087,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -4,9 +4,8 @@\n import pandas as pd\r\n \r\n from data_loading.types.interval_types import TimeInterval\r\n from .base_resolution_transformer import BaseResolutionTransformer\r\n-from models.registry.model_types import ModelType\r\n from models.components.layers import EncoderLayer, DecoderLayer\r\n \r\n class SubhourlyTransformer(BaseResolutionTransformer):\r\n     \"\"\"Transformer optimized for sub-hourly predictions (≤60 minutes).\"\"\"\r\n"
                },
                {
                    "date": 1733238702947,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -12,27 +12,39 @@\n     \r\n     # ...existing code...\r\n \r\n     def __init__(self, config: Dict[str, Any]):\r\n-        # Validate resolution before initialization\r\n-        if config.get('forecast_resolution_minutes', 15) > 60:\r\n-            raise ValueError(\"SubhourlyTransformer cannot handle resolutions > 60 minutes\")\r\n+        \"\"\"\r\n+        Initialize SubhourlyTransformer with proper layer creation.\r\n         \r\n+        Args:\r\n+            config: Configuration dictionary containing model parameters\r\n+        \"\"\"\r\n+        # Call parent class initialization first\r\n         super().__init__(config)\r\n         \r\n-        # Subhourly-specific configurations\r\n-        self.minutes_per_step = config.get('forecast_resolution_minutes', 15)\r\n+        # Initialize layers after parent initialization\r\n         self.steps_per_hour = 60 // self.minutes_per_step\r\n         \r\n-        # Enhanced short-term pattern recognition\r\n+        # Create encoder layers\r\n+        self.encoder_layers = self._create_encoder_layers()\r\n+        \r\n+        # Create decoder layers\r\n+        self.decoder_layers = self._create_decoder_layers()\r\n+        \r\n+        # Initialize short-term pattern recognition\r\n         self.short_term_conv = nn.Conv1d(\r\n             in_channels=self.d_model,\r\n             out_channels=self.d_model,\r\n             kernel_size=3,\r\n             padding=1,\r\n             groups=self.d_model  # Depthwise convolution for efficiency\r\n         )\r\n+        \r\n+        print(\"DEBUG: SubhourlyTransformer initialization complete\")\r\n+        print(f\"DEBUG: Encoder layers created: {hasattr(self, 'encoder_layers')}\")\r\n \r\n+\r\n     def _create_encoder_layers(self) -> nn.ModuleList:\r\n         \"\"\"Create encoder layers optimized for sub-hourly patterns.\"\"\"\r\n         return nn.ModuleList([\r\n             EncoderLayer(\r\n"
                },
                {
                    "date": 1733238859213,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -9,10 +9,8 @@\n \r\n class SubhourlyTransformer(BaseResolutionTransformer):\r\n     \"\"\"Transformer optimized for sub-hourly predictions (≤60 minutes).\"\"\"\r\n     \r\n-    # ...existing code...\r\n-\r\n     def __init__(self, config: Dict[str, Any]):\r\n         \"\"\"\r\n         Initialize SubhourlyTransformer with proper layer creation.\r\n         \r\n@@ -21,9 +19,18 @@\n         \"\"\"\r\n         # Call parent class initialization first\r\n         super().__init__(config)\r\n         \r\n-        # Initialize layers after parent initialization\r\n+        # Store configuration parameters\r\n+        self.n_encoder_layers = config.get('n_encoder_layers', 6)\r\n+        self.n_decoder_layers = config.get('n_decoder_layers', 6)\r\n+        self.d_model = config.get('d_model', 512)\r\n+        self.n_heads = config.get('n_heads', 8)\r\n+        self.d_ff = config.get('d_ff', 2048)\r\n+        self.dropout = config.get('dropout', 0.1)\r\n+        \r\n+        # Calculate steps per hour based on resolution\r\n+        self.minutes_per_step = config.get('forecast_resolution_minutes', 15)\r\n         self.steps_per_hour = 60 // self.minutes_per_step\r\n         \r\n         # Create encoder layers\r\n         self.encoder_layers = self._create_encoder_layers()\r\n@@ -40,11 +47,10 @@\n             groups=self.d_model  # Depthwise convolution for efficiency\r\n         )\r\n         \r\n         print(\"DEBUG: SubhourlyTransformer initialization complete\")\r\n-        print(f\"DEBUG: Encoder layers created: {hasattr(self, 'encoder_layers')}\")\r\n+        print(f\"DEBUG: Configuration loaded - n_encoder_layers: {self.n_encoder_layers}, d_model: {self.d_model}\")\r\n \r\n-\r\n     def _create_encoder_layers(self) -> nn.ModuleList:\r\n         \"\"\"Create encoder layers optimized for sub-hourly patterns.\"\"\"\r\n         return nn.ModuleList([\r\n             EncoderLayer(\r\n"
                },
                {
                    "date": 1733239713767,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -16,8 +16,12 @@\n         \r\n         Args:\r\n             config: Configuration dictionary containing model parameters\r\n         \"\"\"\r\n+        # Ensure output_features is in config\r\n+        if 'output_features' not in config:\r\n+            config['output_features'] = 1  # Default to 1 if not specified\r\n+        \r\n         # Call parent class initialization first\r\n         super().__init__(config)\r\n         \r\n         # Store configuration parameters\r\n"
                }
            ],
            "date": 1733171820893,
            "name": "Commit-0",
            "content": "# models/architectures/transformers/resolution_specific/subhourly_transformer.py\r\nfrom typing import Dict, Any, Optional\r\nimport torch\r\nfrom torch import nn, Tensor\r\n\r\nfrom ....data_loading.base.interval_types import TimeInterval\r\nfrom .base_resolution_transformer import BaseResolutionTransformer\r\nfrom ....registry.factory import ModelFactory\r\nfrom ....registry.model_types import ModelType\r\nfrom ....components.layers import EncoderLayer, DecoderLayer\r\n\r\n@ModelFactory.register(ModelType.SUBHOURLY_TRANSFORMER)\r\nclass SubhourlyTransformer(BaseResolutionTransformer):\r\n    \"\"\"Transformer optimized for sub-hourly predictions (≤60 minutes).\"\"\"\r\n\r\n    def __init__(self, config: Dict[str, Any]):\r\n        # Validate resolution before initialization\r\n        if config.get('forecast_resolution_minutes', 15) > 60:\r\n            raise ValueError(\"SubhourlyTransformer cannot handle resolutions > 60 minutes\")\r\n        \r\n        super().__init__(config)\r\n        \r\n        # Subhourly-specific configurations\r\n        self.minutes_per_step = config.get('forecast_resolution_minutes', 15)\r\n        self.steps_per_hour = 60 // self.minutes_per_step\r\n        \r\n        # Enhanced short-term pattern recognition\r\n        self.short_term_conv = nn.Conv1d(\r\n            in_channels=self.d_model,\r\n            out_channels=self.d_model,\r\n            kernel_size=3,\r\n            padding=1,\r\n            groups=self.d_model  # Depthwise convolution for efficiency\r\n        )\r\n\r\n    def _create_encoder_layers(self) -> nn.ModuleList:\r\n        \"\"\"Create encoder layers optimized for sub-hourly patterns.\"\"\"\r\n        return nn.ModuleList([\r\n            EncoderLayer(\r\n                d_model=self.d_model,\r\n                n_heads=self.n_heads,\r\n                d_ff=self.d_ff,\r\n                dropout=self.dropout,\r\n                attention_type=\"standard\",  # Use standard attention for short sequences\r\n                activation=\"gelu\"  # GELU for better gradient flow\r\n            ) for _ in range(self.n_encoder_layers)\r\n        ])\r\n\r\n    def _create_decoder_layers(self) -> nn.ModuleList:\r\n        \"\"\"Create decoder layers optimized for sub-hourly patterns.\"\"\"\r\n        return nn.ModuleList([\r\n            DecoderLayer(\r\n                d_model=self.d_model,\r\n                n_heads=self.n_heads,\r\n                d_ff=self.d_ff,\r\n                dropout=self.dropout,\r\n                attention_type=\"standard\",\r\n                activation=\"gelu\"\r\n            ) for _ in range(self.n_decoder_layers)\r\n        ])\r\n\r\n    def encode(\r\n        self,\r\n        src: Tensor,\r\n        src_mask: Optional[Tensor] = None,\r\n        src_key_padding_mask: Optional[Tensor] = None,\r\n    ) -> Tensor:\r\n        \"\"\"Enhanced encoding with short-term pattern recognition.\"\"\"\r\n        # Standard embedding\r\n        src = self.encoder_embedding(src)\r\n        \r\n        # Apply short-term pattern recognition\r\n        src_conv = src.transpose(1, 2)  # [batch, d_model, seq_len]\r\n        src_conv = self.short_term_conv(src_conv)\r\n        src_conv = src_conv.transpose(1, 2)  # [batch, seq_len, d_model]\r\n        \r\n        # Combine with original embeddings\r\n        src = src + src_conv\r\n        \r\n        # Pass through encoder layers\r\n        for layer in self.encoder_layers:\r\n            src = layer(\r\n                src,\r\n                src_mask=src_mask,\r\n                src_key_padding_mask=src_key_padding_mask\r\n            )\r\n        return src\r\n\r\n    def _adjust_attention_for_resolution(\r\n        self,\r\n        attention_weights: Tensor,\r\n        resolution_minutes: int\r\n    ) -> Tensor:\r\n        \"\"\"Adjust attention weights for sub-hourly patterns.\"\"\"\r\n        # Enhance attention to recent time steps\r\n        sequence_length = attention_weights.size(-1)\r\n        recent_steps = min(self.steps_per_hour * 2, sequence_length)  # Last 2 hours\r\n        \r\n        # Create decaying weights for recent time steps\r\n        decay = torch.exp(torch.arange(recent_steps, 0, -1, device=attention_weights.device) * -0.1)\r\n        decay = torch.cat([torch.ones(sequence_length - recent_steps, device=attention_weights.device), decay])\r\n        \r\n        # Apply decay to attention weights\r\n        return attention_weights * decay.unsqueeze(0).unsqueeze(0)\r\n\r\n    @classmethod\r\n    def get_resolution_type(cls) -> TimeInterval:\r\n        \"\"\"Get the time interval type for sub-hourly transformer.\"\"\"\r\n        return TimeInterval.FIFTEEN_MIN\r\n\r\n    def forward(\r\n        self,\r\n        src: Tensor,\r\n        tgt: Tensor,\r\n        src_mask: Optional[Tensor] = None,\r\n        tgt_mask: Optional[Tensor] = None,\r\n        src_key_padding_mask: Optional[Tensor] = None,\r\n        tgt_key_padding_mask: Optional[Tensor] = None,\r\n    ) -> Tensor:\r\n        \"\"\"Forward pass with enhanced sub-hourly pattern recognition.\"\"\"\r\n        output = super().forward(\r\n            src, tgt,\r\n            src_mask=src_mask,\r\n            tgt_mask=tgt_mask,\r\n            src_key_padding_mask=src_key_padding_mask,\r\n            tgt_key_padding_mask=tgt_key_padding_mask\r\n        )\r\n        \r\n        # Additional processing for sub-hourly predictions if needed\r\n        if hasattr(self, 'output_processing'):\r\n            output = self.output_processing(output)\r\n            \r\n        return output"
        }
    ]
}