{
    "sourceFile": "models/registry/factory.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 7,
            "patches": [
                {
                    "date": 1733172278210,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1733172431091,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,6 +1,8 @@\n # models/registry/factory.py\r\n from typing import Any, Dict, Type, Callable, Optional\r\n+from sklearn.base import BaseEstimator, RegressorMixin\r\n+from typing import Protocol\r\n \r\n from models.base.base_model import BaseModel\r\n from models.wrappers.pytorch_wrapper import PyTorchWrapper\r\n from models.architectures.transformers.resolution_specific import (\r\n@@ -13,8 +15,23 @@\n \r\n from .model_types import ModelType\r\n from ..interfaces import WrapperInterface\r\n \r\n+class ModelSklearnAdapter(BaseEstimator, RegressorMixin):\r\n+    \"\"\"Adapter to make our models compatible with sklearn interface.\"\"\"\r\n+    \r\n+    def __init__(self, model: BaseModel, model_type: ModelType, config: Dict[str, Any]):\r\n+        self.model = model\r\n+        self.model_type = model_type\r\n+        self.config = config\r\n+\r\n+    def fit(self, X, y=None):\r\n+        self.model.fit(X, y)\r\n+        return self\r\n+\r\n+    def predict(self, X):\r\n+        return self.model.predict(X)\r\n+\r\n class ModelFactory:\r\n     \"\"\"Factory for creating model instances.\"\"\"\r\n     _registry: Dict[ModelType, Type[BaseModel]] = {}\r\n \r\n@@ -100,10 +117,11 @@\n \r\n         # Determine appropriate wrapper\r\n         if wrapper_type == 'sklearn':\r\n             from models.wrappers.sklearn_wrapper import SklearnWrapper\r\n+            adapter = ModelSklearnAdapter(base_model, model_type, config)\r\n             return SklearnWrapper(\r\n-                model=base_model,\r\n+                model=adapter,\r\n                 model_type=model_type,\r\n                 config=config\r\n             )\r\n         else:  # Default to PyTorch wrapper\r\n"
                },
                {
                    "date": 1733172736474,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -114,23 +114,21 @@\n             wrapper_type: Optional wrapper type (defaults to 'pytorch')\r\n         \"\"\"\r\n         base_model = cls.create_base_model(model_type, config)\r\n \r\n-        # Determine appropriate wrapper\r\n-        if wrapper_type == 'sklearn':\r\n-            from models.wrappers.sklearn_wrapper import SklearnWrapper\r\n-            adapter = ModelSklearnAdapter(base_model, model_type, config)\r\n-            return SklearnWrapper(\r\n-                model=adapter,\r\n-                model_type=model_type,\r\n-                config=config\r\n-            )\r\n-        else:  # Default to PyTorch wrapper\r\n+        if wrapper_type != 'sklearn':\r\n             return PyTorchWrapper(\r\n                 model=base_model,\r\n                 model_type=model_type,\r\n                 config=config\r\n             )\r\n+        from models.wrappers.sklearn_wrapper import SklearnWrapper\r\n+        adapter = ModelSklearnAdapter(base_model, model_type, config)\r\n+        return SklearnWrapper(\r\n+            model=adapter,\r\n+            model_type=model_type,\r\n+            config=config\r\n+        )\r\n \r\n     @classmethod\r\n     def get_registered_models(cls) -> Dict[ModelType, Type[BaseModel]]:\r\n         \"\"\"Get all registered model types.\"\"\"\r\n"
                },
                {
                    "date": 1733179517647,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,20 +1,12 @@\n # models/registry/factory.py\r\n-from typing import Any, Dict, Type, Callable, Optional\r\n+from typing import Any, Dict, Optional\r\n from sklearn.base import BaseEstimator, RegressorMixin\r\n-from typing import Protocol\r\n \r\n from models.base.base_model import BaseModel\r\n from models.wrappers.pytorch_wrapper import PyTorchWrapper\r\n-from models.architectures.transformers.resolution_specific import (\r\n-    get_transformer_for_resolution,\r\n-    SubhourlyTransformer,\r\n-    HourlyTransformer,\r\n-    DailyTransformer,\r\n-    MonthlyTransformer\r\n-)\r\n-\r\n-from .model_types import ModelType\r\n+from models.registry.model_types import ModelType\r\n+from models.registry.model_registry import ModelRegistry\r\n from ..interfaces import WrapperInterface\r\n \r\n class ModelSklearnAdapter(BaseEstimator, RegressorMixin):\r\n     \"\"\"Adapter to make our models compatible with sklearn interface.\"\"\"\r\n@@ -32,30 +24,16 @@\n         return self.model.predict(X)\r\n \r\n class ModelFactory:\r\n     \"\"\"Factory for creating model instances.\"\"\"\r\n-    _registry: Dict[ModelType, Type[BaseModel]] = {}\r\n-\r\n+    \r\n     @classmethod\r\n-    def register(cls, model_type: ModelType) -> Callable[[Type[BaseModel]], Type[BaseModel]]:\r\n-        \"\"\"Register a model in the factory.\"\"\"\r\n-        def decorator(model_cls: Type[BaseModel]) -> Type[BaseModel]:\r\n-            print(f\"Registering model {model_cls.__name__} for type {model_type}\")\r\n-            cls._registry[model_type] = model_cls\r\n-            return model_cls\r\n-        return decorator\r\n-\r\n-    @classmethod\r\n     def create_base_model(\r\n         cls,\r\n         model_type: ModelType,\r\n         config: Dict[str, Any]\r\n     ) -> BaseModel:\r\n         \"\"\"Create a raw model instance.\"\"\"\r\n-        if not cls._registry:\r\n-            print(\"Warning: Model registry is empty. Make sure models are imported and registered.\")\r\n-            raise ValueError(\"No models registered in factory\")\r\n-        \r\n         # Handle resolution-specific transformer types\r\n         if model_type in {\r\n             ModelType.SUBHOURLY_TRANSFORMER,\r\n             ModelType.HOURLY_TRANSFORMER,\r\n@@ -63,21 +41,14 @@\n             ModelType.MONTHLY_TRANSFORMER\r\n         }:\r\n             return cls._create_resolution_transformer(model_type, config)\r\n         \r\n-        # Handle standard model types\r\n-        if model_type not in cls._registry:\r\n-            raise ValueError(f\"Unknown model type: {model_type}. Available types: {list(cls._registry.keys())}\")\r\n-        \r\n-        model_class = cls._registry[model_type]\r\n+        # Get model class from registry\r\n+        model_class = ModelRegistry.get_model_class(model_type)\r\n         return model_class(config)\r\n \r\n     @classmethod\r\n-    def _create_resolution_transformer(\r\n-        cls,\r\n-        model_type: ModelType,\r\n-        config: Dict[str, Any]\r\n-    ) -> BaseModel:\r\n+    def _create_resolution_transformer(cls, model_type: ModelType, config: Dict[str, Any]) -> BaseModel:\r\n         \"\"\"Create a resolution-specific transformer instance.\"\"\"\r\n         # Map model type to resolution\r\n         resolution_map = {\r\n             ModelType.SUBHOURLY_TRANSFORMER: 15,  # 15 minutes\r\n@@ -99,14 +70,9 @@\n         # Create and return transformer instance\r\n         return transformer_class(config)\r\n \r\n     @classmethod\r\n-    def create(\r\n-        cls,\r\n-        model_type: ModelType,\r\n-        config: Dict[str, Any],\r\n-        wrapper_type: Optional[str] = None\r\n-    ) -> WrapperInterface:\r\n+    def create(cls, model_type: ModelType, config: Dict[str, Any], wrapper_type: Optional[str] = None) -> WrapperInterface:\r\n         \"\"\"Create a wrapped model instance.\r\n         \r\n         Args:\r\n             model_type: Type of model to create\r\n"
                },
                {
                    "date": 1733179551762,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,12 +1,13 @@\n # models/registry/factory.py\r\n-from typing import Any, Dict, Optional\r\n+from typing import Any, Dict, Optional, Type\r\n from sklearn.base import BaseEstimator, RegressorMixin\r\n \r\n from models.base.base_model import BaseModel\r\n from models.wrappers.pytorch_wrapper import PyTorchWrapper\r\n from models.registry.model_types import ModelType\r\n from models.registry.model_registry import ModelRegistry\r\n+from models.architectures.transformers.resolution_specific import get_transformer_for_resolution\r\n from ..interfaces import WrapperInterface\r\n \r\n class ModelSklearnAdapter(BaseEstimator, RegressorMixin):\r\n     \"\"\"Adapter to make our models compatible with sklearn interface.\"\"\"\r\n@@ -97,9 +98,9 @@\n \r\n     @classmethod\r\n     def get_registered_models(cls) -> Dict[ModelType, Type[BaseModel]]:\r\n         \"\"\"Get all registered model types.\"\"\"\r\n-        return cls._registry.copy()\r\n+        return ModelRegistry.get_registered_models()\r\n \r\n     @classmethod\r\n     def get_resolution_models(cls) -> Dict[str, ModelType]:\r\n         \"\"\"Get available resolution-specific model types.\"\"\"\r\n"
                },
                {
                    "date": 1733179646078,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -25,54 +25,30 @@\n         return self.model.predict(X)\r\n \r\n class ModelFactory:\r\n     \"\"\"Factory for creating model instances.\"\"\"\r\n+    _registry = ModelRegistry()\r\n     \r\n     @classmethod\r\n     def create_base_model(\r\n         cls,\r\n         model_type: ModelType,\r\n         config: Dict[str, Any]\r\n     ) -> BaseModel:\r\n         \"\"\"Create a raw model instance.\"\"\"\r\n-        # Handle resolution-specific transformer types\r\n         if model_type in {\r\n             ModelType.SUBHOURLY_TRANSFORMER,\r\n             ModelType.HOURLY_TRANSFORMER,\r\n             ModelType.DAILY_TRANSFORMER,\r\n             ModelType.MONTHLY_TRANSFORMER\r\n         }:\r\n-            return cls._create_resolution_transformer(model_type, config)\r\n+            from models.architectures.transformers.resolution_specific import get_transformer_for_resolution\r\n+            transformer_class = get_transformer_for_resolution(config['forecast_resolution_minutes'])\r\n+            return transformer_class(config)\r\n         \r\n-        # Get model class from registry\r\n-        model_class = ModelRegistry.get_model_class(model_type)\r\n-        return model_class(config)\r\n+        return cls._registry.create_model(model_type, config)\r\n \r\n     @classmethod\r\n-    def _create_resolution_transformer(cls, model_type: ModelType, config: Dict[str, Any]) -> BaseModel:\r\n-        \"\"\"Create a resolution-specific transformer instance.\"\"\"\r\n-        # Map model type to resolution\r\n-        resolution_map = {\r\n-            ModelType.SUBHOURLY_TRANSFORMER: 15,  # 15 minutes\r\n-            ModelType.HOURLY_TRANSFORMER: 60,     # 1 hour\r\n-            ModelType.DAILY_TRANSFORMER: 1440,    # 24 hours\r\n-            ModelType.MONTHLY_TRANSFORMER: 43200  # 30 days\r\n-        }\r\n-        \r\n-        resolution = resolution_map[model_type]\r\n-        \r\n-        # Ensure resolution is set in config\r\n-        config['forecast_resolution_minutes'] = resolution\r\n-        if 'input_resolution_minutes' not in config:\r\n-            config['input_resolution_minutes'] = resolution\r\n-        \r\n-        # Get appropriate transformer class\r\n-        transformer_class = get_transformer_for_resolution(resolution)\r\n-        \r\n-        # Create and return transformer instance\r\n-        return transformer_class(config)\r\n-\r\n-    @classmethod\r\n     def create(cls, model_type: ModelType, config: Dict[str, Any], wrapper_type: Optional[str] = None) -> WrapperInterface:\r\n         \"\"\"Create a wrapped model instance.\r\n         \r\n         Args:\r\n@@ -98,9 +74,9 @@\n \r\n     @classmethod\r\n     def get_registered_models(cls) -> Dict[ModelType, Type[BaseModel]]:\r\n         \"\"\"Get all registered model types.\"\"\"\r\n-        return ModelRegistry.get_registered_models()\r\n+        return cls._registry.get_registered_models()\r\n \r\n     @classmethod\r\n     def get_resolution_models(cls) -> Dict[str, ModelType]:\r\n         \"\"\"Get available resolution-specific model types.\"\"\"\r\n"
                },
                {
                    "date": 1733183436763,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,6 +1,6 @@\n # models/registry/factory.py\r\n-from typing import Any, Dict, Optional, Type\r\n+from typing import Any, Dict, Optional, Type, ClassVar\r\n from sklearn.base import BaseEstimator, RegressorMixin\r\n \r\n from models.base.base_model import BaseModel\r\n from models.wrappers.pytorch_wrapper import PyTorchWrapper\r\n@@ -24,63 +24,127 @@\n     def predict(self, X):\r\n         return self.model.predict(X)\r\n \r\n class ModelFactory:\r\n-    \"\"\"Factory for creating model instances.\"\"\"\r\n-    _registry = ModelRegistry()\r\n+    \"\"\"\r\n+    Factory for creating and managing model instances. This class provides centralized\r\n+    model creation and registration functionality using a decorator pattern.\r\n+    \"\"\"\r\n+    # Class-level registry instance\r\n+    _registry: ClassVar[ModelRegistry] = ModelRegistry()\r\n     \r\n     @classmethod\r\n-    def create_base_model(\r\n-        cls,\r\n-        model_type: ModelType,\r\n-        config: Dict[str, Any]\r\n-    ) -> BaseModel:\r\n-        \"\"\"Create a raw model instance.\"\"\"\r\n-        if model_type in {\r\n-            ModelType.SUBHOURLY_TRANSFORMER,\r\n-            ModelType.HOURLY_TRANSFORMER,\r\n-            ModelType.DAILY_TRANSFORMER,\r\n-            ModelType.MONTHLY_TRANSFORMER\r\n-        }:\r\n-            from models.architectures.transformers.resolution_specific import get_transformer_for_resolution\r\n-            transformer_class = get_transformer_for_resolution(config['forecast_resolution_minutes'])\r\n-            return transformer_class(config)\r\n+    def register(cls, model_type: ModelType):\r\n+        \"\"\"\r\n+        Class method decorator for registering model implementations.\r\n         \r\n-        return cls._registry.create_model(model_type, config)\r\n+        Usage:\r\n+            @ModelFactory.register(ModelType.LINEAR_REGRESSION)\r\n+            class LinearRegression(BaseModel):\r\n+                ...\r\n+        \r\n+        Args:\r\n+            model_type: The type of model to register\r\n+            \r\n+        Returns:\r\n+            A decorator function that registers the model class\r\n+        \"\"\"\r\n+        def decorator(model_class: Type[BaseModel]) -> Type[BaseModel]:\r\n+            # Register the model class with validation\r\n+            if not issubclass(model_class, BaseModel):\r\n+                raise TypeError(f\"Model class {model_class.__name__} must inherit from BaseModel\")\r\n+            cls._registry.register_model(model_type, model_class)\r\n+            return model_class\r\n+        return decorator\r\n \r\n     @classmethod\r\n-    def create(cls, model_type: ModelType, config: Dict[str, Any], wrapper_type: Optional[str] = None) -> WrapperInterface:\r\n-        \"\"\"Create a wrapped model instance.\r\n+    def create_base_model(cls, model_type: ModelType, config: Dict[str, Any]) -> BaseModel:\r\n+        \"\"\"\r\n+        Create a raw model instance based on type and configuration.\r\n         \r\n         Args:\r\n             model_type: Type of model to create\r\n+            config: Configuration dictionary for model initialization\r\n+            \r\n+        Returns:\r\n+            Instantiated BaseModel\r\n+            \r\n+        Raises:\r\n+            ValueError: If model type is unknown or configuration is invalid\r\n+        \"\"\"\r\n+        try:\r\n+            # Handle resolution-specific transformer types\r\n+            if model_type in {\r\n+                ModelType.SUBHOURLY_TRANSFORMER,\r\n+                ModelType.HOURLY_TRANSFORMER,\r\n+                ModelType.DAILY_TRANSFORMER,\r\n+                ModelType.MONTHLY_TRANSFORMER\r\n+            }:\r\n+                # Get appropriate transformer class based on resolution\r\n+                transformer_class = get_transformer_for_resolution(config['forecast_resolution_minutes'])\r\n+                return transformer_class(config)\r\n+            \r\n+            # Create standard model from registry\r\n+            return cls._registry.create_model(model_type, config)\r\n+            \r\n+        except KeyError as e:\r\n+            registered_models = cls.get_registered_models()\r\n+            raise ValueError(\r\n+                f\"Failed to create model of type {model_type}. \"\r\n+                f\"Available types: {list(registered_models.keys())}\"\r\n+            ) from e\r\n+        except Exception as e:\r\n+            raise ValueError(f\"Error creating model: {str(e)}\") from e\r\n+\r\n+    @classmethod\r\n+    def create(cls, model_type: ModelType, config: Dict[str, Any], \r\n+               wrapper_type: Optional[str] = None) -> WrapperInterface:\r\n+        \"\"\"\r\n+        Create a wrapped model instance ready for training and inference.\r\n+        \r\n+        Args:\r\n+            model_type: Type of model to create\r\n             config: Model configuration dictionary\r\n-            wrapper_type: Optional wrapper type (defaults to 'pytorch')\r\n+            wrapper_type: Optional wrapper type ('pytorch' or 'sklearn')\r\n+            \r\n+        Returns:\r\n+            Wrapped model instance\r\n+            \r\n+        Raises:\r\n+            ValueError: If configuration or wrapper type is invalid\r\n         \"\"\"\r\n-        base_model = cls.create_base_model(model_type, config)\r\n-\r\n-        if wrapper_type != 'sklearn':\r\n-            return PyTorchWrapper(\r\n-                model=base_model,\r\n+        try:\r\n+            # Create base model\r\n+            base_model = cls.create_base_model(model_type, config)\r\n+            \r\n+            # Choose appropriate wrapper\r\n+            if wrapper_type != 'sklearn':\r\n+                return PyTorchWrapper(\r\n+                    model=base_model,\r\n+                    model_type=model_type,\r\n+                    config=config\r\n+                )\r\n+                \r\n+            # Create sklearn wrapper if requested\r\n+            from models.wrappers.sklearn_wrapper import SklearnWrapper\r\n+            adapter = ModelSklearnAdapter(base_model, model_type, config)\r\n+            return SklearnWrapper(\r\n+                model=adapter,\r\n                 model_type=model_type,\r\n                 config=config\r\n             )\r\n-        from models.wrappers.sklearn_wrapper import SklearnWrapper\r\n-        adapter = ModelSklearnAdapter(base_model, model_type, config)\r\n-        return SklearnWrapper(\r\n-            model=adapter,\r\n-            model_type=model_type,\r\n-            config=config\r\n-        )\r\n+            \r\n+        except Exception as e:\r\n+            raise ValueError(f\"Error creating wrapped model: {str(e)}\") from e\r\n \r\n     @classmethod\r\n     def get_registered_models(cls) -> Dict[ModelType, Type[BaseModel]]:\r\n-        \"\"\"Get all registered model types.\"\"\"\r\n+        \"\"\"Get dictionary of all registered model types and their classes.\"\"\"\r\n         return cls._registry.get_registered_models()\r\n \r\n     @classmethod\r\n     def get_resolution_models(cls) -> Dict[str, ModelType]:\r\n-        \"\"\"Get available resolution-specific model types.\"\"\"\r\n+        \"\"\"Get mapping of resolution names to their model types.\"\"\"\r\n         return {\r\n             'subhourly': ModelType.SUBHOURLY_TRANSFORMER,\r\n             'hourly': ModelType.HOURLY_TRANSFORMER,\r\n             'daily': ModelType.DAILY_TRANSFORMER,\r\n"
                },
                {
                    "date": 1733183564152,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -23,8 +23,17 @@\n \r\n     def predict(self, X):\r\n         return self.model.predict(X)\r\n \r\n+    def partial_fit(self, X, y=None):\r\n+        \"\"\"Incrementally fit the model if supported.\"\"\"\r\n+        if hasattr(self.model, 'partial_fit'):\r\n+            self.model.partial_fit(X, y)\r\n+        else:\r\n+            # Fallback to regular fit if partial_fit is not implemented\r\n+            self.fit(X, y)\r\n+        return self\r\n+\r\n class ModelFactory:\r\n     \"\"\"\r\n     Factory for creating and managing model instances. This class provides centralized\r\n     model creation and registration functionality using a decorator pattern.\r\n"
                }
            ],
            "date": 1733172278210,
            "name": "Commit-0",
            "content": "# models/registry/factory.py\r\nfrom typing import Any, Dict, Type, Callable, Optional\r\n\r\nfrom models.base.base_model import BaseModel\r\nfrom models.wrappers.pytorch_wrapper import PyTorchWrapper\r\nfrom models.architectures.transformers.resolution_specific import (\r\n    get_transformer_for_resolution,\r\n    SubhourlyTransformer,\r\n    HourlyTransformer,\r\n    DailyTransformer,\r\n    MonthlyTransformer\r\n)\r\n\r\nfrom .model_types import ModelType\r\nfrom ..interfaces import WrapperInterface\r\n\r\nclass ModelFactory:\r\n    \"\"\"Factory for creating model instances.\"\"\"\r\n    _registry: Dict[ModelType, Type[BaseModel]] = {}\r\n\r\n    @classmethod\r\n    def register(cls, model_type: ModelType) -> Callable[[Type[BaseModel]], Type[BaseModel]]:\r\n        \"\"\"Register a model in the factory.\"\"\"\r\n        def decorator(model_cls: Type[BaseModel]) -> Type[BaseModel]:\r\n            print(f\"Registering model {model_cls.__name__} for type {model_type}\")\r\n            cls._registry[model_type] = model_cls\r\n            return model_cls\r\n        return decorator\r\n\r\n    @classmethod\r\n    def create_base_model(\r\n        cls,\r\n        model_type: ModelType,\r\n        config: Dict[str, Any]\r\n    ) -> BaseModel:\r\n        \"\"\"Create a raw model instance.\"\"\"\r\n        if not cls._registry:\r\n            print(\"Warning: Model registry is empty. Make sure models are imported and registered.\")\r\n            raise ValueError(\"No models registered in factory\")\r\n        \r\n        # Handle resolution-specific transformer types\r\n        if model_type in {\r\n            ModelType.SUBHOURLY_TRANSFORMER,\r\n            ModelType.HOURLY_TRANSFORMER,\r\n            ModelType.DAILY_TRANSFORMER,\r\n            ModelType.MONTHLY_TRANSFORMER\r\n        }:\r\n            return cls._create_resolution_transformer(model_type, config)\r\n        \r\n        # Handle standard model types\r\n        if model_type not in cls._registry:\r\n            raise ValueError(f\"Unknown model type: {model_type}. Available types: {list(cls._registry.keys())}\")\r\n        \r\n        model_class = cls._registry[model_type]\r\n        return model_class(config)\r\n\r\n    @classmethod\r\n    def _create_resolution_transformer(\r\n        cls,\r\n        model_type: ModelType,\r\n        config: Dict[str, Any]\r\n    ) -> BaseModel:\r\n        \"\"\"Create a resolution-specific transformer instance.\"\"\"\r\n        # Map model type to resolution\r\n        resolution_map = {\r\n            ModelType.SUBHOURLY_TRANSFORMER: 15,  # 15 minutes\r\n            ModelType.HOURLY_TRANSFORMER: 60,     # 1 hour\r\n            ModelType.DAILY_TRANSFORMER: 1440,    # 24 hours\r\n            ModelType.MONTHLY_TRANSFORMER: 43200  # 30 days\r\n        }\r\n        \r\n        resolution = resolution_map[model_type]\r\n        \r\n        # Ensure resolution is set in config\r\n        config['forecast_resolution_minutes'] = resolution\r\n        if 'input_resolution_minutes' not in config:\r\n            config['input_resolution_minutes'] = resolution\r\n        \r\n        # Get appropriate transformer class\r\n        transformer_class = get_transformer_for_resolution(resolution)\r\n        \r\n        # Create and return transformer instance\r\n        return transformer_class(config)\r\n\r\n    @classmethod\r\n    def create(\r\n        cls,\r\n        model_type: ModelType,\r\n        config: Dict[str, Any],\r\n        wrapper_type: Optional[str] = None\r\n    ) -> WrapperInterface:\r\n        \"\"\"Create a wrapped model instance.\r\n        \r\n        Args:\r\n            model_type: Type of model to create\r\n            config: Model configuration dictionary\r\n            wrapper_type: Optional wrapper type (defaults to 'pytorch')\r\n        \"\"\"\r\n        base_model = cls.create_base_model(model_type, config)\r\n\r\n        # Determine appropriate wrapper\r\n        if wrapper_type == 'sklearn':\r\n            from models.wrappers.sklearn_wrapper import SklearnWrapper\r\n            return SklearnWrapper(\r\n                model=base_model,\r\n                model_type=model_type,\r\n                config=config\r\n            )\r\n        else:  # Default to PyTorch wrapper\r\n            return PyTorchWrapper(\r\n                model=base_model,\r\n                model_type=model_type,\r\n                config=config\r\n            )\r\n\r\n    @classmethod\r\n    def get_registered_models(cls) -> Dict[ModelType, Type[BaseModel]]:\r\n        \"\"\"Get all registered model types.\"\"\"\r\n        return cls._registry.copy()\r\n\r\n    @classmethod\r\n    def get_resolution_models(cls) -> Dict[str, ModelType]:\r\n        \"\"\"Get available resolution-specific model types.\"\"\"\r\n        return {\r\n            'subhourly': ModelType.SUBHOURLY_TRANSFORMER,\r\n            'hourly': ModelType.HOURLY_TRANSFORMER,\r\n            'daily': ModelType.DAILY_TRANSFORMER,\r\n            'monthly': ModelType.MONTHLY_TRANSFORMER\r\n        }"
        }
    ]
}