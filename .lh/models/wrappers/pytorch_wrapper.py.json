{
    "sourceFile": "models/wrappers/pytorch_wrapper.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 13,
            "patches": [
                {
                    "date": 1733261789213,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1733261986024,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,10 +1,9 @@\n-# models/wrappers/pytorch_wrapper.py\r\n-\r\n from __future__ import annotations\r\n import os\r\n from pathlib import Path\r\n from typing import Union, Any, Dict, List, Optional, Tuple, Type, cast\r\n+from contextlib import nullcontext\r\n import torch\r\n from torch import nn\r\n from os import PathLike\r\n from torch.optim.adam import Adam\r\n@@ -12,12 +11,11 @@\n from torch.optim.sgd import SGD\r\n from torch.optim.rmsprop import RMSprop\r\n from torch.optim import lr_scheduler\r\n from torch.optim.optimizer import Optimizer\r\n-from torch.utils.data import Dataset as TorchDataset  # Rename to avoid conflict\r\n+from torch.utils.data import Dataset as TorchDataset\r\n from torch.utils.data import DataLoader\r\n-from torch.cuda.amp import GradScaler, autocast\r\n-import gc\r\n+import torch.amp as amp  # Updated import for modern AMP\r\n \r\n from models.losses.custom_losses import MAPE\r\n from training.base.base_trainer import TrainingEpoch\r\n from training.reports.training_report import TrainingReport\r\n@@ -45,14 +43,20 @@\n         self.model = model\r\n         self.model_type = model_type\r\n         self.config = config\r\n \r\n-        # Device handling\r\n-        self.device = torch.device(\r\n-            config.get('device', 'cuda' if torch.cuda.is_available() else 'cpu')\r\n-        )\r\n+        # Device handling with improved CUDA settings\r\n+        self.device = torch.device(config.get('device', 'cuda' if torch.cuda.is_available() else 'cpu'))\r\n+        if self.device.type == 'cuda':\r\n+            # Enable TF32 for better performance on Ampere GPUs (like RTX 4060)\r\n+            torch.backends.cuda.matmul.allow_tf32 = True\r\n+            torch.backends.cudnn.allow_tf32 = True\r\n+            # Enable cuDNN autotuner\r\n+            torch.backends.cudnn.benchmark = True\r\n+            \r\n         logger.info(f\"Using device: {self.device}\")\r\n         logger.debug(f\"CUDA available: {torch.cuda.is_available()}\")\r\n+        \r\n         if torch.cuda.is_available():\r\n             logger.debug(f\"CUDA device count: {torch.cuda.device_count()}\")\r\n             logger.debug(f\"Current CUDA device: {torch.cuda.current_device()}\")\r\n \r\n@@ -60,47 +64,33 @@\n         self.model = self.model.to(self.device)\r\n         logger.debug(f\"Model device after moving: {next(self.model.parameters()).device}\")\r\n \r\n         # Training configuration\r\n-        self.batch_size = config.get('batch_size', 32)\r\n+        self.batch_size = config.get('batch_size', 128)  # Increased for RTX 4060\r\n         self.learning_rate = config.get('learning_rate', 1e-3)\r\n         self.max_epochs = config.get('max_epochs', 100)\r\n         self.gradient_clip_val = config.get('gradient_clip_val', 1.0)\r\n-        self.accumulation_steps = config.get('accumulation_steps', 1)  # For gradient accumulation\r\n+        self.accumulation_steps = config.get('accumulation_steps', 4)\r\n \r\n         # Setup optimizer and criterion\r\n         self.optimizer = self._setup_optimizer()\r\n         self.criterion = self._setup_criterion()\r\n \r\n-        # Setup scheduler\r\n-        self.scheduler = None  # Will be initialized in train()\r\n-\r\n-        # Initialize GradScaler for mixed precision\r\n-        self.use_mixed_precision = config.get('use_mixed_precision', True)\r\n-        if self.use_mixed_precision:\r\n-            self.scaler = amp.GradScaler()\r\n-            self.autocast = torch.amp.autocast('cuda', enabled=True)\r\n+        # Initialize modern AMP (Automatic Mixed Precision)\r\n+        self.use_amp = config.get('use_mixed_precision', True) and self.device.type == 'cuda'\r\n+        if self.use_amp:\r\n+            self.grad_scaler = amp.GradScaler('cuda')  # Modern GradScaler initialization\r\n+            self.autocast = amp.autocast(device_type='cuda', dtype=torch.float16)\r\n         else:\r\n-            self.scaler = None\r\n-            self.autocast = None\r\n+            self.grad_scaler = None\r\n+            self.autocast = nullcontext()\r\n \r\n-        # Optimized batch and memory settings\r\n-        self.batch_size = config.get('batch_size', 128)  # Increased for RTX 4060\r\n-        self.accumulation_steps = config.get('accumulation_steps', 4)  # Added gradient accumulation\r\n-        self.prefetch_factor = config.get('prefetch_factor', 2)\r\n-        \r\n-        # Memory optimization settings\r\n-        self.empty_cache_frequency = config.get('empty_cache_frequency', 100)\r\n-        self.max_memory_allocated = 0.0\r\n-        \r\n-        # Configure optimizer with larger batch size\r\n-        self.learning_rate = config.get('learning_rate', 2e-4)  # Adjusted for larger batch size\r\n-        \r\n-        if torch.cuda.is_available():\r\n-            # Set memory allocator settings for better efficiency\r\n+        # Memory management settings\r\n+        if self.device.type == 'cuda':\r\n+            # Set memory allocator settings for RTX 4060 (8GB VRAM)\r\n             torch.cuda.set_per_process_memory_fraction(0.95)  # Use 95% of available VRAM\r\n-            torch.backends.cudnn.benchmark = True  # Enable cuDNN autotuner\r\n-            torch.backends.cuda.matmul.allow_tf32 = True  # Enable TF32 for faster training\r\n+            self.empty_cache_frequency = config.get('empty_cache_frequency', 100)\r\n+            self.max_memory_allocated = 0.0\r\n \r\n     def _setup_scheduler(self, train_loader: DataLoader) -> Optional[Union[LRScheduler, ReduceLROnPlateau]]:\r\n         \"\"\"Initialize learning rate scheduler with improved defaults.\"\"\"\r\n         scheduler_name = self.config.get('scheduler', 'one_cycle').lower()\r\n"
                },
                {
                    "date": 1733262107051,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -90,8 +90,24 @@\n             torch.cuda.set_per_process_memory_fraction(0.95)  # Use 95% of available VRAM\r\n             self.empty_cache_frequency = config.get('empty_cache_frequency', 100)\r\n             self.max_memory_allocated = 0.0\r\n \r\n+    def _setup_data_loader(self, dataset: TorchDataset, shuffle: bool = True) -> DataLoader:\r\n+        \"\"\"Create an optimized DataLoader for GPU training.\"\"\"\r\n+        cpu_count = os.cpu_count() or 4\r\n+        num_workers = min(4, cpu_count // 2)  # Optimized for 32GB RAM\r\n+        \r\n+        return DataLoader(\r\n+            dataset,\r\n+            batch_size=self.batch_size,\r\n+            shuffle=shuffle,\r\n+            num_workers=num_workers,\r\n+            pin_memory=True,\r\n+            persistent_workers=True,\r\n+            prefetch_factor=2,\r\n+            pin_memory_device='cuda' if self.device.type == 'cuda' else None\r\n+        )\r\n+        \r\n     def _setup_scheduler(self, train_loader: DataLoader) -> Optional[Union[LRScheduler, ReduceLROnPlateau]]:\r\n         \"\"\"Initialize learning rate scheduler with improved defaults.\"\"\"\r\n         scheduler_name = self.config.get('scheduler', 'one_cycle').lower()\r\n         scheduler_config = self.config.get('scheduler_config', {})\r\n"
                },
                {
                    "date": 1733262420784,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,547 @@\n+from __future__ import annotations\r\n+import os\r\n+from pathlib import Path\r\n+from typing import Union, Any, Dict, List, Optional, Tuple, Type, cast\r\n+from contextlib import nullcontext\r\n+import torch\r\n+from torch import nn\r\n+from os import PathLike\r\n+from torch.optim.adam import Adam\r\n+from torch.optim.adamw import AdamW\r\n+from torch.optim.sgd import SGD\r\n+from torch.optim.rmsprop import RMSprop\r\n+from torch.optim import lr_scheduler\r\n+from torch.optim.optimizer import Optimizer\r\n+from torch.utils.data import Dataset as TorchDataset\r\n+from torch.utils.data import DataLoader\r\n+from torch.cuda.amp import autocast, GradScaler\r\n+\r\n+\r\n+from models.losses.custom_losses import MAPE\r\n+from training.base.base_trainer import TrainingEpoch\r\n+from training.reports.training_report import TrainingReport\r\n+\r\n+from ..interfaces import WrapperInterface\r\n+from ..base.base_model import BaseModel\r\n+from ..registry.model_types import ModelType\r\n+from torch.optim.lr_scheduler import (\r\n+    OneCycleLR,\r\n+    CosineAnnealingLR,\r\n+    ReduceLROnPlateau,\r\n+    _LRScheduler,\r\n+    LRScheduler\r\n+)\r\n+\r\n+from utils.logging.logger import Logger\r\n+\r\n+# Get module logger\r\n+logger = Logger.get_logger(__name__)\r\n+\r\n+class PyTorchWrapper(WrapperInterface):\r\n+    \"\"\"Wrapper for PyTorch models providing consistent training and inference interface.\"\"\"\r\n+\r\n+    def __init__(self, model: BaseModel, model_type: ModelType, config: Dict[str, Any]):\r\n+        self.model = model\r\n+        self.model_type = model_type\r\n+        self.config = config\r\n+\r\n+        # Device handling with improved CUDA settings\r\n+        self.device = torch.device(config.get('device', 'cuda' if torch.cuda.is_available() else 'cpu'))\r\n+        if self.device.type == 'cuda':\r\n+            # Enable TF32 for better performance on Ampere GPUs (like RTX 4060)\r\n+            torch.backends.cuda.matmul.allow_tf32 = True\r\n+            torch.backends.cudnn.allow_tf32 = True\r\n+            # Enable cuDNN autotuner\r\n+            torch.backends.cudnn.benchmark = True\r\n+            \r\n+        logger.info(f\"Using device: {self.device}\")\r\n+        logger.debug(f\"CUDA available: {torch.cuda.is_available()}\")\r\n+        \r\n+        if torch.cuda.is_available():\r\n+            logger.debug(f\"CUDA device count: {torch.cuda.device_count()}\")\r\n+            logger.debug(f\"Current CUDA device: {torch.cuda.current_device()}\")\r\n+\r\n+        # Move model to device\r\n+        self.model = self.model.to(self.device)\r\n+        logger.debug(f\"Model device after moving: {next(self.model.parameters()).device}\")\r\n+\r\n+        # Training configuration\r\n+        self.batch_size = config.get('batch_size', 128)  # Increased for RTX 4060\r\n+        self.learning_rate = config.get('learning_rate', 1e-3)\r\n+        self.max_epochs = config.get('max_epochs', 100)\r\n+        self.gradient_clip_val = config.get('gradient_clip_val', 1.0)\r\n+        self.accumulation_steps = config.get('accumulation_steps', 4)\r\n+\r\n+        # Setup optimizer and criterion\r\n+        self.optimizer = self._setup_optimizer()\r\n+        self.criterion = self._setup_criterion()\r\n+\r\n+        # Initialize modern AMP (Automatic Mixed Precision)\r\n+        self.use_amp = config.get('use_mixed_precision', True) and self.device.type == 'cuda'\r\n+        if self.use_amp:\r\n+            self.grad_scaler = amp.GradScaler('cuda')  # Modern GradScaler initialization\r\n+            self.autocast = amp.autocast(device_type='cuda', dtype=torch.float16)\r\n+        else:\r\n+            self.grad_scaler = None\r\n+            self.autocast = nullcontext()\r\n+\r\n+        # Memory management settings\r\n+        if self.device.type == 'cuda':\r\n+            # Set memory allocator settings for RTX 4060 (8GB VRAM)\r\n+            torch.cuda.set_per_process_memory_fraction(0.95)  # Use 95% of available VRAM\r\n+            self.empty_cache_frequency = config.get('empty_cache_frequency', 100)\r\n+            self.max_memory_allocated = 0.0\r\n+\r\n+    def _setup_data_loader(self, dataset: TorchDataset, shuffle: bool = True) -> DataLoader:\r\n+        \"\"\"Create an optimized DataLoader for GPU training.\"\"\"\r\n+        cpu_count = os.cpu_count() or 4\r\n+        num_workers = min(4, cpu_count // 2)  # Optimized for 32GB RAM\r\n+        \r\n+        return DataLoader(\r\n+            dataset,\r\n+            batch_size=self.batch_size,\r\n+            shuffle=shuffle,\r\n+            num_workers=num_workers,\r\n+            pin_memory=True,\r\n+            persistent_workers=True,\r\n+            prefetch_factor=2,\r\n+            pin_memory_device='cuda' if self.device.type == 'cuda' else None\r\n+        )\r\n+        \r\n+    def _setup_scheduler(self, train_loader: DataLoader) -> Optional[Union[LRScheduler, ReduceLROnPlateau]]:\r\n+        \"\"\"Initialize learning rate scheduler with improved defaults.\"\"\"\r\n+        scheduler_name = self.config.get('scheduler', 'one_cycle').lower()\r\n+        scheduler_config = self.config.get('scheduler_config', {})\r\n+\r\n+        if scheduler_name == 'one_cycle':\r\n+            total_steps = self.max_epochs * len(train_loader)\r\n+            steps_per_epoch = len(train_loader)\r\n+\r\n+            return cast(LRScheduler, OneCycleLR(\r\n+                self.optimizer,\r\n+                max_lr=self.learning_rate,\r\n+                total_steps=total_steps,\r\n+                epochs=self.max_epochs,\r\n+                steps_per_epoch=steps_per_epoch,\r\n+                pct_start=scheduler_config.get('pct_start', 0.3),\r\n+                div_factor=scheduler_config.get('div_factor', 25.0),\r\n+                final_div_factor=scheduler_config.get('final_div_factor', 1000.0),\r\n+                anneal_strategy=scheduler_config.get('anneal_strategy', 'cos')\r\n+            ))\r\n+\r\n+        elif scheduler_name == 'cosine':\r\n+            return cast(LRScheduler, CosineAnnealingLR(\r\n+                self.optimizer,\r\n+                T_max=self.max_epochs,\r\n+                eta_min=scheduler_config.get('eta_min', 1e-6)\r\n+            ))\r\n+\r\n+        elif scheduler_name == 'plateau':\r\n+            return ReduceLROnPlateau(\r\n+                self.optimizer,\r\n+                mode='min',\r\n+                factor=scheduler_config.get('factor', 0.5),\r\n+                patience=scheduler_config.get('patience', 5),\r\n+                min_lr=scheduler_config.get('min_lr', 1e-6)\r\n+            )\r\n+\r\n+        elif scheduler_name == 'cosineannealinglr':\r\n+            return cast(LRScheduler, CosineAnnealingLR(\r\n+                self.optimizer,\r\n+                T_max=self.max_epochs,\r\n+                eta_min=scheduler_config.get('eta_min', 1e-6)\r\n+            ))\r\n+\r\n+        elif scheduler_name == 'steplr':\r\n+            return cast(LRScheduler, lr_scheduler.StepLR(\r\n+                self.optimizer,\r\n+                step_size=scheduler_config.get('step_size', 10),\r\n+                gamma=scheduler_config.get('gamma', 0.1)\r\n+            ))\r\n+\r\n+        else:\r\n+            logger.warning(f\"Unknown scheduler: {scheduler_name}. No scheduler will be used.\")\r\n+            return None\r\n+\r\n+    def _setup_optimizer(self) -> Optimizer:\r\n+        \"\"\"Initialize optimizer with improved defaults.\"\"\"\r\n+        optimizer_name = self.config.get('optimizer', 'adamw').lower()\r\n+        optimizer_config = self.config.get('optimizer_config', {})\r\n+\r\n+        # Base parameters all optimizers support\r\n+        base_params = {\r\n+            'lr': self.learning_rate,\r\n+            'weight_decay': optimizer_config.get('weight_decay', 0.01)  # Updated default\r\n+        }\r\n+\r\n+        # Create optimizer with appropriate parameters\r\n+        if optimizer_name == 'sgd':\r\n+            sgd_params = {\r\n+                'momentum': optimizer_config.get('momentum', 0.9),\r\n+                'dampening': optimizer_config.get('dampening', 0),\r\n+                'nesterov': optimizer_config.get('nesterov', True)  # Enable Nesterov by default\r\n+            }\r\n+            return SGD(self.model.parameters(), **base_params, **sgd_params)\r\n+\r\n+        elif optimizer_name == 'adam':\r\n+            adam_params = {\r\n+                'betas': optimizer_config.get('betas', (0.9, 0.98)),  # Updated for transformer\r\n+                'eps': optimizer_config.get('eps', 1e-8),\r\n+                'amsgrad': optimizer_config.get('amsgrad', False)  # Typically False\r\n+            }\r\n+            return Adam(self.model.parameters(), **base_params, **adam_params)\r\n+\r\n+        elif optimizer_name == 'adamw':\r\n+            adamw_params = {\r\n+                'betas': optimizer_config.get('betas', (0.9, 0.98)),  # Updated for transformer\r\n+                'eps': optimizer_config.get('eps', 1e-8),\r\n+                'amsgrad': optimizer_config.get('amsgrad', False)  # Typically False\r\n+            }\r\n+            return AdamW(self.model.parameters(), **base_params, **adamw_params)\r\n+\r\n+        elif optimizer_name == 'rmsprop':\r\n+            rmsprop_params = {\r\n+                'alpha': optimizer_config.get('alpha', 0.99),\r\n+                'eps': optimizer_config.get('eps', 1e-8),\r\n+                'momentum': optimizer_config.get('momentum', 0.9),\r\n+                'centered': optimizer_config.get('centered', False)\r\n+            }\r\n+            return RMSprop(self.model.parameters(), **base_params, **rmsprop_params)\r\n+\r\n+        else:\r\n+            raise ValueError(f\"Unknown optimizer: {optimizer_name}\")\r\n+\r\n+    def _setup_criterion(self) -> nn.Module:\r\n+        \"\"\"Initialize loss function based on config.\"\"\"\r\n+        criterion_name = self.config.get('criterion', 'mse').lower()\r\n+        criterion_config = self.config.get('criterion_config', {})\r\n+\r\n+        criteria: Dict[str, nn.Module] = {\r\n+            'mse': nn.MSELoss(**criterion_config),\r\n+            'mae': nn.L1Loss(**criterion_config),\r\n+            'mape': MAPE(**criterion_config)\r\n+        }\r\n+\r\n+        if criterion_name not in criteria:\r\n+            raise ValueError(f\"Unknown criterion: {criterion_name}\")\r\n+\r\n+        return criteria[criterion_name]\r\n+\r\n+    def train(self, train_dataset: TorchDataset, validation_dataset: Optional[TorchDataset] = None) -> TrainingReport:\r\n+        \"\"\"Train the model with modern mixed precision and memory optimization.\"\"\"\r\n+        logger.info(\"Starting training\")\r\n+        \r\n+        # Clear GPU cache before training\r\n+        if self.device.type == 'cuda':\r\n+            torch.cuda.empty_cache()\r\n+            logger.debug(f\"Initial GPU memory allocated: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\r\n+        \r\n+        self.train_loader = self._setup_data_loader(train_dataset, shuffle=True)\r\n+        val_loader = self._setup_data_loader(validation_dataset, shuffle=False) if validation_dataset else None\r\n+\r\n+        # Initialize scheduler\r\n+        self.scheduler = self._setup_scheduler(self.train_loader)\r\n+\r\n+        # Training state\r\n+        train_losses = []\r\n+        val_losses = []\r\n+        learning_rates = []\r\n+        best_val_loss = float('inf')\r\n+        patience_counter = 0\r\n+        early_stopping_patience = self.config.get('early_stopping_patience', 10)\r\n+\r\n+        for epoch in range(1, self.max_epochs + 1):\r\n+            self.model.train()\r\n+            epoch_loss = 0.0\r\n+            num_batches = 0\r\n+\r\n+            for batch_idx, (data, target) in enumerate(self.train_loader):\r\n+                try:\r\n+                    # Move data to device efficiently\r\n+                    if isinstance(data, tuple):\r\n+                        data = tuple(d.to(self.device, non_blocking=True) for d in data)\r\n+                    else:\r\n+                        data = data.to(self.device, non_blocking=True)\r\n+                    target = target.to(self.device, non_blocking=True)\r\n+\r\n+                    # Forward pass with automatic mixed precision\r\n+                    with self.autocast:\r\n+                        outputs = self.model(data)\r\n+                        loss = self.criterion(outputs, target)\r\n+                        loss = loss / self.accumulation_steps\r\n+\r\n+                    # Backward pass with gradient scaling\r\n+                    if self.use_amp:\r\n+                        self.grad_scaler.scale(loss).backward()\r\n+                    else:\r\n+                        loss.backward()\r\n+\r\n+                    # Gradient accumulation step\r\n+                    if (batch_idx + 1) % self.accumulation_steps == 0:\r\n+                        if self.gradient_clip_val > 0:\r\n+                            if self.use_amp:\r\n+                                self.grad_scaler.unscale_(self.optimizer)\r\n+                            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.gradient_clip_val)\r\n+\r\n+                        # Optimizer step with modern AMP\r\n+                        if self.use_amp:\r\n+                            self.grad_scaler.step(self.optimizer)\r\n+                            self.grad_scaler.update()\r\n+                        else:\r\n+                            self.optimizer.step()\r\n+\r\n+                        self.optimizer.zero_grad(set_to_none=True)\r\n+\r\n+                    # Memory management for RTX 4060\r\n+                    if self.device.type == 'cuda' and batch_idx % self.empty_cache_frequency == 0:\r\n+                        current_memory = torch.cuda.memory_allocated() / 1024**3\r\n+                        self.max_memory_allocated = max(self.max_memory_allocated, current_memory)\r\n+                        \r\n+                        if current_memory > 7.0:  # Conservative threshold for 8GB VRAM\r\n+                            torch.cuda.empty_cache()\r\n+\r\n+                    epoch_loss += loss.item() * self.accumulation_steps\r\n+                    num_batches += 1\r\n+\r\n+                except RuntimeError as e:\r\n+                    logger.error(f\"Error in batch {batch_idx}: {str(e)}\")\r\n+                    if \"out of memory\" in str(e):\r\n+                        torch.cuda.empty_cache()\r\n+                    continue\r\n+\r\n+            # Calculate average loss and update metrics\r\n+            avg_train_loss = epoch_loss / num_batches if num_batches > 0 else float('inf')\r\n+            train_losses.append(avg_train_loss)\r\n+            current_lr = self.optimizer.param_groups[0]['lr']\r\n+            learning_rates.append(current_lr)\r\n+\r\n+            # Validation phase\r\n+            if val_loader:\r\n+                val_loss = self._validate(val_loader)\r\n+                val_losses.append(val_loss)\r\n+\r\n+                # Early stopping logic\r\n+                if val_loss < best_val_loss:\r\n+                    best_val_loss = val_loss\r\n+                    patience_counter = 0\r\n+                    self.save('best_model.pth')\r\n+                else:\r\n+                    patience_counter += 1\r\n+                    if patience_counter >= early_stopping_patience:\r\n+                        logger.info(f\"Early stopping triggered after epoch {epoch}\")\r\n+                        break\r\n+\r\n+            # Scheduler step\r\n+            if self.scheduler:\r\n+                if isinstance(self.scheduler, ReduceLROnPlateau):\r\n+                    self.scheduler.step(val_loss if val_loader else avg_train_loss)\r\n+                else:\r\n+                    self.scheduler.step()\r\n+\r\n+            # Log progress\r\n+            logger.info(\r\n+                f\"Epoch {epoch}/{self.max_epochs} - \"\r\n+                f\"Train Loss: {avg_train_loss:.6f}\"\r\n+                + (f\", Val Loss: {val_loss:.6f}\" if val_loader else \"\")\r\n+                + f\" - LR: {current_lr:.6f}\"\r\n+            )\r\n+\r\n+        return TrainingReport(\r\n+            train_losses=train_losses,\r\n+            val_losses=val_losses,\r\n+            learning_rates=learning_rates,\r\n+            epochs=epoch,\r\n+            additional_metrics={'best_val_loss': best_val_loss}\r\n+        )\r\n+        \r\n+        \r\n+    def _validate(self, val_loader: DataLoader) -> float:\r\n+        \"\"\"Validate the model.\"\"\"\r\n+        self.model.eval()\r\n+        val_loss = 0.0\r\n+        num_batches = 0\r\n+\r\n+        with torch.no_grad():\r\n+            for data, target in val_loader:\r\n+                try:\r\n+                    # Move data to device\r\n+                    if isinstance(data, tuple):\r\n+                        data = tuple(d.to(self.device, non_blocking=True) for d in data)\r\n+                    else:\r\n+                        data = data.to(self.device, non_blocking=True)\r\n+                    target = target.to(self.device, non_blocking=True)\r\n+\r\n+                    # Forward pass with autocast if using mixed precision\r\n+                    if self.scaler:\r\n+                        with autocast():\r\n+                            outputs = self.model(data)\r\n+                            loss = self.criterion(outputs, target)\r\n+                    else:\r\n+                        outputs = self.model(data)\r\n+                        loss = self.criterion(outputs, target)\r\n+\r\n+                    val_loss += loss.item()\r\n+                    num_batches += 1\r\n+\r\n+                except RuntimeError as e:\r\n+                    logger.error(f\"Runtime error during validation: {str(e)}\")\r\n+                    torch.cuda.empty_cache()\r\n+                    continue  # Skip this batch\r\n+\r\n+        avg_val_loss = val_loss / num_batches if num_batches > 0 else float('inf')\r\n+        return avg_val_loss\r\n+\r\n+    def predict(self, dataset: TorchDataset) -> Tuple[torch.Tensor, torch.Tensor]:\r\n+        \"\"\"Make predictions using the model.\"\"\"\r\n+        data_loader = DataLoader(\r\n+            dataset, \r\n+            batch_size=self.batch_size,\r\n+            num_workers=min(8, (os.cpu_count() or 4) // 2),\r\n+            pin_memory=torch.cuda.is_available(),\r\n+            shuffle=False,\r\n+            persistent_workers=True,\r\n+            prefetch_factor=4\r\n+        )\r\n+\r\n+        self.model.eval()\r\n+        predictions: List[torch.Tensor] = []\r\n+        targets: List[torch.Tensor] = []\r\n+\r\n+        with torch.no_grad():\r\n+            for data, target in data_loader:\r\n+                try:\r\n+                    # Move data to device\r\n+                    if isinstance(data, tuple):\r\n+                        data = tuple(d.to(self.device, non_blocking=True) for d in data)\r\n+                    else:\r\n+                        data = data.to(self.device, non_blocking=True)\r\n+                    target = target.to(self.device, non_blocking=True)\r\n+\r\n+                    # Forward pass with autocast if using mixed precision\r\n+                    if self.scaler:\r\n+                        with autocast():\r\n+                            output = self.model(data)\r\n+                    else:\r\n+                        output = self.model(data)\r\n+\r\n+                    predictions.append(output.cpu())\r\n+                    targets.append(target.cpu())\r\n+\r\n+                except RuntimeError as e:\r\n+                    logger.error(f\"Runtime error during prediction: {str(e)}\")\r\n+                    torch.cuda.empty_cache()\r\n+                    continue  # Skip this batch\r\n+\r\n+        return torch.cat(predictions), torch.cat(targets)\r\n+\r\n+    def save(self, path: Union[str, Path]) -> None:\r\n+        \"\"\"Save model state.\"\"\"\r\n+        torch.save({\r\n+            'model_state_dict': self.model.state_dict(),\r\n+            'optimizer_state_dict': self.optimizer.state_dict(),\r\n+            'scheduler_state_dict': self.scheduler.state_dict() if self.scheduler else None,\r\n+            'scaler_state_dict': self.scaler.state_dict() if self.scaler else None,\r\n+            'config': self.config\r\n+        }, path)\r\n+        logger.info(f\"Model saved to {path}\")\r\n+\r\n+    def load(self, path: Union[str, Path]) -> None:\r\n+        \"\"\"Load model state.\"\"\"\r\n+        checkpoint = torch.load(path, map_location=self.device)\r\n+        self.model.load_state_dict(checkpoint['model_state_dict'])\r\n+        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\r\n+        if self.scheduler and checkpoint.get('scheduler_state_dict'):\r\n+            self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\r\n+        if self.scaler and checkpoint.get('scaler_state_dict'):\r\n+            self.scaler.load_state_dict(checkpoint['scaler_state_dict'])\r\n+        logger.info(f\"Model loaded from {path}\")\r\n+\r\n+    def training_step(\r\n+        self,\r\n+        batch_input: Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]],\r\n+        batch_target: torch.Tensor,\r\n+        **kwargs\r\n+    ) -> float:\r\n+        \"\"\"Process a single training batch with optimized GPU handling.\"\"\"\r\n+        self.optimizer.zero_grad()\r\n+        \r\n+        try:\r\n+            # Handle transformer models\r\n+            if self.model_type.is_transformer and isinstance(batch_input, tuple):\r\n+                src, tgt = batch_input\r\n+                # Use masks from kwargs if provided, else generate\r\n+                src_mask = kwargs.get('src_mask', self.model.generate_square_subsequent_mask(src.size(1)).to(self.device))\r\n+                tgt_mask = kwargs.get('tgt_mask', self.model.generate_square_subsequent_mask(tgt.size(1)).to(self.device))\r\n+                \r\n+                output = self.model(src, tgt, src_mask=src_mask, tgt_mask=tgt_mask)\r\n+            else:\r\n+                if isinstance(batch_input, tuple):\r\n+                    batch_input = batch_input[0]\r\n+                output = self.model(batch_input)\r\n+            \r\n+            loss = self.criterion(output, batch_target)\r\n+            loss.backward()\r\n+            \r\n+            # Gradient clipping\r\n+            if self.gradient_clip_val > 0:\r\n+                torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.gradient_clip_val)\r\n+                \r\n+            self.optimizer.step()\r\n+            \r\n+            return loss.item()\r\n+                \r\n+        except RuntimeError as e:\r\n+            logger.error(f\"Training step failed: {str(e)}\")\r\n+            logger.debug(\"Device mapping:\")\r\n+            logger.debug(f\"Model: {next(self.model.parameters()).device}\")\r\n+            if isinstance(batch_input, tuple):\r\n+                logger.debug(f\"Input tensors: {[b.device for b in batch_input]}\")\r\n+            else:\r\n+                logger.debug(f\"Input tensor: {batch_input.device}\")\r\n+            logger.debug(f\"Target tensor: {batch_target.device}\")\r\n+            raise\r\n+\r\n+    def validation_step(\r\n+        self,\r\n+        batch_input: Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]],\r\n+        batch_target: torch.Tensor,\r\n+        **kwargs\r\n+    ) -> float:\r\n+        \"\"\"Process a single validation batch.\r\n+        \r\n+        Args:\r\n+            batch_input: Input tensor or tuple of tensors\r\n+            batch_target: Target tensor\r\n+            **kwargs: Additional arguments like masks for transformers\r\n+            \r\n+        Returns:\r\n+            float: Loss value for this batch\r\n+        \"\"\"\r\n+        try:\r\n+            with torch.no_grad():\r\n+                # Handle transformer models\r\n+                if self.model_type.is_transformer and isinstance(batch_input, tuple):\r\n+                    src, tgt = batch_input\r\n+                    # Use masks from kwargs if provided, else generate\r\n+                    src_mask = kwargs.get('src_mask', self.model.generate_square_subsequent_mask(src.size(1)).to(self.device))\r\n+                    tgt_mask = kwargs.get('tgt_mask', self.model.generate_square_subsequent_mask(tgt.size(1)).to(self.device))\r\n+                    \r\n+                    output = self.model(src, tgt, src_mask=src_mask, tgt_mask=tgt_mask)\r\n+                else:\r\n+                    if isinstance(batch_input, tuple):\r\n+                        batch_input = batch_input[0]\r\n+                    output = self.model(batch_input)\r\n+                \r\n+                loss = self.criterion(output, batch_target)\r\n+                return loss.item()\r\n+                \r\n+        except RuntimeError as e:\r\n+            logger.error(f\"Validation step failed: {str(e)}\")\r\n+            logger.debug(\"Device mapping:\")\r\n+            logger.debug(f\"Model: {next(self.model.parameters()).device}\")\r\n+            if isinstance(batch_input, tuple):\r\n+                logger.debug(f\"Input tensors: {[b.device for b in batch_input]}\")\r\n+            else:\r\n+                logger.debug(f\"Input tensor: {batch_input.device}\")\r\n+            logger.debug(f\"Target tensor: {batch_target.device}\")\r\n+            raise\r\n"
                },
                {
                    "date": 1733262433548,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -544,606 +544,4 @@\n             else:\r\n                 logger.debug(f\"Input tensor: {batch_input.device}\")\r\n             logger.debug(f\"Target tensor: {batch_target.device}\")\r\n             raise\r\n-from __future__ import annotations\r\n-import os\r\n-from pathlib import Path\r\n-from typing import Union, Any, Dict, List, Optional, Tuple, Type, cast\r\n-from contextlib import nullcontext\r\n-import torch\r\n-from torch import nn\r\n-from os import PathLike\r\n-from torch.optim.adam import Adam\r\n-from torch.optim.adamw import AdamW\r\n-from torch.optim.sgd import SGD\r\n-from torch.optim.rmsprop import RMSprop\r\n-from torch.optim import lr_scheduler\r\n-from torch.optim.optimizer import Optimizer\r\n-from torch.utils.data import Dataset as TorchDataset\r\n-from torch.utils.data import DataLoader\r\n-import torch.amp as amp  # Updated import for modern AMP\r\n-\r\n-from models.losses.custom_losses import MAPE\r\n-from training.base.base_trainer import TrainingEpoch\r\n-from training.reports.training_report import TrainingReport\r\n-\r\n-from ..interfaces import WrapperInterface\r\n-from ..base.base_model import BaseModel\r\n-from ..registry.model_types import ModelType\r\n-from torch.optim.lr_scheduler import (\r\n-    OneCycleLR,\r\n-    CosineAnnealingLR,\r\n-    ReduceLROnPlateau,\r\n-    _LRScheduler,\r\n-    LRScheduler\r\n-)\r\n-\r\n-from utils.logging.logger import Logger\r\n-\r\n-# Get module logger\r\n-logger = Logger.get_logger(__name__)\r\n-\r\n-class PyTorchWrapper(WrapperInterface):\r\n-    \"\"\"Wrapper for PyTorch models providing consistent training and inference interface.\"\"\"\r\n-\r\n-    def __init__(self, model: BaseModel, model_type: ModelType, config: Dict[str, Any]):\r\n-        self.model = model\r\n-        self.model_type = model_type\r\n-        self.config = config\r\n-\r\n-        # Device handling with improved CUDA settings\r\n-        self.device = torch.device(config.get('device', 'cuda' if torch.cuda.is_available() else 'cpu'))\r\n-        if self.device.type == 'cuda':\r\n-            # Enable TF32 for better performance on Ampere GPUs (like RTX 4060)\r\n-            torch.backends.cuda.matmul.allow_tf32 = True\r\n-            torch.backends.cudnn.allow_tf32 = True\r\n-            # Enable cuDNN autotuner\r\n-            torch.backends.cudnn.benchmark = True\r\n-            \r\n-        logger.info(f\"Using device: {self.device}\")\r\n-        logger.debug(f\"CUDA available: {torch.cuda.is_available()}\")\r\n-        \r\n-        if torch.cuda.is_available():\r\n-            logger.debug(f\"CUDA device count: {torch.cuda.device_count()}\")\r\n-            logger.debug(f\"Current CUDA device: {torch.cuda.current_device()}\")\r\n-\r\n-        # Move model to device\r\n-        self.model = self.model.to(self.device)\r\n-        logger.debug(f\"Model device after moving: {next(self.model.parameters()).device}\")\r\n-\r\n-        # Training configuration\r\n-        self.batch_size = config.get('batch_size', 128)  # Increased for RTX 4060\r\n-        self.learning_rate = config.get('learning_rate', 1e-3)\r\n-        self.max_epochs = config.get('max_epochs', 100)\r\n-        self.gradient_clip_val = config.get('gradient_clip_val', 1.0)\r\n-        self.accumulation_steps = config.get('accumulation_steps', 4)\r\n-\r\n-        # Setup optimizer and criterion\r\n-        self.optimizer = self._setup_optimizer()\r\n-        self.criterion = self._setup_criterion()\r\n-\r\n-        # Initialize modern AMP (Automatic Mixed Precision)\r\n-        self.use_amp = config.get('use_mixed_precision', True) and self.device.type == 'cuda'\r\n-        if self.use_amp:\r\n-            self.grad_scaler = amp.GradScaler('cuda')  # Modern GradScaler initialization\r\n-            self.autocast = amp.autocast(device_type='cuda', dtype=torch.float16)\r\n-        else:\r\n-            self.grad_scaler = None\r\n-            self.autocast = nullcontext()\r\n-\r\n-        # Memory management settings\r\n-        if self.device.type == 'cuda':\r\n-            # Set memory allocator settings for RTX 4060 (8GB VRAM)\r\n-            torch.cuda.set_per_process_memory_fraction(0.95)  # Use 95% of available VRAM\r\n-            self.empty_cache_frequency = config.get('empty_cache_frequency', 100)\r\n-            self.max_memory_allocated = 0.0\r\n-\r\n-    def _setup_data_loader(self, dataset: TorchDataset, shuffle: bool = True) -> DataLoader:\r\n-        \"\"\"Create an optimized DataLoader for GPU training.\"\"\"\r\n-        cpu_count = os.cpu_count() or 4\r\n-        num_workers = min(4, cpu_count // 2)  # Optimized for 32GB RAM\r\n-        \r\n-        return DataLoader(\r\n-            dataset,\r\n-            batch_size=self.batch_size,\r\n-            shuffle=shuffle,\r\n-            num_workers=num_workers,\r\n-            pin_memory=True,\r\n-            persistent_workers=True,\r\n-            prefetch_factor=2,\r\n-            pin_memory_device='cuda' if self.device.type == 'cuda' else None\r\n-        )\r\n-        \r\n-    def _setup_scheduler(self, train_loader: DataLoader) -> Optional[Union[LRScheduler, ReduceLROnPlateau]]:\r\n-        \"\"\"Initialize learning rate scheduler with improved defaults.\"\"\"\r\n-        scheduler_name = self.config.get('scheduler', 'one_cycle').lower()\r\n-        scheduler_config = self.config.get('scheduler_config', {})\r\n-\r\n-        if scheduler_name == 'one_cycle':\r\n-            total_steps = self.max_epochs * len(train_loader)\r\n-            steps_per_epoch = len(train_loader)\r\n-\r\n-            return cast(LRScheduler, OneCycleLR(\r\n-                self.optimizer,\r\n-                max_lr=self.learning_rate,\r\n-                total_steps=total_steps,\r\n-                epochs=self.max_epochs,\r\n-                steps_per_epoch=steps_per_epoch,\r\n-                pct_start=scheduler_config.get('pct_start', 0.3),\r\n-                div_factor=scheduler_config.get('div_factor', 25.0),\r\n-                final_div_factor=scheduler_config.get('final_div_factor', 1000.0),\r\n-                anneal_strategy=scheduler_config.get('anneal_strategy', 'cos')\r\n-            ))\r\n-\r\n-        elif scheduler_name == 'cosine':\r\n-            return cast(LRScheduler, CosineAnnealingLR(\r\n-                self.optimizer,\r\n-                T_max=self.max_epochs,\r\n-                eta_min=scheduler_config.get('eta_min', 1e-6)\r\n-            ))\r\n-\r\n-        elif scheduler_name == 'plateau':\r\n-            return ReduceLROnPlateau(\r\n-                self.optimizer,\r\n-                mode='min',\r\n-                factor=scheduler_config.get('factor', 0.5),\r\n-                patience=scheduler_config.get('patience', 5),\r\n-                min_lr=scheduler_config.get('min_lr', 1e-6)\r\n-            )\r\n-\r\n-        elif scheduler_name == 'cosineannealinglr':\r\n-            return cast(LRScheduler, CosineAnnealingLR(\r\n-                self.optimizer,\r\n-                T_max=self.max_epochs,\r\n-                eta_min=scheduler_config.get('eta_min', 1e-6)\r\n-            ))\r\n-\r\n-        elif scheduler_name == 'steplr':\r\n-            return cast(LRScheduler, lr_scheduler.StepLR(\r\n-                self.optimizer,\r\n-                step_size=scheduler_config.get('step_size', 10),\r\n-                gamma=scheduler_config.get('gamma', 0.1)\r\n-            ))\r\n-\r\n-        else:\r\n-            logger.warning(f\"Unknown scheduler: {scheduler_name}. No scheduler will be used.\")\r\n-            return None\r\n-\r\n-    def _setup_optimizer(self) -> Optimizer:\r\n-        \"\"\"Initialize optimizer with improved defaults.\"\"\"\r\n-        optimizer_name = self.config.get('optimizer', 'adamw').lower()\r\n-        optimizer_config = self.config.get('optimizer_config', {})\r\n-\r\n-        # Base parameters all optimizers support\r\n-        base_params = {\r\n-            'lr': self.learning_rate,\r\n-            'weight_decay': optimizer_config.get('weight_decay', 0.01)  # Updated default\r\n-        }\r\n-\r\n-        # Create optimizer with appropriate parameters\r\n-        if optimizer_name == 'sgd':\r\n-            sgd_params = {\r\n-                'momentum': optimizer_config.get('momentum', 0.9),\r\n-                'dampening': optimizer_config.get('dampening', 0),\r\n-                'nesterov': optimizer_config.get('nesterov', True)  # Enable Nesterov by default\r\n-            }\r\n-            return SGD(self.model.parameters(), **base_params, **sgd_params)\r\n-\r\n-        elif optimizer_name == 'adam':\r\n-            adam_params = {\r\n-                'betas': optimizer_config.get('betas', (0.9, 0.98)),  # Updated for transformer\r\n-                'eps': optimizer_config.get('eps', 1e-8),\r\n-                'amsgrad': optimizer_config.get('amsgrad', False)  # Typically False\r\n-            }\r\n-            return Adam(self.model.parameters(), **base_params, **adam_params)\r\n-\r\n-        elif optimizer_name == 'adamw':\r\n-            adamw_params = {\r\n-                'betas': optimizer_config.get('betas', (0.9, 0.98)),  # Updated for transformer\r\n-                'eps': optimizer_config.get('eps', 1e-8),\r\n-                'amsgrad': optimizer_config.get('amsgrad', False)  # Typically False\r\n-            }\r\n-            return AdamW(self.model.parameters(), **base_params, **adamw_params)\r\n-\r\n-        elif optimizer_name == 'rmsprop':\r\n-            rmsprop_params = {\r\n-                'alpha': optimizer_config.get('alpha', 0.99),\r\n-                'eps': optimizer_config.get('eps', 1e-8),\r\n-                'momentum': optimizer_config.get('momentum', 0.9),\r\n-                'centered': optimizer_config.get('centered', False)\r\n-            }\r\n-            return RMSprop(self.model.parameters(), **base_params, **rmsprop_params)\r\n-\r\n-        else:\r\n-            raise ValueError(f\"Unknown optimizer: {optimizer_name}\")\r\n-\r\n-    def _setup_criterion(self) -> nn.Module:\r\n-        \"\"\"Initialize loss function based on config.\"\"\"\r\n-        criterion_name = self.config.get('criterion', 'mse').lower()\r\n-        criterion_config = self.config.get('criterion_config', {})\r\n-\r\n-        criteria: Dict[str, nn.Module] = {\r\n-            'mse': nn.MSELoss(**criterion_config),\r\n-            'mae': nn.L1Loss(**criterion_config),\r\n-            'mape': MAPE(**criterion_config)\r\n-        }\r\n-\r\n-        if criterion_name not in criteria:\r\n-            raise ValueError(f\"Unknown criterion: {criterion_name}\")\r\n-\r\n-        return criteria[criterion_name]\r\n-\r\n-    def train(\r\n-            self,\r\n-            train_dataset: TorchDataset,\r\n-            validation_dataset: Optional[TorchDataset] = None\r\n-    ) -> TrainingReport:\r\n-        \"\"\"Train the model with proper device handling.\"\"\"\r\n-        \r\n-        logger.info(\"Starting training\")\r\n-        logger.debug(f\"Training device setup: CUDA available: {torch.cuda.is_available()}, Using device: {self.device}\")\r\n-        \r\n-        # Clear GPU cache before training\r\n-        if torch.cuda.is_available():\r\n-            torch.cuda.empty_cache()\r\n-            logger.debug(f\"Initial GPU memory allocated: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\r\n-        \r\n-        # Ensure model is on correct device\r\n-        self.model = self.model.to(self.device)\r\n-        \r\n-        # Setup DataLoader with optimized parameters\r\n-        cpu_count = os.cpu_count() or 4  # Use 4 as fallback if cpu_count is None\r\n-        num_workers = min(8, cpu_count // 2)  # Dynamic determination\r\n-        self.train_loader = DataLoader(\r\n-            train_dataset,\r\n-            batch_size=self.batch_size,\r\n-            shuffle=True,\r\n-            num_workers=num_workers,\r\n-            pin_memory=torch.cuda.is_available(),\r\n-            persistent_workers=True,\r\n-            prefetch_factor=4\r\n-        )\r\n-\r\n-        val_loader = None\r\n-        if validation_dataset is not None:\r\n-            val_loader = DataLoader(\r\n-                validation_dataset,\r\n-                batch_size=self.batch_size,\r\n-                shuffle=False,\r\n-                num_workers=num_workers,\r\n-                pin_memory=torch.cuda.is_available(),\r\n-                persistent_workers=True,\r\n-                prefetch_factor=4\r\n-            )\r\n-\r\n-        # Initialize scheduler\r\n-        self.scheduler = self._setup_scheduler(self.train_loader)\r\n-\r\n-        # Initialize training loop variables\r\n-        train_losses = []\r\n-        val_losses = []\r\n-        learning_rates = []\r\n-        best_val_loss = float('inf')\r\n-        patience_counter = 0\r\n-        early_stopping_patience = self.config.get('early_stopping_patience', 10)\r\n-\r\n-        # Initialize GradScaler if using mixed precision\r\n-        scaler = self.scaler\r\n-\r\n-        for epoch in range(1, self.max_epochs + 1):\r\n-            self.model.train()\r\n-            epoch_loss = 0.0\r\n-            num_batches = 0\r\n-\r\n-            for batch_idx, (data, target) in enumerate(self.train_loader, 1):\r\n-                try:\r\n-                    # Move data to device\r\n-                    if isinstance(data, tuple):\r\n-                        data = tuple(d.to(self.device, non_blocking=True) for d in data)\r\n-                    else:\r\n-                        data = data.to(self.device, non_blocking=True)\r\n-                    target = target.to(self.device, non_blocking=True)\r\n-\r\n-                    # Forward pass with autocast for mixed precision\r\n-                    with autocast() if scaler else torch.no_grad():\r\n-                        outputs = self.model(data)\r\n-                        loss = self.criterion(outputs, target)\r\n-                        loss = loss / self.accumulation_steps  # Normalize loss for accumulation\r\n-\r\n-                    # Backward pass\r\n-                    if scaler:\r\n-                        scaler.scale(loss).backward()\r\n-                    else:\r\n-                        loss.backward()\r\n-\r\n-                    # Gradient accumulation\r\n-                    if batch_idx % self.accumulation_steps == 0:\r\n-                        # Gradient clipping\r\n-                        if self.gradient_clip_val > 0:\r\n-                            if scaler:\r\n-                                scaler.unscale_(self.optimizer)\r\n-                            nn.utils.clip_grad_norm_(self.model.parameters(), self.gradient_clip_val)\r\n-                        \r\n-                        # Optimizer step\r\n-                        if scaler:\r\n-                            scaler.step(self.optimizer)\r\n-                            scaler.update()\r\n-                        else:\r\n-                            self.optimizer.step()\r\n-                        self.optimizer.zero_grad()\r\n-\r\n-                        # Scheduler step for OneCycleLR\r\n-                        if self.scheduler and isinstance(self.scheduler, OneCycleLR):\r\n-                            self.scheduler.step()\r\n-\r\n-                    # Accumulate loss\r\n-                    epoch_loss += loss.item() * self.accumulation_steps\r\n-                    num_batches += 1\r\n-\r\n-                    # Logging every 50 batches\r\n-                    if batch_idx % 50 == 0:\r\n-                        current_lr = self.optimizer.param_groups[0]['lr']\r\n-                        logger.info(\r\n-                            f\"Epoch [{epoch}/{self.max_epochs}] Batch [{batch_idx}/{len(self.train_loader)}] - \"\r\n-                            f\"Loss: {loss.item() * self.accumulation_steps:.6f} - LR: {current_lr:.6f}\"\r\n-                        )\r\n-                        if torch.cuda.is_available():\r\n-                            logger.debug(f\"GPU memory allocated: {torch.cuda.memory_allocated(self.device) / 1e9:.2f} GB\")\r\n-\r\n-                except RuntimeError as e:\r\n-                    logger.error(f\"Runtime error in Epoch [{epoch}/{self.max_epochs}] Batch [{batch_idx}/{len(self.train_loader)}]: {str(e)}\")\r\n-                    torch.cuda.empty_cache()\r\n-                    continue  # Skip this batch\r\n-\r\n-            # Calculate average training loss for the epoch\r\n-            avg_train_loss = epoch_loss / num_batches if num_batches > 0 else float('inf')\r\n-            train_losses.append(avg_train_loss)\r\n-\r\n-            # Scheduler step for non-OneCycleLR schedulers\r\n-            if self.scheduler and not isinstance(self.scheduler, OneCycleLR):\r\n-                if isinstance(self.scheduler, ReduceLROnPlateau):\r\n-                    self.scheduler.step(avg_train_loss)\r\n-                else:\r\n-                    self.scheduler.step()\r\n-\r\n-            # Validation phase\r\n-            if val_loader:\r\n-                val_loss = self._validate(val_loader)\r\n-                val_losses.append(val_loss)\r\n-\r\n-                # Scheduler step for ReduceLROnPlateau\r\n-                if self.scheduler and isinstance(self.scheduler, ReduceLROnPlateau):\r\n-                    self.scheduler.step(val_loss)\r\n-\r\n-                # Early Stopping\r\n-                if val_loss < best_val_loss - 1e-4:  # Adding a small delta to prevent frequent updates\r\n-                    best_val_loss = val_loss\r\n-                    patience_counter = 0\r\n-                    # Save the best model\r\n-                    self.save('best_model.pth')\r\n-                    logger.info(f\"Epoch [{epoch}/{self.max_epochs}] - New best validation loss: {val_loss:.6f}. Model saved.\")\r\n-                else:\r\n-                    patience_counter += 1\r\n-                    logger.info(f\"Epoch [{epoch}/{self.max_epochs}] - Validation loss: {val_loss:.6f}. Patience: {patience_counter}/{early_stopping_patience}\")\r\n-\r\n-                # Early stopping condition\r\n-                if patience_counter >= early_stopping_patience:\r\n-                    logger.warning(f\"Early stopping triggered after Epoch [{epoch}/{self.max_epochs}] with best Val Loss: {best_val_loss:.6f}\")\r\n-                    # Load the best model\r\n-                    self.load('best_model.pth')\r\n-                    break\r\n-\r\n-                logger.info(f\"Epoch [{epoch}/{self.max_epochs}] - Train Loss: {avg_train_loss:.6f}, Val Loss: {val_loss:.6f}\")\r\n-            else:\r\n-                logger.info(f\"Epoch [{epoch}/{self.max_epochs}] - Train Loss: {avg_train_loss:.6f}\")\r\n-\r\n-            # Record current learning rate\r\n-            current_lr = self.optimizer.param_groups[0]['lr']\r\n-            learning_rates.append(current_lr)\r\n-\r\n-        # Compile training report\r\n-        additional_metrics = {\r\n-            'best_val_loss': best_val_loss if val_losses else None,\r\n-            'final_train_loss': train_losses[-1] if train_losses else None,\r\n-            'final_val_loss': val_losses[-1] if val_losses else None,\r\n-            'final_learning_rate': learning_rates[-1] if learning_rates else None\r\n-        }\r\n-\r\n-        return TrainingReport(\r\n-            train_losses=train_losses,\r\n-            val_losses=val_losses,\r\n-            learning_rates=learning_rates,\r\n-            epochs=epoch,\r\n-            additional_metrics=additional_metrics\r\n-        )\r\n-\r\n-    def _validate(self, val_loader: DataLoader) -> float:\r\n-        \"\"\"Validate the model.\"\"\"\r\n-        self.model.eval()\r\n-        val_loss = 0.0\r\n-        num_batches = 0\r\n-\r\n-        with torch.no_grad():\r\n-            for data, target in val_loader:\r\n-                try:\r\n-                    # Move data to device\r\n-                    if isinstance(data, tuple):\r\n-                        data = tuple(d.to(self.device, non_blocking=True) for d in data)\r\n-                    else:\r\n-                        data = data.to(self.device, non_blocking=True)\r\n-                    target = target.to(self.device, non_blocking=True)\r\n-\r\n-                    # Forward pass with autocast if using mixed precision\r\n-                    if self.scaler:\r\n-                        with autocast():\r\n-                            outputs = self.model(data)\r\n-                            loss = self.criterion(outputs, target)\r\n-                    else:\r\n-                        outputs = self.model(data)\r\n-                        loss = self.criterion(outputs, target)\r\n-\r\n-                    val_loss += loss.item()\r\n-                    num_batches += 1\r\n-\r\n-                except RuntimeError as e:\r\n-                    logger.error(f\"Runtime error during validation: {str(e)}\")\r\n-                    torch.cuda.empty_cache()\r\n-                    continue  # Skip this batch\r\n-\r\n-        avg_val_loss = val_loss / num_batches if num_batches > 0 else float('inf')\r\n-        return avg_val_loss\r\n-\r\n-    def predict(self, dataset: TorchDataset) -> Tuple[torch.Tensor, torch.Tensor]:\r\n-        \"\"\"Make predictions using the model.\"\"\"\r\n-        data_loader = DataLoader(\r\n-            dataset, \r\n-            batch_size=self.batch_size,\r\n-            num_workers=min(8, (os.cpu_count() or 4) // 2),\r\n-            pin_memory=torch.cuda.is_available(),\r\n-            shuffle=False,\r\n-            persistent_workers=True,\r\n-            prefetch_factor=4\r\n-        )\r\n-\r\n-        self.model.eval()\r\n-        predictions: List[torch.Tensor] = []\r\n-        targets: List[torch.Tensor] = []\r\n-\r\n-        with torch.no_grad():\r\n-            for data, target in data_loader:\r\n-                try:\r\n-                    # Move data to device\r\n-                    if isinstance(data, tuple):\r\n-                        data = tuple(d.to(self.device, non_blocking=True) for d in data)\r\n-                    else:\r\n-                        data = data.to(self.device, non_blocking=True)\r\n-                    target = target.to(self.device, non_blocking=True)\r\n-\r\n-                    # Forward pass with autocast if using mixed precision\r\n-                    if self.scaler:\r\n-                        with autocast():\r\n-                            output = self.model(data)\r\n-                    else:\r\n-                        output = self.model(data)\r\n-\r\n-                    predictions.append(output.cpu())\r\n-                    targets.append(target.cpu())\r\n-\r\n-                except RuntimeError as e:\r\n-                    logger.error(f\"Runtime error during prediction: {str(e)}\")\r\n-                    torch.cuda.empty_cache()\r\n-                    continue  # Skip this batch\r\n-\r\n-        return torch.cat(predictions), torch.cat(targets)\r\n-\r\n-    def save(self, path: Union[str, Path]) -> None:\r\n-        \"\"\"Save model state.\"\"\"\r\n-        torch.save({\r\n-            'model_state_dict': self.model.state_dict(),\r\n-            'optimizer_state_dict': self.optimizer.state_dict(),\r\n-            'scheduler_state_dict': self.scheduler.state_dict() if self.scheduler else None,\r\n-            'scaler_state_dict': self.scaler.state_dict() if self.scaler else None,\r\n-            'config': self.config\r\n-        }, path)\r\n-        logger.info(f\"Model saved to {path}\")\r\n-\r\n-    def load(self, path: Union[str, Path]) -> None:\r\n-        \"\"\"Load model state.\"\"\"\r\n-        checkpoint = torch.load(path, map_location=self.device)\r\n-        self.model.load_state_dict(checkpoint['model_state_dict'])\r\n-        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\r\n-        if self.scheduler and checkpoint.get('scheduler_state_dict'):\r\n-            self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\r\n-        if self.scaler and checkpoint.get('scaler_state_dict'):\r\n-            self.scaler.load_state_dict(checkpoint['scaler_state_dict'])\r\n-        logger.info(f\"Model loaded from {path}\")\r\n-\r\n-    def training_step(\r\n-        self,\r\n-        batch_input: Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]],\r\n-        batch_target: torch.Tensor,\r\n-        **kwargs\r\n-    ) -> float:\r\n-        \"\"\"Process a single training batch with optimized GPU handling.\"\"\"\r\n-        self.optimizer.zero_grad()\r\n-        \r\n-        try:\r\n-            # Handle transformer models\r\n-            if self.model_type.is_transformer and isinstance(batch_input, tuple):\r\n-                src, tgt = batch_input\r\n-                # Use masks from kwargs if provided, else generate\r\n-                src_mask = kwargs.get('src_mask', self.model.generate_square_subsequent_mask(src.size(1)).to(self.device))\r\n-                tgt_mask = kwargs.get('tgt_mask', self.model.generate_square_subsequent_mask(tgt.size(1)).to(self.device))\r\n-                \r\n-                output = self.model(src, tgt, src_mask=src_mask, tgt_mask=tgt_mask)\r\n-            else:\r\n-                if isinstance(batch_input, tuple):\r\n-                    batch_input = batch_input[0]\r\n-                output = self.model(batch_input)\r\n-            \r\n-            loss = self.criterion(output, batch_target)\r\n-            loss.backward()\r\n-            \r\n-            # Gradient clipping\r\n-            if self.gradient_clip_val > 0:\r\n-                torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.gradient_clip_val)\r\n-                \r\n-            self.optimizer.step()\r\n-            \r\n-            return loss.item()\r\n-                \r\n-        except RuntimeError as e:\r\n-            logger.error(f\"Training step failed: {str(e)}\")\r\n-            logger.debug(\"Device mapping:\")\r\n-            logger.debug(f\"Model: {next(self.model.parameters()).device}\")\r\n-            if isinstance(batch_input, tuple):\r\n-                logger.debug(f\"Input tensors: {[b.device for b in batch_input]}\")\r\n-            else:\r\n-                logger.debug(f\"Input tensor: {batch_input.device}\")\r\n-            logger.debug(f\"Target tensor: {batch_target.device}\")\r\n-            raise\r\n-\r\n-    def validation_step(\r\n-        self,\r\n-        batch_input: Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]],\r\n-        batch_target: torch.Tensor,\r\n-        **kwargs\r\n-    ) -> float:\r\n-        \"\"\"Process a single validation batch.\r\n-        \r\n-        Args:\r\n-            batch_input: Input tensor or tuple of tensors\r\n-            batch_target: Target tensor\r\n-            **kwargs: Additional arguments like masks for transformers\r\n-            \r\n-        Returns:\r\n-            float: Loss value for this batch\r\n-        \"\"\"\r\n-        try:\r\n-            with torch.no_grad():\r\n-                # Handle transformer models\r\n-                if self.model_type.is_transformer and isinstance(batch_input, tuple):\r\n-                    src, tgt = batch_input\r\n-                    # Use masks from kwargs if provided, else generate\r\n-                    src_mask = kwargs.get('src_mask', self.model.generate_square_subsequent_mask(src.size(1)).to(self.device))\r\n-                    tgt_mask = kwargs.get('tgt_mask', self.model.generate_square_subsequent_mask(tgt.size(1)).to(self.device))\r\n-                    \r\n-                    output = self.model(src, tgt, src_mask=src_mask, tgt_mask=tgt_mask)\r\n-                else:\r\n-                    if isinstance(batch_input, tuple):\r\n-                        batch_input = batch_input[0]\r\n-                    output = self.model(batch_input)\r\n-                \r\n-                loss = self.criterion(output, batch_target)\r\n-                return loss.item()\r\n-                \r\n-        except RuntimeError as e:\r\n-            logger.error(f\"Validation step failed: {str(e)}\")\r\n-            logger.debug(\"Device mapping:\")\r\n-            logger.debug(f\"Model: {next(self.model.parameters()).device}\")\r\n-            if isinstance(batch_input, tuple):\r\n-                logger.debug(f\"Input tensors: {[b.device for b in batch_input]}\")\r\n-            else:\r\n-                logger.debug(f\"Input tensor: {batch_input.device}\")\r\n-            logger.debug(f\"Target tensor: {batch_target.device}\")\r\n-            raise\r\n"
                },
                {
                    "date": 1733262452443,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -90,24 +90,27 @@\n             # Set memory allocator settings for RTX 4060 (8GB VRAM)\r\n             torch.cuda.set_per_process_memory_fraction(0.95)  # Use 95% of available VRAM\r\n             self.empty_cache_frequency = config.get('empty_cache_frequency', 100)\r\n             self.max_memory_allocated = 0.0\r\n-\r\n+            \r\n     def _setup_data_loader(self, dataset: TorchDataset, shuffle: bool = True) -> DataLoader:\r\n         \"\"\"Create an optimized DataLoader for GPU training.\"\"\"\r\n         cpu_count = os.cpu_count() or 4\r\n         num_workers = min(4, cpu_count // 2)  # Optimized for 32GB RAM\r\n-        \r\n+\r\n+        pin_memory_device: Optional[str] = 'cuda' if self.device.type == 'cuda' else None\r\n+\r\n         return DataLoader(\r\n             dataset,\r\n             batch_size=self.batch_size,\r\n             shuffle=shuffle,\r\n             num_workers=num_workers,\r\n             pin_memory=True,\r\n             persistent_workers=True,\r\n             prefetch_factor=2,\r\n-            pin_memory_device='cuda' if self.device.type == 'cuda' else None\r\n+            pin_memory_device=pin_memory_device\r\n         )\r\n+\r\n         \r\n     def _setup_scheduler(self, train_loader: DataLoader) -> Optional[Union[LRScheduler, ReduceLROnPlateau]]:\r\n         \"\"\"Initialize learning rate scheduler with improved defaults.\"\"\"\r\n         scheduler_name = self.config.get('scheduler', 'one_cycle').lower()\r\n"
                },
                {
                    "date": 1733262499382,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -78,10 +78,10 @@\n \r\n         # Initialize modern AMP (Automatic Mixed Precision)\r\n         self.use_amp = config.get('use_mixed_precision', True) and self.device.type == 'cuda'\r\n         if self.use_amp:\r\n-            self.grad_scaler = amp.GradScaler('cuda')  # Modern GradScaler initialization\r\n-            self.autocast = amp.autocast(device_type='cuda', dtype=torch.float16)\r\n+            self.grad_scaler = GradScaler('cuda')  # Modern GradScaler initialization\r\n+            self.autocast = autocast(device_type='cuda', dtype=torch.float16)\r\n         else:\r\n             self.grad_scaler = None\r\n             self.autocast = nullcontext()\r\n \r\n@@ -353,10 +353,11 @@\n             train_losses=train_losses,\r\n             val_losses=val_losses,\r\n             learning_rates=learning_rates,\r\n             epochs=epoch,\r\n-            additional_metrics={'best_val_loss': best_val_loss}\r\n+            additional_metrics={'best_val_loss': [best_val_loss]}\r\n         )\r\n+\r\n         \r\n         \r\n     def _validate(self, val_loader: DataLoader) -> float:\r\n         \"\"\"Validate the model.\"\"\"\r\n"
                },
                {
                    "date": 1733262536008,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,560 @@\n+from __future__ import annotations\r\n+import os\r\n+from pathlib import Path\r\n+from typing import Union, Any, Dict, List, Optional, Tuple, Type, cast\r\n+from contextlib import nullcontext\r\n+import torch\r\n+from torch import nn\r\n+from os import PathLike\r\n+from torch.optim.adam import Adam\r\n+from torch.optim.adamw import AdamW\r\n+from torch.optim.sgd import SGD\r\n+from torch.optim.rmsprop import RMSprop\r\n+from torch.optim import lr_scheduler\r\n+from torch.optim.optimizer import Optimizer\r\n+from torch.utils.data import Dataset as TorchDataset\r\n+from torch.utils.data import DataLoader\r\n+from torch.cuda.amp import autocast, GradScaler  # Corrected import for AMP\r\n+\r\n+from models.losses.custom_losses import MAPE\r\n+from training.base.base_trainer import TrainingEpoch\r\n+from training.reports.training_report import TrainingReport\r\n+\r\n+from ..interfaces import WrapperInterface\r\n+from ..base.base_model import BaseModel\r\n+from ..registry.model_types import ModelType\r\n+\r\n+from torch.optim.lr_scheduler import (\r\n+    OneCycleLR,\r\n+    CosineAnnealingLR,\r\n+    ReduceLROnPlateau,\r\n+    _LRScheduler,\r\n+    LRScheduler\r\n+)\r\n+\r\n+from utils.logging.logger import Logger\r\n+\r\n+# Get module logger\r\n+logger = Logger.get_logger(__name__)\r\n+\r\n+class PyTorchWrapper(WrapperInterface):\r\n+    \"\"\"Wrapper for PyTorch models providing consistent training and inference interface.\"\"\"\r\n+\r\n+    def __init__(self, model: BaseModel, model_type: ModelType, config: Dict[str, Any]):\r\n+        self.model = model\r\n+        self.model_type = model_type\r\n+        self.config = config\r\n+\r\n+        # Device handling with improved CUDA settings\r\n+        self.device = torch.device(config.get('device', 'cuda' if torch.cuda.is_available() else 'cpu'))\r\n+        if self.device.type == 'cuda':\r\n+            # Enable TF32 for better performance on Ampere GPUs (like RTX 4060)\r\n+            torch.backends.cuda.matmul.allow_tf32 = True\r\n+            torch.backends.cudnn.allow_tf32 = True\r\n+            # Enable cuDNN autotuner\r\n+            torch.backends.cudnn.benchmark = True\r\n+\r\n+        logger.info(f\"Using device: {self.device}\")\r\n+        logger.debug(f\"CUDA available: {torch.cuda.is_available()}\")\r\n+\r\n+        if torch.cuda.is_available():\r\n+            logger.debug(f\"CUDA device count: {torch.cuda.device_count()}\")\r\n+            logger.debug(f\"Current CUDA device: {torch.cuda.current_device()}\")\r\n+\r\n+        # Move model to device\r\n+        self.model = self.model.to(self.device)\r\n+        logger.debug(f\"Model device after moving: {next(self.model.parameters()).device}\")\r\n+\r\n+        # Training configuration\r\n+        self.batch_size = config.get('batch_size', 128)  # Increased for RTX 4060\r\n+        self.learning_rate = config.get('learning_rate', 1e-3)\r\n+        self.max_epochs = config.get('max_epochs', 100)\r\n+        self.gradient_clip_val = config.get('gradient_clip_val', 1.0)\r\n+        self.accumulation_steps = config.get('accumulation_steps', 4)\r\n+\r\n+        # Setup optimizer and criterion\r\n+        self.optimizer = self._setup_optimizer()\r\n+        self.criterion = self._setup_criterion()\r\n+\r\n+        # Initialize modern AMP (Automatic Mixed Precision)\r\n+        self.use_amp = config.get('use_mixed_precision', True) and self.device.type == 'cuda'\r\n+        if self.use_amp:\r\n+            self.grad_scaler = GradScaler()  # Correct GradScaler initialization\r\n+        else:\r\n+            self.grad_scaler = None\r\n+\r\n+        # Memory management settings\r\n+        if self.device.type == 'cuda':\r\n+            # Set memory allocator settings for RTX 4060 (8GB VRAM)\r\n+            torch.cuda.set_per_process_memory_fraction(0.95)  # Use 95% of available VRAM\r\n+            self.empty_cache_frequency = config.get('empty_cache_frequency', 100)\r\n+            self.max_memory_allocated = 0.0\r\n+\r\n+    def _setup_data_loader(self, dataset: TorchDataset, shuffle: bool = True) -> DataLoader:\r\n+        \"\"\"Create an optimized DataLoader for GPU training.\"\"\"\r\n+        cpu_count = os.cpu_count() or 4\r\n+        num_workers = min(4, cpu_count // 2)  # Optimized for 32GB RAM\r\n+\r\n+        dataloader_kwargs = {\r\n+            'dataset': dataset,\r\n+            'batch_size': self.batch_size,\r\n+            'shuffle': shuffle,\r\n+            'num_workers': num_workers,\r\n+            'pin_memory': True,\r\n+            'persistent_workers': True,\r\n+            'prefetch_factor': 2,\r\n+        }\r\n+\r\n+        if self.device.type == 'cuda':\r\n+            dataloader_kwargs['pin_memory_device'] = 'cuda'\r\n+\r\n+        return DataLoader(**dataloader_kwargs)\r\n+        \r\n+    def _setup_scheduler(self, train_loader: DataLoader) -> Optional[Union[LRScheduler, ReduceLROnPlateau]]:\r\n+        \"\"\"Initialize learning rate scheduler with improved defaults.\"\"\"\r\n+        scheduler_name = self.config.get('scheduler', 'one_cycle').lower()\r\n+        scheduler_config = self.config.get('scheduler_config', {})\r\n+\r\n+        if scheduler_name == 'one_cycle':\r\n+            total_steps = self.max_epochs * len(train_loader)\r\n+            steps_per_epoch = len(train_loader)\r\n+\r\n+            return cast(LRScheduler, OneCycleLR(\r\n+                self.optimizer,\r\n+                max_lr=self.learning_rate,\r\n+                total_steps=total_steps,\r\n+                epochs=self.max_epochs,\r\n+                steps_per_epoch=steps_per_epoch,\r\n+                pct_start=scheduler_config.get('pct_start', 0.3),\r\n+                div_factor=scheduler_config.get('div_factor', 25.0),\r\n+                final_div_factor=scheduler_config.get('final_div_factor', 1000.0),\r\n+                anneal_strategy=scheduler_config.get('anneal_strategy', 'cos')\r\n+            ))\r\n+\r\n+        elif scheduler_name == 'cosine':\r\n+            return cast(LRScheduler, CosineAnnealingLR(\r\n+                self.optimizer,\r\n+                T_max=self.max_epochs,\r\n+                eta_min=scheduler_config.get('eta_min', 1e-6)\r\n+            ))\r\n+\r\n+        elif scheduler_name == 'plateau':\r\n+            return ReduceLROnPlateau(\r\n+                self.optimizer,\r\n+                mode='min',\r\n+                factor=scheduler_config.get('factor', 0.5),\r\n+                patience=scheduler_config.get('patience', 5),\r\n+                min_lr=scheduler_config.get('min_lr', 1e-6)\r\n+            )\r\n+\r\n+        elif scheduler_name == 'cosineannealinglr':\r\n+            return cast(LRScheduler, CosineAnnealingLR(\r\n+                self.optimizer,\r\n+                T_max=self.max_epochs,\r\n+                eta_min=scheduler_config.get('eta_min', 1e-6)\r\n+            ))\r\n+\r\n+        elif scheduler_name == 'steplr':\r\n+            return cast(LRScheduler, lr_scheduler.StepLR(\r\n+                self.optimizer,\r\n+                step_size=scheduler_config.get('step_size', 10),\r\n+                gamma=scheduler_config.get('gamma', 0.1)\r\n+            ))\r\n+\r\n+        else:\r\n+            logger.warning(f\"Unknown scheduler: {scheduler_name}. No scheduler will be used.\")\r\n+            return None\r\n+\r\n+    def _setup_optimizer(self) -> Optimizer:\r\n+        \"\"\"Initialize optimizer with improved defaults.\"\"\"\r\n+        optimizer_name = self.config.get('optimizer', 'adamw').lower()\r\n+        optimizer_config = self.config.get('optimizer_config', {})\r\n+\r\n+        # Base parameters all optimizers support\r\n+        base_params = {\r\n+            'lr': self.learning_rate,\r\n+            'weight_decay': optimizer_config.get('weight_decay', 0.01)  # Updated default\r\n+        }\r\n+\r\n+        # Create optimizer with appropriate parameters\r\n+        if optimizer_name == 'sgd':\r\n+            sgd_params = {\r\n+                'momentum': optimizer_config.get('momentum', 0.9),\r\n+                'dampening': optimizer_config.get('dampening', 0),\r\n+                'nesterov': optimizer_config.get('nesterov', True)  # Enable Nesterov by default\r\n+            }\r\n+            return SGD(self.model.parameters(), **base_params, **sgd_params)\r\n+\r\n+        elif optimizer_name == 'adam':\r\n+            adam_params = {\r\n+                'betas': optimizer_config.get('betas', (0.9, 0.98)),  # Updated for transformer\r\n+                'eps': optimizer_config.get('eps', 1e-8),\r\n+                'amsgrad': optimizer_config.get('amsgrad', False)  # Typically False\r\n+            }\r\n+            return Adam(self.model.parameters(), **base_params, **adam_params)\r\n+\r\n+        elif optimizer_name == 'adamw':\r\n+            adamw_params = {\r\n+                'betas': optimizer_config.get('betas', (0.9, 0.98)),  # Updated for transformer\r\n+                'eps': optimizer_config.get('eps', 1e-8),\r\n+                'amsgrad': optimizer_config.get('amsgrad', False)  # Typically False\r\n+            }\r\n+            return AdamW(self.model.parameters(), **base_params, **adamw_params)\r\n+\r\n+        elif optimizer_name == 'rmsprop':\r\n+            rmsprop_params = {\r\n+                'alpha': optimizer_config.get('alpha', 0.99),\r\n+                'eps': optimizer_config.get('eps', 1e-8),\r\n+                'momentum': optimizer_config.get('momentum', 0.9),\r\n+                'centered': optimizer_config.get('centered', False)\r\n+            }\r\n+            return RMSprop(self.model.parameters(), **base_params, **rmsprop_params)\r\n+\r\n+        else:\r\n+            raise ValueError(f\"Unknown optimizer: {optimizer_name}\")\r\n+\r\n+    def _setup_criterion(self) -> nn.Module:\r\n+        \"\"\"Initialize loss function based on config.\"\"\"\r\n+        criterion_name = self.config.get('criterion', 'mse').lower()\r\n+        criterion_config = self.config.get('criterion_config', {})\r\n+\r\n+        criteria: Dict[str, nn.Module] = {\r\n+            'mse': nn.MSELoss(**criterion_config),\r\n+            'mae': nn.L1Loss(**criterion_config),\r\n+            'mape': MAPE(**criterion_config)\r\n+        }\r\n+\r\n+        if criterion_name not in criteria:\r\n+            raise ValueError(f\"Unknown criterion: {criterion_name}\")\r\n+\r\n+        return criteria[criterion_name]\r\n+\r\n+    def train(self, train_dataset: TorchDataset, validation_dataset: Optional[TorchDataset] = None) -> TrainingReport:\r\n+        \"\"\"Train the model with modern mixed precision and memory optimization.\"\"\"\r\n+        logger.info(\"Starting training\")\r\n+        \r\n+        # Clear GPU cache before training\r\n+        if self.device.type == 'cuda':\r\n+            torch.cuda.empty_cache()\r\n+            logger.debug(f\"Initial GPU memory allocated: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\r\n+        \r\n+        self.train_loader = self._setup_data_loader(train_dataset, shuffle=True)\r\n+        val_loader = self._setup_data_loader(validation_dataset, shuffle=False) if validation_dataset else None\r\n+\r\n+        # Initialize scheduler\r\n+        self.scheduler = self._setup_scheduler(self.train_loader)\r\n+\r\n+        # Training state\r\n+        train_losses = []\r\n+        val_losses = []\r\n+        learning_rates = []\r\n+        best_val_loss = float('inf')\r\n+        patience_counter = 0\r\n+        early_stopping_patience = self.config.get('early_stopping_patience', 10)\r\n+\r\n+        for epoch in range(1, self.max_epochs + 1):\r\n+            self.model.train()\r\n+            epoch_loss = 0.0\r\n+            num_batches = 0\r\n+\r\n+            for batch_idx, (data, target) in enumerate(self.train_loader):\r\n+                try:\r\n+                    # Move data to device efficiently\r\n+                    if isinstance(data, tuple):\r\n+                        data = tuple(d.to(self.device, non_blocking=True) for d in data)\r\n+                    else:\r\n+                        data = data.to(self.device, non_blocking=True)\r\n+                    target = target.to(self.device, non_blocking=True)\r\n+\r\n+                    # Forward pass with automatic mixed precision\r\n+                    with autocast() if self.use_amp else nullcontext():\r\n+                        outputs = self.model(data)\r\n+                        loss = self.criterion(outputs, target)\r\n+                        loss = loss / self.accumulation_steps\r\n+\r\n+                    # Backward pass with gradient scaling\r\n+                    if self.use_amp and self.grad_scaler is not None:\r\n+                        self.grad_scaler.scale(loss).backward()\r\n+                    else:\r\n+                        loss.backward()\r\n+\r\n+                    # Gradient accumulation step\r\n+                    if (batch_idx + 1) % self.accumulation_steps == 0:\r\n+                        if self.gradient_clip_val > 0:\r\n+                            if self.use_amp and self.grad_scaler is not None:\r\n+                                self.grad_scaler.unscale_(self.optimizer)\r\n+                            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.gradient_clip_val)\r\n+\r\n+                        # Optimizer step with modern AMP\r\n+                        if self.use_amp and self.grad_scaler is not None:\r\n+                            self.grad_scaler.step(self.optimizer)\r\n+                            self.grad_scaler.update()\r\n+                        else:\r\n+                            self.optimizer.step()\r\n+\r\n+                        self.optimizer.zero_grad(set_to_none=True)\r\n+\r\n+                    # Memory management for RTX 4060\r\n+                    if self.device.type == 'cuda' and batch_idx % self.empty_cache_frequency == 0:\r\n+                        current_memory = torch.cuda.memory_allocated() / 1024**3\r\n+                        self.max_memory_allocated = max(self.max_memory_allocated, current_memory)\r\n+                        \r\n+                        if current_memory > 7.0:  # Conservative threshold for 8GB VRAM\r\n+                            torch.cuda.empty_cache()\r\n+\r\n+                    epoch_loss += loss.item() * self.accumulation_steps\r\n+                    num_batches += 1\r\n+\r\n+                except RuntimeError as e:\r\n+                    logger.error(f\"Error in batch {batch_idx}: {str(e)}\")\r\n+                    if \"out of memory\" in str(e):\r\n+                        torch.cuda.empty_cache()\r\n+                    continue\r\n+\r\n+            # Calculate average loss and update metrics\r\n+            avg_train_loss = epoch_loss / num_batches if num_batches > 0 else float('inf')\r\n+            train_losses.append(avg_train_loss)\r\n+            current_lr = self.optimizer.param_groups[0]['lr']\r\n+            learning_rates.append(current_lr)\r\n+\r\n+            # Validation phase\r\n+            if val_loader:\r\n+                val_loss = self._validate(val_loader)\r\n+                val_losses.append(val_loss)\r\n+\r\n+                # Early stopping logic\r\n+                if val_loss < best_val_loss:\r\n+                    best_val_loss = val_loss\r\n+                    patience_counter = 0\r\n+                    self.save('best_model.pth')\r\n+                else:\r\n+                    patience_counter += 1\r\n+                    if patience_counter >= early_stopping_patience:\r\n+                        logger.info(f\"Early stopping triggered after epoch {epoch}\")\r\n+                        break\r\n+\r\n+            # Scheduler step\r\n+            if self.scheduler:\r\n+                if isinstance(self.scheduler, ReduceLROnPlateau):\r\n+                    self.scheduler.step(val_loss if val_loader else avg_train_loss)\r\n+                else:\r\n+                    self.scheduler.step()\r\n+\r\n+            # Log progress\r\n+            logger.info(\r\n+                f\"Epoch {epoch}/{self.max_epochs} - \"\r\n+                f\"Train Loss: {avg_train_loss:.6f}\"\r\n+                + (f\", Val Loss: {val_loss:.6f}\" if val_loader else \"\")\r\n+                + f\" - LR: {current_lr:.6f}\"\r\n+            )\r\n+\r\n+        return TrainingReport(\r\n+            train_losses=train_losses,\r\n+            val_losses=val_losses,\r\n+            learning_rates=learning_rates,\r\n+            epochs=epoch,\r\n+            additional_metrics={'best_val_loss': [best_val_loss]}  # Updated to use list\r\n+        )\r\n+        \r\n+        \r\n+    def _validate(self, val_loader: DataLoader) -> float:\r\n+        \"\"\"Validate the model.\"\"\"\r\n+        self.model.eval()\r\n+        val_loss = 0.0\r\n+        num_batches = 0\r\n+\r\n+        with torch.no_grad():\r\n+            for data, target in val_loader:\r\n+                try:\r\n+                    # Move data to device\r\n+                    if isinstance(data, tuple):\r\n+                        data = tuple(d.to(self.device, non_blocking=True) for d in data)\r\n+                    else:\r\n+                        data = data.to(self.device, non_blocking=True)\r\n+                    target = target.to(self.device, non_blocking=True)\r\n+\r\n+                    # Forward pass with autocast if using mixed precision\r\n+                    with autocast() if self.use_amp else nullcontext():\r\n+                        outputs = self.model(data)\r\n+                        loss = self.criterion(outputs, target)\r\n+\r\n+                    val_loss += loss.item()\r\n+                    num_batches += 1\r\n+\r\n+                except RuntimeError as e:\r\n+                    logger.error(f\"Runtime error during validation: {str(e)}\")\r\n+                    torch.cuda.empty_cache()\r\n+                    continue  # Skip this batch\r\n+\r\n+        avg_val_loss = val_loss / num_batches if num_batches > 0 else float('inf')\r\n+        return avg_val_loss\r\n+\r\n+    def predict(self, dataset: TorchDataset) -> Tuple[torch.Tensor, torch.Tensor]:\r\n+        \"\"\"Make predictions using the model.\"\"\"\r\n+        data_loader = DataLoader(\r\n+            dataset, \r\n+            batch_size=self.batch_size,\r\n+            num_workers=min(8, (os.cpu_count() or 4) // 2),\r\n+            pin_memory=torch.cuda.is_available(),\r\n+            shuffle=False,\r\n+            persistent_workers=True,\r\n+            prefetch_factor=4\r\n+        )\r\n+\r\n+        self.model.eval()\r\n+        predictions: List[torch.Tensor] = []\r\n+        targets: List[torch.Tensor] = []\r\n+\r\n+        with torch.no_grad():\r\n+            for data, target in data_loader:\r\n+                try:\r\n+                    # Move data to device\r\n+                    if isinstance(data, tuple):\r\n+                        data = tuple(d.to(self.device, non_blocking=True) for d in data)\r\n+                    else:\r\n+                        data = data.to(self.device, non_blocking=True)\r\n+                    target = target.to(self.device, non_blocking=True)\r\n+\r\n+                    # Forward pass with autocast if using mixed precision\r\n+                    with autocast() if self.use_amp else nullcontext():\r\n+                        output = self.model(data)\r\n+\r\n+                    predictions.append(output.cpu())\r\n+                    targets.append(target.cpu())\r\n+\r\n+                except RuntimeError as e:\r\n+                    logger.error(f\"Runtime error during prediction: {str(e)}\")\r\n+                    torch.cuda.empty_cache()\r\n+                    continue  # Skip this batch\r\n+\r\n+        return torch.cat(predictions), torch.cat(targets)\r\n+\r\n+    def save(self, path: Union[str, Path]) -> None:\r\n+        \"\"\"Save model state.\"\"\"\r\n+        torch.save({\r\n+            'model_state_dict': self.model.state_dict(),\r\n+            'optimizer_state_dict': self.optimizer.state_dict(),\r\n+            'scheduler_state_dict': self.scheduler.state_dict() if self.scheduler else None,\r\n+            'grad_scaler_state_dict': self.grad_scaler.state_dict() if self.grad_scaler else None,\r\n+            'config': self.config\r\n+        }, path)\r\n+        logger.info(f\"Model saved to {path}\")\r\n+\r\n+    def load(self, path: Union[str, Path]) -> None:\r\n+        \"\"\"Load model state.\"\"\"\r\n+        checkpoint = torch.load(path, map_location=self.device)\r\n+        self.model.load_state_dict(checkpoint['model_state_dict'])\r\n+        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\r\n+        if self.scheduler and checkpoint.get('scheduler_state_dict'):\r\n+            self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\r\n+        if self.grad_scaler and checkpoint.get('grad_scaler_state_dict'):\r\n+            self.grad_scaler.load_state_dict(checkpoint['grad_scaler_state_dict'])\r\n+        logger.info(f\"Model loaded from {path}\")\r\n+\r\n+    def training_step(\r\n+        self,\r\n+        batch_input: Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]],\r\n+        batch_target: torch.Tensor,\r\n+        **kwargs\r\n+    ) -> float:\r\n+        \"\"\"Process a single training batch with optimized GPU handling.\"\"\"\r\n+        self.optimizer.zero_grad()\r\n+        \r\n+        try:\r\n+            # Handle transformer models\r\n+            if self.model_type.is_transformer and isinstance(batch_input, tuple):\r\n+                src, tgt = batch_input\r\n+                # Use masks from kwargs if provided, else generate\r\n+                src_mask = kwargs.get('src_mask', self.model.generate_square_subsequent_mask(src.size(1)).to(self.device))\r\n+                tgt_mask = kwargs.get('tgt_mask', self.model.generate_square_subsequent_mask(tgt.size(1)).to(self.device))\r\n+                \r\n+                with autocast() if self.use_amp else nullcontext():\r\n+                    output = self.model(src, tgt, src_mask=src_mask, tgt_mask=tgt_mask)\r\n+            else:\r\n+                if isinstance(batch_input, tuple):\r\n+                    batch_input = batch_input[0]\r\n+                with autocast() if self.use_amp else nullcontext():\r\n+                    output = self.model(batch_input)\r\n+            \r\n+            loss = self.criterion(output, batch_target)\r\n+            \r\n+            if self.use_amp and self.grad_scaler is not None:\r\n+                self.grad_scaler.scale(loss).backward()\r\n+            else:\r\n+                loss.backward()\r\n+            \r\n+            # Gradient clipping\r\n+            if self.gradient_clip_val > 0:\r\n+                if self.use_amp and self.grad_scaler is not None:\r\n+                    self.grad_scaler.unscale_(self.optimizer)\r\n+                torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.gradient_clip_val)\r\n+                \r\n+            # Optimizer step\r\n+            if self.use_amp and self.grad_scaler is not None:\r\n+                self.grad_scaler.step(self.optimizer)\r\n+                self.grad_scaler.update()\r\n+            else:\r\n+                self.optimizer.step()\r\n+            \r\n+            return loss.item()\r\n+                \r\n+        except RuntimeError as e:\r\n+            logger.error(f\"Training step failed: {str(e)}\")\r\n+            logger.debug(\"Device mapping:\")\r\n+            logger.debug(f\"Model: {next(self.model.parameters()).device}\")\r\n+            if isinstance(batch_input, tuple):\r\n+                logger.debug(f\"Input tensors: {[b.device for b in batch_input]}\")\r\n+            else:\r\n+                logger.debug(f\"Input tensor: {batch_input.device}\")\r\n+            logger.debug(f\"Target tensor: {batch_target.device}\")\r\n+            raise\r\n+\r\n+    def validation_step(\r\n+        self,\r\n+        batch_input: Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]],\r\n+        batch_target: torch.Tensor,\r\n+        **kwargs\r\n+    ) -> float:\r\n+        \"\"\"Process a single validation batch.\r\n+        \r\n+        Args:\r\n+            batch_input: Input tensor or tuple of tensors\r\n+            batch_target: Target tensor\r\n+            **kwargs: Additional arguments like masks for transformers\r\n+            \r\n+        Returns:\r\n+            float: Loss value for this batch\r\n+        \"\"\"\r\n+        try:\r\n+            # Handle transformer models\r\n+            if self.model_type.is_transformer and isinstance(batch_input, tuple):\r\n+                src, tgt = batch_input\r\n+                # Use masks from kwargs if provided, else generate\r\n+                src_mask = kwargs.get('src_mask', self.model.generate_square_subsequent_mask(src.size(1)).to(self.device))\r\n+                tgt_mask = kwargs.get('tgt_mask', self.model.generate_square_subsequent_mask(tgt.size(1)).to(self.device))\r\n+                \r\n+                with torch.no_grad():\r\n+                    with autocast() if self.use_amp else nullcontext():\r\n+                        output = self.model(src, tgt, src_mask=src_mask, tgt_mask=tgt_mask)\r\n+            else:\r\n+                if isinstance(batch_input, tuple):\r\n+                    batch_input = batch_input[0]\r\n+                with torch.no_grad():\r\n+                    with autocast() if self.use_amp else nullcontext():\r\n+                        output = self.model(batch_input)\r\n+                \r\n+                loss = self.criterion(output, batch_target)\r\n+\r\n+            loss = self.criterion(output, batch_target)\r\n+            return loss.item()\r\n+                \r\n+        except RuntimeError as e:\r\n+            logger.error(f\"Validation step failed: {str(e)}\")\r\n+            logger.debug(\"Device mapping:\")\r\n+            logger.debug(f\"Model: {next(self.model.parameters()).device}\")\r\n+            if isinstance(batch_input, tuple):\r\n+                logger.debug(f\"Input tensors: {[b.device for b in batch_input]}\")\r\n+            else:\r\n+                logger.debug(f\"Input tensor: {batch_input.device}\")\r\n+            logger.debug(f\"Target tensor: {batch_target.device}\")\r\n+            raise\r\n"
                },
                {
                    "date": 1733262769756,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -13,9 +13,10 @@\n from torch.optim import lr_scheduler\r\n from torch.optim.optimizer import Optimizer\r\n from torch.utils.data import Dataset as TorchDataset\r\n from torch.utils.data import DataLoader\r\n-from torch.cuda.amp import autocast, GradScaler  # Corrected import for AMP\r\n+from torch.amp.autocast_mode import autocast  # Updated import for autocast\r\n+from torch.amp.grad_scaler import GradScaler  # Updated import for GradScaler\r\n \r\n from models.losses.custom_losses import MAPE\r\n from training.base.base_trainer import TrainingEpoch\r\n from training.reports.training_report import TrainingReport\r\n@@ -94,10 +95,9 @@\n         \"\"\"Create an optimized DataLoader for GPU training.\"\"\"\r\n         cpu_count = os.cpu_count() or 4\r\n         num_workers = min(4, cpu_count // 2)  # Optimized for 32GB RAM\r\n \r\n-        dataloader_kwargs = {\r\n-            'dataset': dataset,\r\n+        data_loader_kwargs = {\r\n             'batch_size': self.batch_size,\r\n             'shuffle': shuffle,\r\n             'num_workers': num_workers,\r\n             'pin_memory': True,\r\n@@ -105,11 +105,11 @@\n             'prefetch_factor': 2,\r\n         }\r\n \r\n         if self.device.type == 'cuda':\r\n-            dataloader_kwargs['pin_memory_device'] = 'cuda'\r\n+            data_loader_kwargs['pin_memory_device'] = 'cuda'  # Only pass when using CUDA\r\n \r\n-        return DataLoader(**dataloader_kwargs)\r\n+        return DataLoader(dataset, **data_loader_kwargs)\r\n         \r\n     def _setup_scheduler(self, train_loader: DataLoader) -> Optional[Union[LRScheduler, ReduceLROnPlateau]]:\r\n         \"\"\"Initialize learning rate scheduler with improved defaults.\"\"\"\r\n         scheduler_name = self.config.get('scheduler', 'one_cycle').lower()\r\n@@ -266,9 +266,9 @@\n                         data = data.to(self.device, non_blocking=True)\r\n                     target = target.to(self.device, non_blocking=True)\r\n \r\n                     # Forward pass with automatic mixed precision\r\n-                    with autocast() if self.use_amp else nullcontext():\r\n+                    with autocast('cuda') if self.use_amp else nullcontext():\r\n                         outputs = self.model(data)\r\n                         loss = self.criterion(outputs, target)\r\n                         loss = loss / self.accumulation_steps\r\n \r\n@@ -373,9 +373,9 @@\n                         data = data.to(self.device, non_blocking=True)\r\n                     target = target.to(self.device, non_blocking=True)\r\n \r\n                     # Forward pass with autocast if using mixed precision\r\n-                    with autocast() if self.use_amp else nullcontext():\r\n+                    with autocast('cuda') if self.use_amp else nullcontext():\r\n                         outputs = self.model(data)\r\n                         loss = self.criterion(outputs, target)\r\n \r\n                     val_loss += loss.item()\r\n@@ -415,9 +415,9 @@\n                         data = data.to(self.device, non_blocking=True)\r\n                     target = target.to(self.device, non_blocking=True)\r\n \r\n                     # Forward pass with autocast if using mixed precision\r\n-                    with autocast() if self.use_amp else nullcontext():\r\n+                    with autocast('cuda') if self.use_amp else nullcontext():\r\n                         output = self.model(data)\r\n \r\n                     predictions.append(output.cpu())\r\n                     targets.append(target.cpu())\r\n@@ -467,14 +467,14 @@\n                 # Use masks from kwargs if provided, else generate\r\n                 src_mask = kwargs.get('src_mask', self.model.generate_square_subsequent_mask(src.size(1)).to(self.device))\r\n                 tgt_mask = kwargs.get('tgt_mask', self.model.generate_square_subsequent_mask(tgt.size(1)).to(self.device))\r\n                 \r\n-                with autocast() if self.use_amp else nullcontext():\r\n+                with autocast('cuda') if self.use_amp else nullcontext():\r\n                     output = self.model(src, tgt, src_mask=src_mask, tgt_mask=tgt_mask)\r\n             else:\r\n                 if isinstance(batch_input, tuple):\r\n                     batch_input = batch_input[0]\r\n-                with autocast() if self.use_amp else nullcontext():\r\n+                with autocast('cuda') if self.use_amp else nullcontext():\r\n                     output = self.model(batch_input)\r\n             \r\n             loss = self.criterion(output, batch_target)\r\n             \r\n@@ -533,15 +533,15 @@\n                 src_mask = kwargs.get('src_mask', self.model.generate_square_subsequent_mask(src.size(1)).to(self.device))\r\n                 tgt_mask = kwargs.get('tgt_mask', self.model.generate_square_subsequent_mask(tgt.size(1)).to(self.device))\r\n                 \r\n                 with torch.no_grad():\r\n-                    with autocast() if self.use_amp else nullcontext():\r\n+                    with autocast('cuda') if self.use_amp else nullcontext():\r\n                         output = self.model(src, tgt, src_mask=src_mask, tgt_mask=tgt_mask)\r\n             else:\r\n                 if isinstance(batch_input, tuple):\r\n                     batch_input = batch_input[0]\r\n                 with torch.no_grad():\r\n-                    with autocast() if self.use_amp else nullcontext():\r\n+                    with autocast('cuda') if self.use_amp else nullcontext():\r\n                         output = self.model(batch_input)\r\n                 \r\n                 loss = self.criterion(output, batch_target)\r\n \r\n@@ -557,555 +557,4 @@\n             else:\r\n                 logger.debug(f\"Input tensor: {batch_input.device}\")\r\n             logger.debug(f\"Target tensor: {batch_target.device}\")\r\n             raise\r\n-from __future__ import annotations\r\n-import os\r\n-from pathlib import Path\r\n-from typing import Union, Any, Dict, List, Optional, Tuple, Type, cast\r\n-from contextlib import nullcontext\r\n-import torch\r\n-from torch import nn\r\n-from os import PathLike\r\n-from torch.optim.adam import Adam\r\n-from torch.optim.adamw import AdamW\r\n-from torch.optim.sgd import SGD\r\n-from torch.optim.rmsprop import RMSprop\r\n-from torch.optim import lr_scheduler\r\n-from torch.optim.optimizer import Optimizer\r\n-from torch.utils.data import Dataset as TorchDataset\r\n-from torch.utils.data import DataLoader\r\n-from torch.cuda.amp import autocast, GradScaler\r\n-\r\n-\r\n-from models.losses.custom_losses import MAPE\r\n-from training.base.base_trainer import TrainingEpoch\r\n-from training.reports.training_report import TrainingReport\r\n-\r\n-from ..interfaces import WrapperInterface\r\n-from ..base.base_model import BaseModel\r\n-from ..registry.model_types import ModelType\r\n-from torch.optim.lr_scheduler import (\r\n-    OneCycleLR,\r\n-    CosineAnnealingLR,\r\n-    ReduceLROnPlateau,\r\n-    _LRScheduler,\r\n-    LRScheduler\r\n-)\r\n-\r\n-from utils.logging.logger import Logger\r\n-\r\n-# Get module logger\r\n-logger = Logger.get_logger(__name__)\r\n-\r\n-class PyTorchWrapper(WrapperInterface):\r\n-    \"\"\"Wrapper for PyTorch models providing consistent training and inference interface.\"\"\"\r\n-\r\n-    def __init__(self, model: BaseModel, model_type: ModelType, config: Dict[str, Any]):\r\n-        self.model = model\r\n-        self.model_type = model_type\r\n-        self.config = config\r\n-\r\n-        # Device handling with improved CUDA settings\r\n-        self.device = torch.device(config.get('device', 'cuda' if torch.cuda.is_available() else 'cpu'))\r\n-        if self.device.type == 'cuda':\r\n-            # Enable TF32 for better performance on Ampere GPUs (like RTX 4060)\r\n-            torch.backends.cuda.matmul.allow_tf32 = True\r\n-            torch.backends.cudnn.allow_tf32 = True\r\n-            # Enable cuDNN autotuner\r\n-            torch.backends.cudnn.benchmark = True\r\n-            \r\n-        logger.info(f\"Using device: {self.device}\")\r\n-        logger.debug(f\"CUDA available: {torch.cuda.is_available()}\")\r\n-        \r\n-        if torch.cuda.is_available():\r\n-            logger.debug(f\"CUDA device count: {torch.cuda.device_count()}\")\r\n-            logger.debug(f\"Current CUDA device: {torch.cuda.current_device()}\")\r\n-\r\n-        # Move model to device\r\n-        self.model = self.model.to(self.device)\r\n-        logger.debug(f\"Model device after moving: {next(self.model.parameters()).device}\")\r\n-\r\n-        # Training configuration\r\n-        self.batch_size = config.get('batch_size', 128)  # Increased for RTX 4060\r\n-        self.learning_rate = config.get('learning_rate', 1e-3)\r\n-        self.max_epochs = config.get('max_epochs', 100)\r\n-        self.gradient_clip_val = config.get('gradient_clip_val', 1.0)\r\n-        self.accumulation_steps = config.get('accumulation_steps', 4)\r\n-\r\n-        # Setup optimizer and criterion\r\n-        self.optimizer = self._setup_optimizer()\r\n-        self.criterion = self._setup_criterion()\r\n-\r\n-        # Initialize modern AMP (Automatic Mixed Precision)\r\n-        self.use_amp = config.get('use_mixed_precision', True) and self.device.type == 'cuda'\r\n-        if self.use_amp:\r\n-            self.grad_scaler = GradScaler('cuda')  # Modern GradScaler initialization\r\n-            self.autocast = autocast(device_type='cuda', dtype=torch.float16)\r\n-        else:\r\n-            self.grad_scaler = None\r\n-            self.autocast = nullcontext()\r\n-\r\n-        # Memory management settings\r\n-        if self.device.type == 'cuda':\r\n-            # Set memory allocator settings for RTX 4060 (8GB VRAM)\r\n-            torch.cuda.set_per_process_memory_fraction(0.95)  # Use 95% of available VRAM\r\n-            self.empty_cache_frequency = config.get('empty_cache_frequency', 100)\r\n-            self.max_memory_allocated = 0.0\r\n-            \r\n-    def _setup_data_loader(self, dataset: TorchDataset, shuffle: bool = True) -> DataLoader:\r\n-        \"\"\"Create an optimized DataLoader for GPU training.\"\"\"\r\n-        cpu_count = os.cpu_count() or 4\r\n-        num_workers = min(4, cpu_count // 2)  # Optimized for 32GB RAM\r\n-\r\n-        pin_memory_device: Optional[str] = 'cuda' if self.device.type == 'cuda' else None\r\n-\r\n-        return DataLoader(\r\n-            dataset,\r\n-            batch_size=self.batch_size,\r\n-            shuffle=shuffle,\r\n-            num_workers=num_workers,\r\n-            pin_memory=True,\r\n-            persistent_workers=True,\r\n-            prefetch_factor=2,\r\n-            pin_memory_device=pin_memory_device\r\n-        )\r\n-\r\n-        \r\n-    def _setup_scheduler(self, train_loader: DataLoader) -> Optional[Union[LRScheduler, ReduceLROnPlateau]]:\r\n-        \"\"\"Initialize learning rate scheduler with improved defaults.\"\"\"\r\n-        scheduler_name = self.config.get('scheduler', 'one_cycle').lower()\r\n-        scheduler_config = self.config.get('scheduler_config', {})\r\n-\r\n-        if scheduler_name == 'one_cycle':\r\n-            total_steps = self.max_epochs * len(train_loader)\r\n-            steps_per_epoch = len(train_loader)\r\n-\r\n-            return cast(LRScheduler, OneCycleLR(\r\n-                self.optimizer,\r\n-                max_lr=self.learning_rate,\r\n-                total_steps=total_steps,\r\n-                epochs=self.max_epochs,\r\n-                steps_per_epoch=steps_per_epoch,\r\n-                pct_start=scheduler_config.get('pct_start', 0.3),\r\n-                div_factor=scheduler_config.get('div_factor', 25.0),\r\n-                final_div_factor=scheduler_config.get('final_div_factor', 1000.0),\r\n-                anneal_strategy=scheduler_config.get('anneal_strategy', 'cos')\r\n-            ))\r\n-\r\n-        elif scheduler_name == 'cosine':\r\n-            return cast(LRScheduler, CosineAnnealingLR(\r\n-                self.optimizer,\r\n-                T_max=self.max_epochs,\r\n-                eta_min=scheduler_config.get('eta_min', 1e-6)\r\n-            ))\r\n-\r\n-        elif scheduler_name == 'plateau':\r\n-            return ReduceLROnPlateau(\r\n-                self.optimizer,\r\n-                mode='min',\r\n-                factor=scheduler_config.get('factor', 0.5),\r\n-                patience=scheduler_config.get('patience', 5),\r\n-                min_lr=scheduler_config.get('min_lr', 1e-6)\r\n-            )\r\n-\r\n-        elif scheduler_name == 'cosineannealinglr':\r\n-            return cast(LRScheduler, CosineAnnealingLR(\r\n-                self.optimizer,\r\n-                T_max=self.max_epochs,\r\n-                eta_min=scheduler_config.get('eta_min', 1e-6)\r\n-            ))\r\n-\r\n-        elif scheduler_name == 'steplr':\r\n-            return cast(LRScheduler, lr_scheduler.StepLR(\r\n-                self.optimizer,\r\n-                step_size=scheduler_config.get('step_size', 10),\r\n-                gamma=scheduler_config.get('gamma', 0.1)\r\n-            ))\r\n-\r\n-        else:\r\n-            logger.warning(f\"Unknown scheduler: {scheduler_name}. No scheduler will be used.\")\r\n-            return None\r\n-\r\n-    def _setup_optimizer(self) -> Optimizer:\r\n-        \"\"\"Initialize optimizer with improved defaults.\"\"\"\r\n-        optimizer_name = self.config.get('optimizer', 'adamw').lower()\r\n-        optimizer_config = self.config.get('optimizer_config', {})\r\n-\r\n-        # Base parameters all optimizers support\r\n-        base_params = {\r\n-            'lr': self.learning_rate,\r\n-            'weight_decay': optimizer_config.get('weight_decay', 0.01)  # Updated default\r\n-        }\r\n-\r\n-        # Create optimizer with appropriate parameters\r\n-        if optimizer_name == 'sgd':\r\n-            sgd_params = {\r\n-                'momentum': optimizer_config.get('momentum', 0.9),\r\n-                'dampening': optimizer_config.get('dampening', 0),\r\n-                'nesterov': optimizer_config.get('nesterov', True)  # Enable Nesterov by default\r\n-            }\r\n-            return SGD(self.model.parameters(), **base_params, **sgd_params)\r\n-\r\n-        elif optimizer_name == 'adam':\r\n-            adam_params = {\r\n-                'betas': optimizer_config.get('betas', (0.9, 0.98)),  # Updated for transformer\r\n-                'eps': optimizer_config.get('eps', 1e-8),\r\n-                'amsgrad': optimizer_config.get('amsgrad', False)  # Typically False\r\n-            }\r\n-            return Adam(self.model.parameters(), **base_params, **adam_params)\r\n-\r\n-        elif optimizer_name == 'adamw':\r\n-            adamw_params = {\r\n-                'betas': optimizer_config.get('betas', (0.9, 0.98)),  # Updated for transformer\r\n-                'eps': optimizer_config.get('eps', 1e-8),\r\n-                'amsgrad': optimizer_config.get('amsgrad', False)  # Typically False\r\n-            }\r\n-            return AdamW(self.model.parameters(), **base_params, **adamw_params)\r\n-\r\n-        elif optimizer_name == 'rmsprop':\r\n-            rmsprop_params = {\r\n-                'alpha': optimizer_config.get('alpha', 0.99),\r\n-                'eps': optimizer_config.get('eps', 1e-8),\r\n-                'momentum': optimizer_config.get('momentum', 0.9),\r\n-                'centered': optimizer_config.get('centered', False)\r\n-            }\r\n-            return RMSprop(self.model.parameters(), **base_params, **rmsprop_params)\r\n-\r\n-        else:\r\n-            raise ValueError(f\"Unknown optimizer: {optimizer_name}\")\r\n-\r\n-    def _setup_criterion(self) -> nn.Module:\r\n-        \"\"\"Initialize loss function based on config.\"\"\"\r\n-        criterion_name = self.config.get('criterion', 'mse').lower()\r\n-        criterion_config = self.config.get('criterion_config', {})\r\n-\r\n-        criteria: Dict[str, nn.Module] = {\r\n-            'mse': nn.MSELoss(**criterion_config),\r\n-            'mae': nn.L1Loss(**criterion_config),\r\n-            'mape': MAPE(**criterion_config)\r\n-        }\r\n-\r\n-        if criterion_name not in criteria:\r\n-            raise ValueError(f\"Unknown criterion: {criterion_name}\")\r\n-\r\n-        return criteria[criterion_name]\r\n-\r\n-    def train(self, train_dataset: TorchDataset, validation_dataset: Optional[TorchDataset] = None) -> TrainingReport:\r\n-        \"\"\"Train the model with modern mixed precision and memory optimization.\"\"\"\r\n-        logger.info(\"Starting training\")\r\n-        \r\n-        # Clear GPU cache before training\r\n-        if self.device.type == 'cuda':\r\n-            torch.cuda.empty_cache()\r\n-            logger.debug(f\"Initial GPU memory allocated: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\r\n-        \r\n-        self.train_loader = self._setup_data_loader(train_dataset, shuffle=True)\r\n-        val_loader = self._setup_data_loader(validation_dataset, shuffle=False) if validation_dataset else None\r\n-\r\n-        # Initialize scheduler\r\n-        self.scheduler = self._setup_scheduler(self.train_loader)\r\n-\r\n-        # Training state\r\n-        train_losses = []\r\n-        val_losses = []\r\n-        learning_rates = []\r\n-        best_val_loss = float('inf')\r\n-        patience_counter = 0\r\n-        early_stopping_patience = self.config.get('early_stopping_patience', 10)\r\n-\r\n-        for epoch in range(1, self.max_epochs + 1):\r\n-            self.model.train()\r\n-            epoch_loss = 0.0\r\n-            num_batches = 0\r\n-\r\n-            for batch_idx, (data, target) in enumerate(self.train_loader):\r\n-                try:\r\n-                    # Move data to device efficiently\r\n-                    if isinstance(data, tuple):\r\n-                        data = tuple(d.to(self.device, non_blocking=True) for d in data)\r\n-                    else:\r\n-                        data = data.to(self.device, non_blocking=True)\r\n-                    target = target.to(self.device, non_blocking=True)\r\n-\r\n-                    # Forward pass with automatic mixed precision\r\n-                    with self.autocast:\r\n-                        outputs = self.model(data)\r\n-                        loss = self.criterion(outputs, target)\r\n-                        loss = loss / self.accumulation_steps\r\n-\r\n-                    # Backward pass with gradient scaling\r\n-                    if self.use_amp:\r\n-                        self.grad_scaler.scale(loss).backward()\r\n-                    else:\r\n-                        loss.backward()\r\n-\r\n-                    # Gradient accumulation step\r\n-                    if (batch_idx + 1) % self.accumulation_steps == 0:\r\n-                        if self.gradient_clip_val > 0:\r\n-                            if self.use_amp:\r\n-                                self.grad_scaler.unscale_(self.optimizer)\r\n-                            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.gradient_clip_val)\r\n-\r\n-                        # Optimizer step with modern AMP\r\n-                        if self.use_amp:\r\n-                            self.grad_scaler.step(self.optimizer)\r\n-                            self.grad_scaler.update()\r\n-                        else:\r\n-                            self.optimizer.step()\r\n-\r\n-                        self.optimizer.zero_grad(set_to_none=True)\r\n-\r\n-                    # Memory management for RTX 4060\r\n-                    if self.device.type == 'cuda' and batch_idx % self.empty_cache_frequency == 0:\r\n-                        current_memory = torch.cuda.memory_allocated() / 1024**3\r\n-                        self.max_memory_allocated = max(self.max_memory_allocated, current_memory)\r\n-                        \r\n-                        if current_memory > 7.0:  # Conservative threshold for 8GB VRAM\r\n-                            torch.cuda.empty_cache()\r\n-\r\n-                    epoch_loss += loss.item() * self.accumulation_steps\r\n-                    num_batches += 1\r\n-\r\n-                except RuntimeError as e:\r\n-                    logger.error(f\"Error in batch {batch_idx}: {str(e)}\")\r\n-                    if \"out of memory\" in str(e):\r\n-                        torch.cuda.empty_cache()\r\n-                    continue\r\n-\r\n-            # Calculate average loss and update metrics\r\n-            avg_train_loss = epoch_loss / num_batches if num_batches > 0 else float('inf')\r\n-            train_losses.append(avg_train_loss)\r\n-            current_lr = self.optimizer.param_groups[0]['lr']\r\n-            learning_rates.append(current_lr)\r\n-\r\n-            # Validation phase\r\n-            if val_loader:\r\n-                val_loss = self._validate(val_loader)\r\n-                val_losses.append(val_loss)\r\n-\r\n-                # Early stopping logic\r\n-                if val_loss < best_val_loss:\r\n-                    best_val_loss = val_loss\r\n-                    patience_counter = 0\r\n-                    self.save('best_model.pth')\r\n-                else:\r\n-                    patience_counter += 1\r\n-                    if patience_counter >= early_stopping_patience:\r\n-                        logger.info(f\"Early stopping triggered after epoch {epoch}\")\r\n-                        break\r\n-\r\n-            # Scheduler step\r\n-            if self.scheduler:\r\n-                if isinstance(self.scheduler, ReduceLROnPlateau):\r\n-                    self.scheduler.step(val_loss if val_loader else avg_train_loss)\r\n-                else:\r\n-                    self.scheduler.step()\r\n-\r\n-            # Log progress\r\n-            logger.info(\r\n-                f\"Epoch {epoch}/{self.max_epochs} - \"\r\n-                f\"Train Loss: {avg_train_loss:.6f}\"\r\n-                + (f\", Val Loss: {val_loss:.6f}\" if val_loader else \"\")\r\n-                + f\" - LR: {current_lr:.6f}\"\r\n-            )\r\n-\r\n-        return TrainingReport(\r\n-            train_losses=train_losses,\r\n-            val_losses=val_losses,\r\n-            learning_rates=learning_rates,\r\n-            epochs=epoch,\r\n-            additional_metrics={'best_val_loss': [best_val_loss]}\r\n-        )\r\n-\r\n-        \r\n-        \r\n-    def _validate(self, val_loader: DataLoader) -> float:\r\n-        \"\"\"Validate the model.\"\"\"\r\n-        self.model.eval()\r\n-        val_loss = 0.0\r\n-        num_batches = 0\r\n-\r\n-        with torch.no_grad():\r\n-            for data, target in val_loader:\r\n-                try:\r\n-                    # Move data to device\r\n-                    if isinstance(data, tuple):\r\n-                        data = tuple(d.to(self.device, non_blocking=True) for d in data)\r\n-                    else:\r\n-                        data = data.to(self.device, non_blocking=True)\r\n-                    target = target.to(self.device, non_blocking=True)\r\n-\r\n-                    # Forward pass with autocast if using mixed precision\r\n-                    if self.scaler:\r\n-                        with autocast():\r\n-                            outputs = self.model(data)\r\n-                            loss = self.criterion(outputs, target)\r\n-                    else:\r\n-                        outputs = self.model(data)\r\n-                        loss = self.criterion(outputs, target)\r\n-\r\n-                    val_loss += loss.item()\r\n-                    num_batches += 1\r\n-\r\n-                except RuntimeError as e:\r\n-                    logger.error(f\"Runtime error during validation: {str(e)}\")\r\n-                    torch.cuda.empty_cache()\r\n-                    continue  # Skip this batch\r\n-\r\n-        avg_val_loss = val_loss / num_batches if num_batches > 0 else float('inf')\r\n-        return avg_val_loss\r\n-\r\n-    def predict(self, dataset: TorchDataset) -> Tuple[torch.Tensor, torch.Tensor]:\r\n-        \"\"\"Make predictions using the model.\"\"\"\r\n-        data_loader = DataLoader(\r\n-            dataset, \r\n-            batch_size=self.batch_size,\r\n-            num_workers=min(8, (os.cpu_count() or 4) // 2),\r\n-            pin_memory=torch.cuda.is_available(),\r\n-            shuffle=False,\r\n-            persistent_workers=True,\r\n-            prefetch_factor=4\r\n-        )\r\n-\r\n-        self.model.eval()\r\n-        predictions: List[torch.Tensor] = []\r\n-        targets: List[torch.Tensor] = []\r\n-\r\n-        with torch.no_grad():\r\n-            for data, target in data_loader:\r\n-                try:\r\n-                    # Move data to device\r\n-                    if isinstance(data, tuple):\r\n-                        data = tuple(d.to(self.device, non_blocking=True) for d in data)\r\n-                    else:\r\n-                        data = data.to(self.device, non_blocking=True)\r\n-                    target = target.to(self.device, non_blocking=True)\r\n-\r\n-                    # Forward pass with autocast if using mixed precision\r\n-                    if self.scaler:\r\n-                        with autocast():\r\n-                            output = self.model(data)\r\n-                    else:\r\n-                        output = self.model(data)\r\n-\r\n-                    predictions.append(output.cpu())\r\n-                    targets.append(target.cpu())\r\n-\r\n-                except RuntimeError as e:\r\n-                    logger.error(f\"Runtime error during prediction: {str(e)}\")\r\n-                    torch.cuda.empty_cache()\r\n-                    continue  # Skip this batch\r\n-\r\n-        return torch.cat(predictions), torch.cat(targets)\r\n-\r\n-    def save(self, path: Union[str, Path]) -> None:\r\n-        \"\"\"Save model state.\"\"\"\r\n-        torch.save({\r\n-            'model_state_dict': self.model.state_dict(),\r\n-            'optimizer_state_dict': self.optimizer.state_dict(),\r\n-            'scheduler_state_dict': self.scheduler.state_dict() if self.scheduler else None,\r\n-            'scaler_state_dict': self.scaler.state_dict() if self.scaler else None,\r\n-            'config': self.config\r\n-        }, path)\r\n-        logger.info(f\"Model saved to {path}\")\r\n-\r\n-    def load(self, path: Union[str, Path]) -> None:\r\n-        \"\"\"Load model state.\"\"\"\r\n-        checkpoint = torch.load(path, map_location=self.device)\r\n-        self.model.load_state_dict(checkpoint['model_state_dict'])\r\n-        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\r\n-        if self.scheduler and checkpoint.get('scheduler_state_dict'):\r\n-            self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\r\n-        if self.scaler and checkpoint.get('scaler_state_dict'):\r\n-            self.scaler.load_state_dict(checkpoint['scaler_state_dict'])\r\n-        logger.info(f\"Model loaded from {path}\")\r\n-\r\n-    def training_step(\r\n-        self,\r\n-        batch_input: Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]],\r\n-        batch_target: torch.Tensor,\r\n-        **kwargs\r\n-    ) -> float:\r\n-        \"\"\"Process a single training batch with optimized GPU handling.\"\"\"\r\n-        self.optimizer.zero_grad()\r\n-        \r\n-        try:\r\n-            # Handle transformer models\r\n-            if self.model_type.is_transformer and isinstance(batch_input, tuple):\r\n-                src, tgt = batch_input\r\n-                # Use masks from kwargs if provided, else generate\r\n-                src_mask = kwargs.get('src_mask', self.model.generate_square_subsequent_mask(src.size(1)).to(self.device))\r\n-                tgt_mask = kwargs.get('tgt_mask', self.model.generate_square_subsequent_mask(tgt.size(1)).to(self.device))\r\n-                \r\n-                output = self.model(src, tgt, src_mask=src_mask, tgt_mask=tgt_mask)\r\n-            else:\r\n-                if isinstance(batch_input, tuple):\r\n-                    batch_input = batch_input[0]\r\n-                output = self.model(batch_input)\r\n-            \r\n-            loss = self.criterion(output, batch_target)\r\n-            loss.backward()\r\n-            \r\n-            # Gradient clipping\r\n-            if self.gradient_clip_val > 0:\r\n-                torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.gradient_clip_val)\r\n-                \r\n-            self.optimizer.step()\r\n-            \r\n-            return loss.item()\r\n-                \r\n-        except RuntimeError as e:\r\n-            logger.error(f\"Training step failed: {str(e)}\")\r\n-            logger.debug(\"Device mapping:\")\r\n-            logger.debug(f\"Model: {next(self.model.parameters()).device}\")\r\n-            if isinstance(batch_input, tuple):\r\n-                logger.debug(f\"Input tensors: {[b.device for b in batch_input]}\")\r\n-            else:\r\n-                logger.debug(f\"Input tensor: {batch_input.device}\")\r\n-            logger.debug(f\"Target tensor: {batch_target.device}\")\r\n-            raise\r\n-\r\n-    def validation_step(\r\n-        self,\r\n-        batch_input: Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]],\r\n-        batch_target: torch.Tensor,\r\n-        **kwargs\r\n-    ) -> float:\r\n-        \"\"\"Process a single validation batch.\r\n-        \r\n-        Args:\r\n-            batch_input: Input tensor or tuple of tensors\r\n-            batch_target: Target tensor\r\n-            **kwargs: Additional arguments like masks for transformers\r\n-            \r\n-        Returns:\r\n-            float: Loss value for this batch\r\n-        \"\"\"\r\n-        try:\r\n-            with torch.no_grad():\r\n-                # Handle transformer models\r\n-                if self.model_type.is_transformer and isinstance(batch_input, tuple):\r\n-                    src, tgt = batch_input\r\n-                    # Use masks from kwargs if provided, else generate\r\n-                    src_mask = kwargs.get('src_mask', self.model.generate_square_subsequent_mask(src.size(1)).to(self.device))\r\n-                    tgt_mask = kwargs.get('tgt_mask', self.model.generate_square_subsequent_mask(tgt.size(1)).to(self.device))\r\n-                    \r\n-                    output = self.model(src, tgt, src_mask=src_mask, tgt_mask=tgt_mask)\r\n-                else:\r\n-                    if isinstance(batch_input, tuple):\r\n-                        batch_input = batch_input[0]\r\n-                    output = self.model(batch_input)\r\n-                \r\n-                loss = self.criterion(output, batch_target)\r\n-                return loss.item()\r\n-                \r\n-        except RuntimeError as e:\r\n-            logger.error(f\"Validation step failed: {str(e)}\")\r\n-            logger.debug(\"Device mapping:\")\r\n-            logger.debug(f\"Model: {next(self.model.parameters()).device}\")\r\n-            if isinstance(batch_input, tuple):\r\n-                logger.debug(f\"Input tensors: {[b.device for b in batch_input]}\")\r\n-            else:\r\n-                logger.debug(f\"Input tensor: {batch_input.device}\")\r\n-            logger.debug(f\"Target tensor: {batch_target.device}\")\r\n-            raise\r\n"
                },
                {
                    "date": 1733263376044,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -61,8 +61,23 @@\n         if torch.cuda.is_available():\r\n             logger.debug(f\"CUDA device count: {torch.cuda.device_count()}\")\r\n             logger.debug(f\"Current CUDA device: {torch.cuda.current_device()}\")\r\n \r\n+        # Update mixed precision settings\r\n+        self.use_amp = config.get('use_mixed_precision', True) and self.device.type == 'cuda'\r\n+        self.dtype = torch.float16 if self.use_amp else torch.float32\r\n+        \r\n+        # Move model to device with correct dtype\r\n+        self.model = self.model.to(device=self.device, dtype=self.dtype)\r\n+        \r\n+        if self.use_amp:\r\n+            self.grad_scaler = GradScaler()\r\n+        else:\r\n+            self.grad_scaler = None\r\n+            \r\n+        # Set default tensor type for the model\r\n+        torch.set_default_dtype(self.dtype)\r\n+\r\n         # Move model to device\r\n         self.model = self.model.to(self.device)\r\n         logger.debug(f\"Model device after moving: {next(self.model.parameters()).device}\")\r\n \r\n@@ -452,29 +467,41 @@\n         logger.info(f\"Model loaded from {path}\")\r\n \r\n     def training_step(\r\n         self,\r\n-        batch_input: Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]],\r\n+        batch_input: Union[torch.Tensor, Tuple[torch.Tensor, ...]],  # Changed type hint\r\n         batch_target: torch.Tensor,\r\n-        **kwargs\r\n+        src_mask: Optional[torch.Tensor] = None,\r\n+        tgt_mask: Optional[torch.Tensor] = None,\r\n+        **kwargs: Any\r\n     ) -> float:\r\n         \"\"\"Process a single training batch with optimized GPU handling.\"\"\"\r\n         self.optimizer.zero_grad()\r\n         \r\n         try:\r\n+            # Convert inputs to correct dtype\r\n+            if isinstance(batch_input, tuple):\r\n+                batch_input = tuple(b.to(device=self.device, dtype=self.dtype) for b in batch_input)\r\n+                if len(batch_input) != 2:\r\n+                    raise ValueError(f\"Expected tuple of 2 tensors but got {len(batch_input)}\")\r\n+                batch_input = cast(Tuple[torch.Tensor, torch.Tensor], batch_input)  # Add explicit cast\r\n+            else:\r\n+                batch_input = batch_input.to(device=self.device, dtype=self.dtype)\r\n+            \r\n+            batch_target = batch_target.to(device=self.device, dtype=self.dtype)\r\n+            \r\n             # Handle transformer models\r\n             if self.model_type.is_transformer and isinstance(batch_input, tuple):\r\n                 src, tgt = batch_input\r\n-                # Use masks from kwargs if provided, else generate\r\n-                src_mask = kwargs.get('src_mask', self.model.generate_square_subsequent_mask(src.size(1)).to(self.device))\r\n-                tgt_mask = kwargs.get('tgt_mask', self.model.generate_square_subsequent_mask(tgt.size(1)).to(self.device))\r\n+                src_mask = src_mask or self.model.generate_square_subsequent_mask(src.size(1)).to(device=self.device, dtype=self.dtype)\r\n+                tgt_mask = tgt_mask or self.model.generate_square_subsequent_mask(tgt.size(1)).to(device=self.device, dtype=self.dtype)\r\n                 \r\n-                with autocast('cuda') if self.use_amp else nullcontext():\r\n+                with autocast(device_type='cuda', dtype=self.dtype) if self.use_amp else nullcontext():\r\n                     output = self.model(src, tgt, src_mask=src_mask, tgt_mask=tgt_mask)\r\n             else:\r\n                 if isinstance(batch_input, tuple):\r\n                     batch_input = batch_input[0]\r\n-                with autocast('cuda') if self.use_amp else nullcontext():\r\n+                with autocast(device_type='cuda', dtype=self.dtype) if self.use_amp else nullcontext():\r\n                     output = self.model(batch_input)\r\n             \r\n             loss = self.criterion(output, batch_target)\r\n             \r\n@@ -499,22 +526,22 @@\n             return loss.item()\r\n                 \r\n         except RuntimeError as e:\r\n             logger.error(f\"Training step failed: {str(e)}\")\r\n-            logger.debug(\"Device mapping:\")\r\n-            logger.debug(f\"Model: {next(self.model.parameters()).device}\")\r\n+            logger.debug(\"Device and dtype mapping:\")\r\n+            logger.debug(f\"Model: device={next(self.model.parameters()).device}, dtype={next(self.model.parameters()).dtype}\")\r\n             if isinstance(batch_input, tuple):\r\n-                logger.debug(f\"Input tensors: {[b.device for b in batch_input]}\")\r\n+                logger.debug(f\"Input tensors: {[(b.device, b.dtype) for b in batch_input]}\")\r\n             else:\r\n-                logger.debug(f\"Input tensor: {batch_input.device}\")\r\n-            logger.debug(f\"Target tensor: {batch_target.device}\")\r\n+                logger.debug(f\"Input tensor: device={batch_input.device}, dtype={batch_input.dtype}\")\r\n+            logger.debug(f\"Target tensor: device={batch_target.device}, dtype={batch_target.dtype}\")\r\n             raise\r\n \r\n     def validation_step(\r\n         self,\r\n         batch_input: Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]],\r\n         batch_target: torch.Tensor,\r\n-        **kwargs\r\n+        **kwargs: Any\r\n     ) -> float:\r\n         \"\"\"Process a single validation batch.\r\n         \r\n         Args:\r\n"
                },
                {
                    "date": 1733263526099,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -491,10 +491,13 @@\n             \r\n             # Handle transformer models\r\n             if self.model_type.is_transformer and isinstance(batch_input, tuple):\r\n                 src, tgt = batch_input\r\n-                src_mask = src_mask or self.model.generate_square_subsequent_mask(src.size(1)).to(device=self.device, dtype=self.dtype)\r\n-                tgt_mask = tgt_mask or self.model.generate_square_subsequent_mask(tgt.size(1)).to(device=self.device, dtype=self.dtype)\r\n+                # Fix mask handling - don't use 'or' operator with tensors\r\n+                if src_mask is None:\r\n+                    src_mask = self.model.generate_square_subsequent_mask(src.size(1)).to(device=self.device, dtype=self.dtype)\r\n+                if tgt_mask is None:\r\n+                    tgt_mask = self.model.generate_square_subsequent_mask(tgt.size(1)).to(device=self.device, dtype=self.dtype)\r\n                 \r\n                 with autocast(device_type='cuda', dtype=self.dtype) if self.use_amp else nullcontext():\r\n                     output = self.model(src, tgt, src_mask=src_mask, tgt_mask=tgt_mask)\r\n             else:\r\n@@ -555,12 +558,17 @@\n         try:\r\n             # Handle transformer models\r\n             if self.model_type.is_transformer and isinstance(batch_input, tuple):\r\n                 src, tgt = batch_input\r\n-                # Use masks from kwargs if provided, else generate\r\n-                src_mask = kwargs.get('src_mask', self.model.generate_square_subsequent_mask(src.size(1)).to(self.device))\r\n-                tgt_mask = kwargs.get('tgt_mask', self.model.generate_square_subsequent_mask(tgt.size(1)).to(self.device))\r\n+                # Fix mask handling - don't use get() directly on kwargs\r\n+                src_mask = kwargs.get('src_mask')\r\n+                tgt_mask = kwargs.get('tgt_mask')\r\n                 \r\n+                if src_mask is None:\r\n+                    src_mask = self.model.generate_square_subsequent_mask(src.size(1)).to(self.device)\r\n+                if tgt_mask is None:\r\n+                    tgt_mask = self.model.generate_square_subsequent_mask(tgt.size(1)).to(self.device)\r\n+                \r\n                 with torch.no_grad():\r\n                     with autocast('cuda') if self.use_amp else nullcontext():\r\n                         output = self.model(src, tgt, src_mask=src_mask, tgt_mask=tgt_mask)\r\n             else:\r\n"
                },
                {
                    "date": 1733263614682,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,590 @@\n+from __future__ import annotations\r\n+import os\r\n+from pathlib import Path\r\n+from typing import Union, Any, Dict, List, Optional, Tuple, Type, cast\r\n+from contextlib import nullcontext\r\n+import torch\r\n+from torch import nn\r\n+from os import PathLike\r\n+from torch.optim.adam import Adam\r\n+from torch.optim.adamw import AdamW\r\n+from torch.optim.sgd import SGD\r\n+from torch.optim.rmsprop import RMSprop\r\n+from torch.optim import lr_scheduler\r\n+from torch.optim.optimizer import Optimizer\r\n+from torch.utils.data import Dataset as TorchDataset\r\n+from torch.utils.data import DataLoader\r\n+from torch.amp.autocast_mode import autocast  # Updated import for autocast\r\n+from torch.amp.grad_scaler import GradScaler  # Updated import for GradScaler\r\n+\r\n+from models.losses.custom_losses import MAPE\r\n+from training.base.base_trainer import TrainingEpoch\r\n+from training.reports.training_report import TrainingReport\r\n+\r\n+from ..interfaces import WrapperInterface\r\n+from ..base.base_model import BaseModel\r\n+from ..registry.model_types import ModelType\r\n+\r\n+from torch.optim.lr_scheduler import (\r\n+    OneCycleLR,\r\n+    CosineAnnealingLR,\r\n+    ReduceLROnPlateau,\r\n+    _LRScheduler,\r\n+    LRScheduler\r\n+)\r\n+\r\n+from utils.logging.logger import Logger\r\n+\r\n+# Get module logger\r\n+logger = Logger.get_logger(__name__)\r\n+\r\n+class PyTorchWrapper(WrapperInterface):\r\n+    \"\"\"Wrapper for PyTorch models providing consistent training and inference interface.\"\"\"\r\n+\r\n+    def __init__(self, model: BaseModel, model_type: ModelType, config: Dict[str, Any]):\r\n+        self.model = model\r\n+        self.model_type = model_type\r\n+        self.config = config\r\n+\r\n+        # Device handling with improved CUDA settings\r\n+        self.device = torch.device(config.get('device', 'cuda' if torch.cuda.is_available() else 'cpu'))\r\n+        if self.device.type == 'cuda':\r\n+            # Enable TF32 for better performance on Ampere GPUs (like RTX 4060)\r\n+            torch.backends.cuda.matmul.allow_tf32 = True\r\n+            torch.backends.cudnn.allow_tf32 = True\r\n+            # Enable cuDNN autotuner\r\n+            torch.backends.cudnn.benchmark = True\r\n+\r\n+        logger.info(f\"Using device: {self.device}\")\r\n+        logger.debug(f\"CUDA available: {torch.cuda.is_available()}\")\r\n+\r\n+        if torch.cuda.is_available():\r\n+            logger.debug(f\"CUDA device count: {torch.cuda.device_count()}\")\r\n+            logger.debug(f\"Current CUDA device: {torch.cuda.current_device()}\")\r\n+\r\n+        # Update mixed precision settings\r\n+        self.use_amp = config.get('use_mixed_precision', True) and self.device.type == 'cuda'\r\n+        # Change dtype to float32 for gradients but keep compute in float16\r\n+        self.dtype = torch.float32  # Changed from float16\r\n+        self.compute_dtype = torch.float16 if self.use_amp else torch.float32\r\n+        \r\n+        # Move model to device with correct dtype\r\n+        self.model = self.model.to(device=self.device, dtype=self.dtype)\r\n+        \r\n+        if self.use_amp:\r\n+            self.grad_scaler = GradScaler()\r\n+        else:\r\n+            self.grad_scaler = None\r\n+            \r\n+        # Set default tensor type for the model\r\n+        torch.set_default_dtype(self.dtype)\r\n+\r\n+        # Move model to device\r\n+        self.model = self.model.to(self.device)\r\n+        logger.debug(f\"Model device after moving: {next(self.model.parameters()).device}\")\r\n+\r\n+        # Training configuration\r\n+        self.batch_size = config.get('batch_size', 128)  # Increased for RTX 4060\r\n+        self.learning_rate = config.get('learning_rate', 1e-3)\r\n+        self.max_epochs = config.get('max_epochs', 100)\r\n+        self.gradient_clip_val = config.get('gradient_clip_val', 1.0)\r\n+        self.accumulation_steps = config.get('accumulation_steps', 4)\r\n+\r\n+        # Setup optimizer and criterion\r\n+        self.optimizer = self._setup_optimizer()\r\n+        self.criterion = self._setup_criterion()\r\n+\r\n+        # Initialize modern AMP (Automatic Mixed Precision)\r\n+        self.use_amp = config.get('use_mixed_precision', True) and self.device.type == 'cuda'\r\n+        if self.use_amp:\r\n+            self.grad_scaler = GradScaler()  # Correct GradScaler initialization\r\n+        else:\r\n+            self.grad_scaler = None\r\n+\r\n+        # Memory management settings\r\n+        if self.device.type == 'cuda':\r\n+            # Set memory allocator settings for RTX 4060 (8GB VRAM)\r\n+            torch.cuda.set_per_process_memory_fraction(0.95)  # Use 95% of available VRAM\r\n+            self.empty_cache_frequency = config.get('empty_cache_frequency', 100)\r\n+            self.max_memory_allocated = 0.0\r\n+\r\n+    def _setup_data_loader(self, dataset: TorchDataset, shuffle: bool = True) -> DataLoader:\r\n+        \"\"\"Create an optimized DataLoader for GPU training.\"\"\"\r\n+        cpu_count = os.cpu_count() or 4\r\n+        num_workers = min(4, cpu_count // 2)  # Optimized for 32GB RAM\r\n+\r\n+        data_loader_kwargs = {\r\n+            'batch_size': self.batch_size,\r\n+            'shuffle': shuffle,\r\n+            'num_workers': num_workers,\r\n+            'pin_memory': True,\r\n+            'persistent_workers': True,\r\n+            'prefetch_factor': 2,\r\n+        }\r\n+\r\n+        if self.device.type == 'cuda':\r\n+            data_loader_kwargs['pin_memory_device'] = 'cuda'  # Only pass when using CUDA\r\n+\r\n+        return DataLoader(dataset, **data_loader_kwargs)\r\n+        \r\n+    def _setup_scheduler(self, train_loader: DataLoader) -> Optional[Union[LRScheduler, ReduceLROnPlateau]]:\r\n+        \"\"\"Initialize learning rate scheduler with improved defaults.\"\"\"\r\n+        scheduler_name = self.config.get('scheduler', 'one_cycle').lower()\r\n+        scheduler_config = self.config.get('scheduler_config', {})\r\n+\r\n+        if scheduler_name == 'one_cycle':\r\n+            total_steps = self.max_epochs * len(train_loader)\r\n+            steps_per_epoch = len(train_loader)\r\n+\r\n+            return cast(LRScheduler, OneCycleLR(\r\n+                self.optimizer,\r\n+                max_lr=self.learning_rate,\r\n+                total_steps=total_steps,\r\n+                epochs=self.max_epochs,\r\n+                steps_per_epoch=steps_per_epoch,\r\n+                pct_start=scheduler_config.get('pct_start', 0.3),\r\n+                div_factor=scheduler_config.get('div_factor', 25.0),\r\n+                final_div_factor=scheduler_config.get('final_div_factor', 1000.0),\r\n+                anneal_strategy=scheduler_config.get('anneal_strategy', 'cos')\r\n+            ))\r\n+\r\n+        elif scheduler_name == 'cosine':\r\n+            return cast(LRScheduler, CosineAnnealingLR(\r\n+                self.optimizer,\r\n+                T_max=self.max_epochs,\r\n+                eta_min=scheduler_config.get('eta_min', 1e-6)\r\n+            ))\r\n+\r\n+        elif scheduler_name == 'plateau':\r\n+            return ReduceLROnPlateau(\r\n+                self.optimizer,\r\n+                mode='min',\r\n+                factor=scheduler_config.get('factor', 0.5),\r\n+                patience=scheduler_config.get('patience', 5),\r\n+                min_lr=scheduler_config.get('min_lr', 1e-6)\r\n+            )\r\n+\r\n+        elif scheduler_name == 'cosineannealinglr':\r\n+            return cast(LRScheduler, CosineAnnealingLR(\r\n+                self.optimizer,\r\n+                T_max=self.max_epochs,\r\n+                eta_min=scheduler_config.get('eta_min', 1e-6)\r\n+            ))\r\n+\r\n+        elif scheduler_name == 'steplr':\r\n+            return cast(LRScheduler, lr_scheduler.StepLR(\r\n+                self.optimizer,\r\n+                step_size=scheduler_config.get('step_size', 10),\r\n+                gamma=scheduler_config.get('gamma', 0.1)\r\n+            ))\r\n+\r\n+        else:\r\n+            logger.warning(f\"Unknown scheduler: {scheduler_name}. No scheduler will be used.\")\r\n+            return None\r\n+\r\n+    def _setup_optimizer(self) -> Optimizer:\r\n+        \"\"\"Initialize optimizer with improved defaults.\"\"\"\r\n+        optimizer_name = self.config.get('optimizer', 'adamw').lower()\r\n+        optimizer_config = self.config.get('optimizer_config', {})\r\n+\r\n+        # Base parameters all optimizers support\r\n+        base_params = {\r\n+            'lr': self.learning_rate,\r\n+            'weight_decay': optimizer_config.get('weight_decay', 0.01)  # Updated default\r\n+        }\r\n+\r\n+        # Create optimizer with appropriate parameters\r\n+        if optimizer_name == 'sgd':\r\n+            sgd_params = {\r\n+                'momentum': optimizer_config.get('momentum', 0.9),\r\n+                'dampening': optimizer_config.get('dampening', 0),\r\n+                'nesterov': optimizer_config.get('nesterov', True)  # Enable Nesterov by default\r\n+            }\r\n+            return SGD(self.model.parameters(), **base_params, **sgd_params)\r\n+\r\n+        elif optimizer_name == 'adam':\r\n+            adam_params = {\r\n+                'betas': optimizer_config.get('betas', (0.9, 0.98)),  # Updated for transformer\r\n+                'eps': optimizer_config.get('eps', 1e-8),\r\n+                'amsgrad': optimizer_config.get('amsgrad', False)  # Typically False\r\n+            }\r\n+            return Adam(self.model.parameters(), **base_params, **adam_params)\r\n+\r\n+        elif optimizer_name == 'adamw':\r\n+            adamw_params = {\r\n+                'betas': optimizer_config.get('betas', (0.9, 0.98)),  # Updated for transformer\r\n+                'eps': optimizer_config.get('eps', 1e-8),\r\n+                'amsgrad': optimizer_config.get('amsgrad', False)  # Typically False\r\n+            }\r\n+            return AdamW(self.model.parameters(), **base_params, **adamw_params)\r\n+\r\n+        elif optimizer_name == 'rmsprop':\r\n+            rmsprop_params = {\r\n+                'alpha': optimizer_config.get('alpha', 0.99),\r\n+                'eps': optimizer_config.get('eps', 1e-8),\r\n+                'momentum': optimizer_config.get('momentum', 0.9),\r\n+                'centered': optimizer_config.get('centered', False)\r\n+            }\r\n+            return RMSprop(self.model.parameters(), **base_params, **rmsprop_params)\r\n+\r\n+        else:\r\n+            raise ValueError(f\"Unknown optimizer: {optimizer_name}\")\r\n+\r\n+    def _setup_criterion(self) -> nn.Module:\r\n+        \"\"\"Initialize loss function based on config.\"\"\"\r\n+        criterion_name = self.config.get('criterion', 'mse').lower()\r\n+        criterion_config = self.config.get('criterion_config', {})\r\n+\r\n+        criteria: Dict[str, nn.Module] = {\r\n+            'mse': nn.MSELoss(**criterion_config),\r\n+            'mae': nn.L1Loss(**criterion_config),\r\n+            'mape': MAPE(**criterion_config)\r\n+        }\r\n+\r\n+        if criterion_name not in criteria:\r\n+            raise ValueError(f\"Unknown criterion: {criterion_name}\")\r\n+\r\n+        return criteria[criterion_name]\r\n+\r\n+    def train(self, train_dataset: TorchDataset, validation_dataset: Optional[TorchDataset] = None) -> TrainingReport:\r\n+        \"\"\"Train the model with modern mixed precision and memory optimization.\"\"\"\r\n+        logger.info(\"Starting training\")\r\n+        \r\n+        # Clear GPU cache before training\r\n+        if self.device.type == 'cuda':\r\n+            torch.cuda.empty_cache()\r\n+            logger.debug(f\"Initial GPU memory allocated: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\r\n+        \r\n+        self.train_loader = self._setup_data_loader(train_dataset, shuffle=True)\r\n+        val_loader = self._setup_data_loader(validation_dataset, shuffle=False) if validation_dataset else None\r\n+\r\n+        # Initialize scheduler\r\n+        self.scheduler = self._setup_scheduler(self.train_loader)\r\n+\r\n+        # Training state\r\n+        train_losses = []\r\n+        val_losses = []\r\n+        learning_rates = []\r\n+        best_val_loss = float('inf')\r\n+        patience_counter = 0\r\n+        early_stopping_patience = self.config.get('early_stopping_patience', 10)\r\n+\r\n+        for epoch in range(1, self.max_epochs + 1):\r\n+            self.model.train()\r\n+            epoch_loss = 0.0\r\n+            num_batches = 0\r\n+\r\n+            for batch_idx, (data, target) in enumerate(self.train_loader):\r\n+                try:\r\n+                    # Move data to device efficiently\r\n+                    if isinstance(data, tuple):\r\n+                        data = tuple(d.to(self.device, non_blocking=True) for d in data)\r\n+                    else:\r\n+                        data = data.to(self.device, non_blocking=True)\r\n+                    target = target.to(self.device, non_blocking=True)\r\n+\r\n+                    # Forward pass with automatic mixed precision\r\n+                    with autocast('cuda') if self.use_amp else nullcontext():\r\n+                        outputs = self.model(data)\r\n+                        loss = self.criterion(outputs, target)\r\n+                        loss = loss / self.accumulation_steps\r\n+\r\n+                    # Backward pass with gradient scaling\r\n+                    if self.use_amp and self.grad_scaler is not None:\r\n+                        self.grad_scaler.scale(loss).backward()\r\n+                    else:\r\n+                        loss.backward()\r\n+\r\n+                    # Gradient accumulation step\r\n+                    if (batch_idx + 1) % self.accumulation_steps == 0:\r\n+                        if self.gradient_clip_val > 0:\r\n+                            if self.use_amp and self.grad_scaler is not None:\r\n+                                self.grad_scaler.unscale_(self.optimizer)\r\n+                            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.gradient_clip_val)\r\n+\r\n+                        # Optimizer step with modern AMP\r\n+                        if self.use_amp and self.grad_scaler is not None:\r\n+                            self.grad_scaler.step(self.optimizer)\r\n+                            self.grad_scaler.update()\r\n+                        else:\r\n+                            self.optimizer.step()\r\n+\r\n+                        self.optimizer.zero_grad(set_to_none=True)\r\n+\r\n+                    # Memory management for RTX 4060\r\n+                    if self.device.type == 'cuda' and batch_idx % self.empty_cache_frequency == 0:\r\n+                        current_memory = torch.cuda.memory_allocated() / 1024**3\r\n+                        self.max_memory_allocated = max(self.max_memory_allocated, current_memory)\r\n+                        \r\n+                        if current_memory > 7.0:  # Conservative threshold for 8GB VRAM\r\n+                            torch.cuda.empty_cache()\r\n+\r\n+                    epoch_loss += loss.item() * self.accumulation_steps\r\n+                    num_batches += 1\r\n+\r\n+                except RuntimeError as e:\r\n+                    logger.error(f\"Error in batch {batch_idx}: {str(e)}\")\r\n+                    if \"out of memory\" in str(e):\r\n+                        torch.cuda.empty_cache()\r\n+                    continue\r\n+\r\n+            # Calculate average loss and update metrics\r\n+            avg_train_loss = epoch_loss / num_batches if num_batches > 0 else float('inf')\r\n+            train_losses.append(avg_train_loss)\r\n+            current_lr = self.optimizer.param_groups[0]['lr']\r\n+            learning_rates.append(current_lr)\r\n+\r\n+            # Validation phase\r\n+            if val_loader:\r\n+                val_loss = self._validate(val_loader)\r\n+                val_losses.append(val_loss)\r\n+\r\n+                # Early stopping logic\r\n+                if val_loss < best_val_loss:\r\n+                    best_val_loss = val_loss\r\n+                    patience_counter = 0\r\n+                    self.save('best_model.pth')\r\n+                else:\r\n+                    patience_counter += 1\r\n+                    if patience_counter >= early_stopping_patience:\r\n+                        logger.info(f\"Early stopping triggered after epoch {epoch}\")\r\n+                        break\r\n+\r\n+            # Scheduler step\r\n+            if self.scheduler:\r\n+                if isinstance(self.scheduler, ReduceLROnPlateau):\r\n+                    self.scheduler.step(val_loss if val_loader else avg_train_loss)\r\n+                else:\r\n+                    self.scheduler.step()\r\n+\r\n+            # Log progress\r\n+            logger.info(\r\n+                f\"Epoch {epoch}/{self.max_epochs} - \"\r\n+                f\"Train Loss: {avg_train_loss:.6f}\"\r\n+                + (f\", Val Loss: {val_loss:.6f}\" if val_loader else \"\")\r\n+                + f\" - LR: {current_lr:.6f}\"\r\n+            )\r\n+\r\n+        return TrainingReport(\r\n+            train_losses=train_losses,\r\n+            val_losses=val_losses,\r\n+            learning_rates=learning_rates,\r\n+            epochs=epoch,\r\n+            additional_metrics={'best_val_loss': [best_val_loss]}  # Updated to use list\r\n+        )\r\n+        \r\n+        \r\n+    def _validate(self, val_loader: DataLoader) -> float:\r\n+        \"\"\"Validate the model.\"\"\"\r\n+        self.model.eval()\r\n+        val_loss = 0.0\r\n+        num_batches = 0\r\n+\r\n+        with torch.no_grad():\r\n+            for data, target in val_loader:\r\n+                try:\r\n+                    # Move data to device\r\n+                    if isinstance(data, tuple):\r\n+                        data = tuple(d.to(self.device, non_blocking=True) for d in data)\r\n+                    else:\r\n+                        data = data.to(self.device, non_blocking=True)\r\n+                    target = target.to(self.device, non_blocking=True)\r\n+\r\n+                    # Forward pass with autocast if using mixed precision\r\n+                    with autocast('cuda') if self.use_amp else nullcontext():\r\n+                        outputs = self.model(data)\r\n+                        loss = self.criterion(outputs, target)\r\n+\r\n+                    val_loss += loss.item()\r\n+                    num_batches += 1\r\n+\r\n+                except RuntimeError as e:\r\n+                    logger.error(f\"Runtime error during validation: {str(e)}\")\r\n+                    torch.cuda.empty_cache()\r\n+                    continue  # Skip this batch\r\n+\r\n+        avg_val_loss = val_loss / num_batches if num_batches > 0 else float('inf')\r\n+        return avg_val_loss\r\n+\r\n+    def predict(self, dataset: TorchDataset) -> Tuple[torch.Tensor, torch.Tensor]:\r\n+        \"\"\"Make predictions using the model.\"\"\"\r\n+        data_loader = DataLoader(\r\n+            dataset, \r\n+            batch_size=self.batch_size,\r\n+            num_workers=min(8, (os.cpu_count() or 4) // 2),\r\n+            pin_memory=torch.cuda.is_available(),\r\n+            shuffle=False,\r\n+            persistent_workers=True,\r\n+            prefetch_factor=4\r\n+        )\r\n+\r\n+        self.model.eval()\r\n+        predictions: List[torch.Tensor] = []\r\n+        targets: List[torch.Tensor] = []\r\n+\r\n+        with torch.no_grad():\r\n+            for data, target in data_loader:\r\n+                try:\r\n+                    # Move data to device\r\n+                    if isinstance(data, tuple):\r\n+                        data = tuple(d.to(self.device, non_blocking=True) for d in data)\r\n+                    else:\r\n+                        data = data.to(self.device, non_blocking=True)\r\n+                    target = target.to(self.device, non_blocking=True)\r\n+\r\n+                    # Forward pass with autocast if using mixed precision\r\n+                    with autocast('cuda') if self.use_amp else nullcontext():\r\n+                        output = self.model(data)\r\n+\r\n+                    predictions.append(output.cpu())\r\n+                    targets.append(target.cpu())\r\n+\r\n+                except RuntimeError as e:\r\n+                    logger.error(f\"Runtime error during prediction: {str(e)}\")\r\n+                    torch.cuda.empty_cache()\r\n+                    continue  # Skip this batch\r\n+\r\n+        return torch.cat(predictions), torch.cat(targets)\r\n+\r\n+    def save(self, path: Union[str, Path]) -> None:\r\n+        \"\"\"Save model state.\"\"\"\r\n+        torch.save({\r\n+            'model_state_dict': self.model.state_dict(),\r\n+            'optimizer_state_dict': self.optimizer.state_dict(),\r\n+            'scheduler_state_dict': self.scheduler.state_dict() if self.scheduler else None,\r\n+            'grad_scaler_state_dict': self.grad_scaler.state_dict() if self.grad_scaler else None,\r\n+            'config': self.config\r\n+        }, path)\r\n+        logger.info(f\"Model saved to {path}\")\r\n+\r\n+    def load(self, path: Union[str, Path]) -> None:\r\n+        \"\"\"Load model state.\"\"\"\r\n+        checkpoint = torch.load(path, map_location=self.device)\r\n+        self.model.load_state_dict(checkpoint['model_state_dict'])\r\n+        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\r\n+        if self.scheduler and checkpoint.get('scheduler_state_dict'):\r\n+            self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\r\n+        if self.grad_scaler and checkpoint.get('grad_scaler_state_dict'):\r\n+            self.grad_scaler.load_state_dict(checkpoint['grad_scaler_state_dict'])\r\n+        logger.info(f\"Model loaded from {path}\")\r\n+\r\n+    def training_step(\r\n+        self,\r\n+        batch_input: Union[torch.Tensor, Tuple[torch.Tensor, ...]],  # Changed type hint\r\n+        batch_target: torch.Tensor,\r\n+        src_mask: Optional[torch.Tensor] = None,\r\n+        tgt_mask: Optional[torch.Tensor] = None,\r\n+        **kwargs: Any\r\n+    ) -> float:\r\n+        \"\"\"Process a single training batch with optimized GPU handling.\"\"\"\r\n+        self.optimizer.zero_grad()\r\n+        \r\n+        try:\r\n+            # Convert inputs to correct dtype\r\n+            if isinstance(batch_input, tuple):\r\n+                batch_input = tuple(b.to(device=self.device, dtype=self.dtype) for b in batch_input)\r\n+                if len(batch_input) != 2:\r\n+                    raise ValueError(f\"Expected tuple of 2 tensors but got {len(batch_input)}\")\r\n+                batch_input = cast(Tuple[torch.Tensor, torch.Tensor], batch_input)  # Add explicit cast\r\n+            else:\r\n+                batch_input = batch_input.to(device=self.device, dtype=self.dtype)\r\n+            \r\n+            batch_target = batch_target.to(device=self.device, dtype=self.dtype)\r\n+            \r\n+            # Handle transformer models\r\n+            if self.model_type.is_transformer and isinstance(batch_input, tuple):\r\n+                src, tgt = batch_input\r\n+                # Fix mask handling - don't use 'or' operator with tensors\r\n+                if src_mask is None:\r\n+                    src_mask = self.model.generate_square_subsequent_mask(src.size(1)).to(device=self.device, dtype=self.dtype)\r\n+                if tgt_mask is None:\r\n+                    tgt_mask = self.model.generate_square_subsequent_mask(tgt.size(1)).to(device=self.device, dtype=self.dtype)\r\n+                \r\n+                with autocast(device_type='cuda', dtype=self.compute_dtype) if self.use_amp else nullcontext():\r\n+                    output = self.model(src, tgt, src_mask=src_mask, tgt_mask=tgt_mask)\r\n+            else:\r\n+                if isinstance(batch_input, tuple):\r\n+                    batch_input = batch_input[0]\r\n+                with autocast(device_type='cuda', dtype=self.compute_dtype) if self.use_amp else nullcontext():\r\n+                    output = self.model(batch_input)\r\n+            \r\n+            loss = self.criterion(output, batch_target)\r\n+            \r\n+            if self.use_amp and self.grad_scaler is not None:\r\n+                self.grad_scaler.scale(loss).backward()\r\n+                self.grad_scaler.unscale_(self.optimizer)\r\n+                torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.gradient_clip_val)\r\n+                self.grad_scaler.step(self.optimizer)\r\n+                self.grad_scaler.update()\r\n+            else:\r\n+                loss.backward()\r\n+                torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.gradient_clip_val)\r\n+                self.optimizer.step()\r\n+            \r\n+            return loss.item()\r\n+                \r\n+        except RuntimeError as e:\r\n+            logger.error(f\"Training step failed: {str(e)}\")\r\n+            logger.debug(\"Device and dtype mapping:\")\r\n+            logger.debug(f\"Model: device={next(self.model.parameters()).device}, dtype={next(self.model.parameters()).dtype}\")\r\n+            if isinstance(batch_input, tuple):\r\n+                logger.debug(f\"Input tensors: {[(b.device, b.dtype) for b in batch_input]}\")\r\n+            else:\r\n+                logger.debug(f\"Input tensor: device={batch_input.device}, dtype={batch_input.dtype}\")\r\n+            logger.debug(f\"Target tensor: device={batch_target.device}, dtype={batch_target.dtype}\")\r\n+            raise\r\n+\r\n+    def validation_step(\r\n+        self,\r\n+        batch_input: Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]],\r\n+        batch_target: torch.Tensor,\r\n+        **kwargs: Any\r\n+    ) -> float:\r\n+        \"\"\"Process a single validation batch.\r\n+        \r\n+        Args:\r\n+            batch_input: Input tensor or tuple of tensors\r\n+            batch_target: Target tensor\r\n+            **kwargs: Additional arguments like masks for transformers\r\n+            \r\n+        Returns:\r\n+            float: Loss value for this batch\r\n+        \"\"\"\r\n+        try:\r\n+            # Handle transformer models\r\n+            if self.model_type.is_transformer and isinstance(batch_input, tuple):\r\n+                src, tgt = batch_input\r\n+                # Fix mask handling - don't use get() directly on kwargs\r\n+                src_mask = kwargs.get('src_mask')\r\n+                tgt_mask = kwargs.get('tgt_mask')\r\n+                \r\n+                if src_mask is None:\r\n+                    src_mask = self.model.generate_square_subsequent_mask(src.size(1)).to(self.device)\r\n+                if tgt_mask is None:\r\n+                    tgt_mask = self.model.generate_square_subsequent_mask(tgt.size(1)).to(self.device)\r\n+                \r\n+                with torch.no_grad():\r\n+                    with autocast('cuda') if self.use_amp else nullcontext():\r\n+                        output = self.model(src, tgt, src_mask=src_mask, tgt_mask=tgt_mask)\r\n+            else:\r\n+                if isinstance(batch_input, tuple):\r\n+                    batch_input = batch_input[0]\r\n+                with torch.no_grad():\r\n+                    with autocast('cuda') if self.use_amp else nullcontext():\r\n+                        output = self.model(batch_input)\r\n+                \r\n+                loss = self.criterion(output, batch_target)\r\n+\r\n+            loss = self.criterion(output, batch_target)\r\n+            return loss.item()\r\n+                \r\n+        except RuntimeError as e:\r\n+            logger.error(f\"Validation step failed: {str(e)}\")\r\n+            logger.debug(\"Device mapping:\")\r\n+            logger.debug(f\"Model: {next(self.model.parameters()).device}\")\r\n+            if isinstance(batch_input, tuple):\r\n+                logger.debug(f\"Input tensors: {[b.device for b in batch_input]}\")\r\n+            else:\r\n+                logger.debug(f\"Input tensor: {batch_input.device}\")\r\n+            logger.debug(f\"Target tensor: {batch_target.device}\")\r\n+            raise\r\n"
                },
                {
                    "date": 1733263878384,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,587 @@\n+from __future__ import annotations\r\n+import os\r\n+from pathlib import Path\r\n+from typing import Union, Any, Dict, List, Optional, Tuple, Type, cast\r\n+from contextlib import nullcontext\r\n+import torch\r\n+from torch import nn\r\n+from os import PathLike\r\n+from torch.optim.adam import Adam\r\n+from torch.optim.adamw import AdamW\r\n+from torch.optim.sgd import SGD\r\n+from torch.optim.rmsprop import RMSprop\r\n+from torch.optim import lr_scheduler\r\n+from torch.optim.optimizer import Optimizer\r\n+from torch.utils.data import Dataset as TorchDataset\r\n+from torch.utils.data import DataLoader\r\n+from torch.amp.autocast_mode import autocast  # Updated import for autocast\r\n+from torch.amp.grad_scaler import GradScaler  # Updated import for GradScaler\r\n+\r\n+from models.losses.custom_losses import MAPE\r\n+from training.base.base_trainer import TrainingEpoch\r\n+from training.reports.training_report import TrainingReport\r\n+\r\n+from ..interfaces import WrapperInterface\r\n+from ..base.base_model import BaseModel\r\n+from ..registry.model_types import ModelType\r\n+\r\n+from torch.optim.lr_scheduler import (\r\n+    OneCycleLR,\r\n+    CosineAnnealingLR,\r\n+    ReduceLROnPlateau,\r\n+    _LRScheduler,\r\n+    LRScheduler\r\n+)\r\n+\r\n+from utils.logging.logger import Logger\r\n+\r\n+# Get module logger\r\n+logger = Logger.get_logger(__name__)\r\n+\r\n+class PyTorchWrapper(WrapperInterface):\r\n+    \"\"\"Wrapper for PyTorch models providing consistent training and inference interface.\"\"\"\r\n+\r\n+    def __init__(self, model: BaseModel, model_type: ModelType, config: Dict[str, Any]):\r\n+        self.model = model\r\n+        self.model_type = model_type\r\n+        self.config = config\r\n+\r\n+        # Device handling with improved CUDA settings\r\n+        self.device = torch.device(config.get('device', 'cuda' if torch.cuda.is_available() else 'cpu'))\r\n+        if self.device.type == 'cuda':\r\n+            # Enable TF32 for better performance on Ampere GPUs (like RTX 4060)\r\n+            torch.backends.cuda.matmul.allow_tf32 = True\r\n+            torch.backends.cudnn.allow_tf32 = True\r\n+            # Enable cuDNN autotuner\r\n+            torch.backends.cudnn.benchmark = True\r\n+\r\n+        logger.info(f\"Using device: {self.device}\")\r\n+        logger.debug(f\"CUDA available: {torch.cuda.is_available()}\")\r\n+\r\n+        if torch.cuda.is_available():\r\n+            logger.debug(f\"CUDA device count: {torch.cuda.device_count()}\")\r\n+            logger.debug(f\"Current CUDA device: {torch.cuda.current_device()}\")\r\n+\r\n+        # Update mixed precision settings\r\n+        self.use_amp = config.get('use_mixed_precision', True) and self.device.type == 'cuda'\r\n+        self.dtype = torch.float32  # Base dtype for model parameters\r\n+        self.compute_dtype = torch.float16 if self.use_amp else torch.float32  # dtype for computations\r\n+        \r\n+        # Move model to device with correct dtype\r\n+        self.model = self.model.to(device=self.device, dtype=self.dtype)\r\n+        \r\n+        # Initialize grad scaler exactly once\r\n+        self.grad_scaler = GradScaler(enabled=True) if self.use_amp else None\r\n+            \r\n+        # Set default tensor type for the model\r\n+        torch.set_default_dtype(self.dtype)\r\n+\r\n+        # Move model to device\r\n+        self.model = self.model.to(self.device)\r\n+        logger.debug(f\"Model device after moving: {next(self.model.parameters()).device}\")\r\n+\r\n+        # Training configuration\r\n+        self.batch_size = config.get('batch_size', 128)  # Increased for RTX 4060\r\n+        self.learning_rate = config.get('learning_rate', 1e-3)\r\n+        self.max_epochs = config.get('max_epochs', 100)\r\n+        self.gradient_clip_val = config.get('gradient_clip_val', 1.0)\r\n+        self.accumulation_steps = config.get('accumulation_steps', 4)\r\n+\r\n+        # Setup optimizer and criterion\r\n+        self.optimizer = self._setup_optimizer()\r\n+        self.criterion = self._setup_criterion()\r\n+\r\n+        # Memory management settings\r\n+        if self.device.type == 'cuda':\r\n+            # Set memory allocator settings for RTX 4060 (8GB VRAM)\r\n+            torch.cuda.set_per_process_memory_fraction(0.95)  # Use 95% of available VRAM\r\n+            self.empty_cache_frequency = config.get('empty_cache_frequency', 100)\r\n+            self.max_memory_allocated = 0.0\r\n+\r\n+    def _setup_data_loader(self, dataset: TorchDataset, shuffle: bool = True) -> DataLoader:\r\n+        \"\"\"Create an optimized DataLoader for GPU training.\"\"\"\r\n+        cpu_count = os.cpu_count() or 4\r\n+        num_workers = min(4, cpu_count // 2)  # Optimized for 32GB RAM\r\n+\r\n+        data_loader_kwargs = {\r\n+            'batch_size': self.batch_size,\r\n+            'shuffle': shuffle,\r\n+            'num_workers': num_workers,\r\n+            'pin_memory': True,\r\n+            'persistent_workers': True,\r\n+            'prefetch_factor': 2,\r\n+        }\r\n+\r\n+        if self.device.type == 'cuda':\r\n+            data_loader_kwargs['pin_memory_device'] = 'cuda'  # Only pass when using CUDA\r\n+\r\n+        return DataLoader(dataset, **data_loader_kwargs)\r\n+        \r\n+    def _setup_scheduler(self, train_loader: DataLoader) -> Optional[Union[LRScheduler, ReduceLROnPlateau]]:\r\n+        \"\"\"Initialize learning rate scheduler with improved defaults.\"\"\"\r\n+        scheduler_name = self.config.get('scheduler', 'one_cycle').lower()\r\n+        scheduler_config = self.config.get('scheduler_config', {})\r\n+\r\n+        if scheduler_name == 'one_cycle':\r\n+            total_steps = self.max_epochs * len(train_loader)\r\n+            steps_per_epoch = len(train_loader)\r\n+\r\n+            return cast(LRScheduler, OneCycleLR(\r\n+                self.optimizer,\r\n+                max_lr=self.learning_rate,\r\n+                total_steps=total_steps,\r\n+                epochs=self.max_epochs,\r\n+                steps_per_epoch=steps_per_epoch,\r\n+                pct_start=scheduler_config.get('pct_start', 0.3),\r\n+                div_factor=scheduler_config.get('div_factor', 25.0),\r\n+                final_div_factor=scheduler_config.get('final_div_factor', 1000.0),\r\n+                anneal_strategy=scheduler_config.get('anneal_strategy', 'cos')\r\n+            ))\r\n+\r\n+        elif scheduler_name == 'cosine':\r\n+            return cast(LRScheduler, CosineAnnealingLR(\r\n+                self.optimizer,\r\n+                T_max=self.max_epochs,\r\n+                eta_min=scheduler_config.get('eta_min', 1e-6)\r\n+            ))\r\n+\r\n+        elif scheduler_name == 'plateau':\r\n+            return ReduceLROnPlateau(\r\n+                self.optimizer,\r\n+                mode='min',\r\n+                factor=scheduler_config.get('factor', 0.5),\r\n+                patience=scheduler_config.get('patience', 5),\r\n+                min_lr=scheduler_config.get('min_lr', 1e-6)\r\n+            )\r\n+\r\n+        elif scheduler_name == 'cosineannealinglr':\r\n+            return cast(LRScheduler, CosineAnnealingLR(\r\n+                self.optimizer,\r\n+                T_max=self.max_epochs,\r\n+                eta_min=scheduler_config.get('eta_min', 1e-6)\r\n+            ))\r\n+\r\n+        elif scheduler_name == 'steplr':\r\n+            return cast(LRScheduler, lr_scheduler.StepLR(\r\n+                self.optimizer,\r\n+                step_size=scheduler_config.get('step_size', 10),\r\n+                gamma=scheduler_config.get('gamma', 0.1)\r\n+            ))\r\n+\r\n+        else:\r\n+            logger.warning(f\"Unknown scheduler: {scheduler_name}. No scheduler will be used.\")\r\n+            return None\r\n+\r\n+    def _setup_optimizer(self) -> Optimizer:\r\n+        \"\"\"Initialize optimizer with improved defaults.\"\"\"\r\n+        optimizer_name = self.config.get('optimizer', 'adamw').lower()\r\n+        optimizer_config = self.config.get('optimizer_config', {})\r\n+\r\n+        # Base parameters all optimizers support\r\n+        base_params = {\r\n+            'lr': self.learning_rate,\r\n+            'weight_decay': optimizer_config.get('weight_decay', 0.01)  # Updated default\r\n+        }\r\n+\r\n+        # Create optimizer with appropriate parameters\r\n+        if optimizer_name == 'sgd':\r\n+            sgd_params = {\r\n+                'momentum': optimizer_config.get('momentum', 0.9),\r\n+                'dampening': optimizer_config.get('dampening', 0),\r\n+                'nesterov': optimizer_config.get('nesterov', True)  # Enable Nesterov by default\r\n+            }\r\n+            return SGD(self.model.parameters(), **base_params, **sgd_params)\r\n+\r\n+        elif optimizer_name == 'adam':\r\n+            adam_params = {\r\n+                'betas': optimizer_config.get('betas', (0.9, 0.98)),  # Updated for transformer\r\n+                'eps': optimizer_config.get('eps', 1e-8),\r\n+                'amsgrad': optimizer_config.get('amsgrad', False)  # Typically False\r\n+            }\r\n+            return Adam(self.model.parameters(), **base_params, **adam_params)\r\n+\r\n+        elif optimizer_name == 'adamw':\r\n+            adamw_params = {\r\n+                'betas': optimizer_config.get('betas', (0.9, 0.98)),  # Updated for transformer\r\n+                'eps': optimizer_config.get('eps', 1e-8),\r\n+                'amsgrad': optimizer_config.get('amsgrad', False)  # Typically False\r\n+            }\r\n+            return AdamW(self.model.parameters(), **base_params, **adamw_params)\r\n+\r\n+        elif optimizer_name == 'rmsprop':\r\n+            rmsprop_params = {\r\n+                'alpha': optimizer_config.get('alpha', 0.99),\r\n+                'eps': optimizer_config.get('eps', 1e-8),\r\n+                'momentum': optimizer_config.get('momentum', 0.9),\r\n+                'centered': optimizer_config.get('centered', False)\r\n+            }\r\n+            return RMSprop(self.model.parameters(), **base_params, **rmsprop_params)\r\n+\r\n+        else:\r\n+            raise ValueError(f\"Unknown optimizer: {optimizer_name}\")\r\n+\r\n+    def _setup_criterion(self) -> nn.Module:\r\n+        \"\"\"Initialize loss function based on config.\"\"\"\r\n+        criterion_name = self.config.get('criterion', 'mse').lower()\r\n+        criterion_config = self.config.get('criterion_config', {})\r\n+\r\n+        criteria: Dict[str, nn.Module] = {\r\n+            'mse': nn.MSELoss(**criterion_config),\r\n+            'mae': nn.L1Loss(**criterion_config),\r\n+            'mape': MAPE(**criterion_config)\r\n+        }\r\n+\r\n+        if criterion_name not in criteria:\r\n+            raise ValueError(f\"Unknown criterion: {criterion_name}\")\r\n+\r\n+        return criteria[criterion_name]\r\n+\r\n+    def train(self, train_dataset: TorchDataset, validation_dataset: Optional[TorchDataset] = None) -> TrainingReport:\r\n+        \"\"\"Train the model with modern mixed precision and memory optimization.\"\"\"\r\n+        logger.info(\"Starting training\")\r\n+        \r\n+        # Clear GPU cache before training\r\n+        if self.device.type == 'cuda':\r\n+            torch.cuda.empty_cache()\r\n+            logger.debug(f\"Initial GPU memory allocated: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\r\n+        \r\n+        self.train_loader = self._setup_data_loader(train_dataset, shuffle=True)\r\n+        val_loader = self._setup_data_loader(validation_dataset, shuffle=False) if validation_dataset else None\r\n+\r\n+        # Initialize scheduler\r\n+        self.scheduler = self._setup_scheduler(self.train_loader)\r\n+\r\n+        # Training state\r\n+        train_losses = []\r\n+        val_losses = []\r\n+        learning_rates = []\r\n+        best_val_loss = float('inf')\r\n+        patience_counter = 0\r\n+        early_stopping_patience = self.config.get('early_stopping_patience', 10)\r\n+\r\n+        for epoch in range(1, self.max_epochs + 1):\r\n+            self.model.train()\r\n+            epoch_loss = 0.0\r\n+            num_batches = 0\r\n+\r\n+            for batch_idx, (data, target) in enumerate(self.train_loader):\r\n+                try:\r\n+                    # Move data to device efficiently\r\n+                    if isinstance(data, tuple):\r\n+                        data = tuple(d.to(self.device, non_blocking=True) for d in data)\r\n+                    else:\r\n+                        data = data.to(self.device, non_blocking=True)\r\n+                    target = target.to(self.device, non_blocking=True)\r\n+\r\n+                    # Forward pass with automatic mixed precision\r\n+                    with autocast('cuda') if self.use_amp else nullcontext():\r\n+                        outputs = self.model(data)\r\n+                        loss = self.criterion(outputs, target)\r\n+                        loss = loss / self.accumulation_steps\r\n+\r\n+                    # Backward pass with gradient scaling\r\n+                    if self.use_amp and self.grad_scaler is not None:\r\n+                        self.grad_scaler.scale(loss).backward()\r\n+                    else:\r\n+                        loss.backward()\r\n+\r\n+                    # Gradient accumulation step\r\n+                    if (batch_idx + 1) % self.accumulation_steps == 0:\r\n+                        if self.gradient_clip_val > 0:\r\n+                            if self.use_amp and self.grad_scaler is not None:\r\n+                                self.grad_scaler.unscale_(self.optimizer)\r\n+                            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.gradient_clip_val)\r\n+\r\n+                        # Optimizer step with modern AMP\r\n+                        if self.use_amp and self.grad_scaler is not None:\r\n+                            self.grad_scaler.step(self.optimizer)\r\n+                            self.grad_scaler.update()\r\n+                        else:\r\n+                            self.optimizer.step()\r\n+\r\n+                        self.optimizer.zero_grad(set_to_none=True)\r\n+\r\n+                    # Memory management for RTX 4060\r\n+                    if self.device.type == 'cuda' and batch_idx % self.empty_cache_frequency == 0:\r\n+                        current_memory = torch.cuda.memory_allocated() / 1024**3\r\n+                        self.max_memory_allocated = max(self.max_memory_allocated, current_memory)\r\n+                        \r\n+                        if current_memory > 7.0:  # Conservative threshold for 8GB VRAM\r\n+                            torch.cuda.empty_cache()\r\n+\r\n+                    epoch_loss += loss.item() * self.accumulation_steps\r\n+                    num_batches += 1\r\n+\r\n+                except RuntimeError as e:\r\n+                    logger.error(f\"Error in batch {batch_idx}: {str(e)}\")\r\n+                    if \"out of memory\" in str(e):\r\n+                        torch.cuda.empty_cache()\r\n+                    continue\r\n+\r\n+            # Calculate average loss and update metrics\r\n+            avg_train_loss = epoch_loss / num_batches if num_batches > 0 else float('inf')\r\n+            train_losses.append(avg_train_loss)\r\n+            current_lr = self.optimizer.param_groups[0]['lr']\r\n+            learning_rates.append(current_lr)\r\n+\r\n+            # Validation phase\r\n+            if val_loader:\r\n+                val_loss = self._validate(val_loader)\r\n+                val_losses.append(val_loss)\r\n+\r\n+                # Early stopping logic\r\n+                if val_loss < best_val_loss:\r\n+                    best_val_loss = val_loss\r\n+                    patience_counter = 0\r\n+                    self.save('best_model.pth')\r\n+                else:\r\n+                    patience_counter += 1\r\n+                    if patience_counter >= early_stopping_patience:\r\n+                        logger.info(f\"Early stopping triggered after epoch {epoch}\")\r\n+                        break\r\n+\r\n+            # Scheduler step\r\n+            if self.scheduler:\r\n+                if isinstance(self.scheduler, ReduceLROnPlateau):\r\n+                    self.scheduler.step(val_loss if val_loader else avg_train_loss)\r\n+                else:\r\n+                    self.scheduler.step()\r\n+\r\n+            # Log progress\r\n+            logger.info(\r\n+                f\"Epoch {epoch}/{self.max_epochs} - \"\r\n+                f\"Train Loss: {avg_train_loss:.6f}\"\r\n+                + (f\", Val Loss: {val_loss:.6f}\" if val_loader else \"\")\r\n+                + f\" - LR: {current_lr:.6f}\"\r\n+            )\r\n+\r\n+        return TrainingReport(\r\n+            train_losses=train_losses,\r\n+            val_losses=val_losses,\r\n+            learning_rates=learning_rates,\r\n+            epochs=epoch,\r\n+            additional_metrics={'best_val_loss': [best_val_loss]}  # Updated to use list\r\n+        )\r\n+        \r\n+        \r\n+    def _validate(self, val_loader: DataLoader) -> float:\r\n+        \"\"\"Validate the model.\"\"\"\r\n+        self.model.eval()\r\n+        val_loss = 0.0\r\n+        num_batches = 0\r\n+\r\n+        with torch.no_grad():\r\n+            for data, target in val_loader:\r\n+                try:\r\n+                    # Move data to device\r\n+                    if isinstance(data, tuple):\r\n+                        data = tuple(d.to(self.device, non_blocking=True) for d in data)\r\n+                    else:\r\n+                        data = data.to(self.device, non_blocking=True)\r\n+                    target = target.to(self.device, non_blocking=True)\r\n+\r\n+                    # Forward pass with autocast if using mixed precision\r\n+                    with autocast('cuda') if self.use_amp else nullcontext():\r\n+                        outputs = self.model(data)\r\n+                        loss = self.criterion(outputs, target)\r\n+\r\n+                    val_loss += loss.item()\r\n+                    num_batches += 1\r\n+\r\n+                except RuntimeError as e:\r\n+                    logger.error(f\"Runtime error during validation: {str(e)}\")\r\n+                    torch.cuda.empty_cache()\r\n+                    continue  # Skip this batch\r\n+\r\n+        avg_val_loss = val_loss / num_batches if num_batches > 0 else float('inf')\r\n+        return avg_val_loss\r\n+\r\n+    def predict(self, dataset: TorchDataset) -> Tuple[torch.Tensor, torch.Tensor]:\r\n+        \"\"\"Make predictions using the model.\"\"\"\r\n+        data_loader = DataLoader(\r\n+            dataset, \r\n+            batch_size=self.batch_size,\r\n+            num_workers=min(8, (os.cpu_count() or 4) // 2),\r\n+            pin_memory=torch.cuda.is_available(),\r\n+            shuffle=False,\r\n+            persistent_workers=True,\r\n+            prefetch_factor=4\r\n+        )\r\n+\r\n+        self.model.eval()\r\n+        predictions: List[torch.Tensor] = []\r\n+        targets: List[torch.Tensor] = []\r\n+\r\n+        with torch.no_grad():\r\n+            for data, target in data_loader:\r\n+                try:\r\n+                    # Move data to device\r\n+                    if isinstance(data, tuple):\r\n+                        data = tuple(d.to(self.device, non_blocking=True) for d in data)\r\n+                    else:\r\n+                        data = data.to(self.device, non_blocking=True)\r\n+                    target = target.to(self.device, non_blocking=True)\r\n+\r\n+                    # Forward pass with autocast if using mixed precision\r\n+                    with autocast('cuda') if self.use_amp else nullcontext():\r\n+                        output = self.model(data)\r\n+\r\n+                    predictions.append(output.cpu())\r\n+                    targets.append(target.cpu())\r\n+\r\n+                except RuntimeError as e:\r\n+                    logger.error(f\"Runtime error during prediction: {str(e)}\")\r\n+                    torch.cuda.empty_cache()\r\n+                    continue  # Skip this batch\r\n+\r\n+        return torch.cat(predictions), torch.cat(targets)\r\n+\r\n+    def save(self, path: Union[str, Path]) -> None:\r\n+        \"\"\"Save model state.\"\"\"\r\n+        torch.save({\r\n+            'model_state_dict': self.model.state_dict(),\r\n+            'optimizer_state_dict': self.optimizer.state_dict(),\r\n+            'scheduler_state_dict': self.scheduler.state_dict() if self.scheduler else None,\r\n+            'grad_scaler_state_dict': self.grad_scaler.state_dict() if self.grad_scaler else None,\r\n+            'config': self.config\r\n+        }, path)\r\n+        logger.info(f\"Model saved to {path}\")\r\n+\r\n+    def load(self, path: Union[str, Path]) -> None:\r\n+        \"\"\"Load model state.\"\"\"\r\n+        checkpoint = torch.load(path, map_location=self.device)\r\n+        self.model.load_state_dict(checkpoint['model_state_dict'])\r\n+        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\r\n+        if self.scheduler and checkpoint.get('scheduler_state_dict'):\r\n+            self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\r\n+        if self.grad_scaler and checkpoint.get('grad_scaler_state_dict'):\r\n+            self.grad_scaler.load_state_dict(checkpoint['grad_scaler_state_dict'])\r\n+        logger.info(f\"Model loaded from {path}\")\r\n+\r\n+    def training_step(\r\n+        self,\r\n+        batch_input: Union[torch.Tensor, Tuple[torch.Tensor, ...]],  # Changed type hint\r\n+        batch_target: torch.Tensor,\r\n+        src_mask: Optional[torch.Tensor] = None,\r\n+        tgt_mask: Optional[torch.Tensor] = None,\r\n+        **kwargs: Any\r\n+    ) -> float:\r\n+        \"\"\"Process a single training batch with optimized GPU handling.\"\"\"\r\n+        self.optimizer.zero_grad(set_to_none=True)\r\n+        \r\n+        try:\r\n+            # Convert inputs to correct dtype (always float32 for parameters)\r\n+            if isinstance(batch_input, tuple):\r\n+                batch_input = tuple(b.to(device=self.device, dtype=self.dtype) for b in batch_input)\r\n+                if len(batch_input) != 2:\r\n+                    raise ValueError(f\"Expected tuple of 2 tensors but got {len(batch_input)}\")\r\n+                batch_input = cast(Tuple[torch.Tensor, torch.Tensor], batch_input)  # Add explicit cast\r\n+            else:\r\n+                batch_input = batch_input.to(device=self.device, dtype=self.dtype)\r\n+            \r\n+            batch_target = batch_target.to(device=self.device, dtype=self.dtype)\r\n+            \r\n+            # Handle transformer models\r\n+            if self.model_type.is_transformer and isinstance(batch_input, tuple):\r\n+                src, tgt = batch_input\r\n+                src_mask = (src_mask.to(device=self.device, dtype=self.dtype) \r\n+                           if src_mask is not None \r\n+                           else self.model.generate_square_subsequent_mask(src.size(1)).to(device=self.device, dtype=self.dtype))\r\n+                tgt_mask = (tgt_mask.to(device=self.device, dtype=self.dtype)\r\n+                           if tgt_mask is not None\r\n+                           else self.model.generate_square_subsequent_mask(tgt.size(1)).to(device=self.device, dtype=self.dtype))\r\n+                \r\n+                with autocast(device_type='cuda', dtype=self.compute_dtype) if self.use_amp else nullcontext():\r\n+                    output = self.model(src, tgt, src_mask=src_mask, tgt_mask=tgt_mask)\r\n+                    loss = self.criterion(output, batch_target)\r\n+            else:\r\n+                if isinstance(batch_input, tuple):\r\n+                    batch_input = batch_input[0]\r\n+                with autocast(device_type='cuda', dtype=self.compute_dtype) if self.use_amp else nullcontext():\r\n+                    output = self.model(batch_input)\r\n+                    loss = self.criterion(output, batch_target)\r\n+            \r\n+            # Modified gradient handling with proper checks\r\n+            if self.use_amp and self.grad_scaler is not None:\r\n+                assert self.grad_scaler is not None  # For type checker\r\n+                self.grad_scaler.scale(loss).backward()\r\n+                \r\n+                if self.gradient_clip_val > 0:\r\n+                    self.grad_scaler.unscale_(self.optimizer)\r\n+                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.gradient_clip_val)\r\n+                \r\n+                self.grad_scaler.step(self.optimizer)\r\n+                self.grad_scaler.update()\r\n+            else:\r\n+                loss.backward()\r\n+                if self.gradient_clip_val > 0:\r\n+                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.gradient_clip_val)\r\n+                self.optimizer.step()\r\n+            \r\n+            return loss.item()\r\n+                \r\n+        except RuntimeError as e:\r\n+            logger.error(f\"Training step failed: {str(e)}\")\r\n+            logger.debug(\"Device and dtype mapping:\")\r\n+            logger.debug(f\"Model: device={next(self.model.parameters()).device}, dtype={next(self.model.parameters()).dtype}\")\r\n+            if isinstance(batch_input, tuple):\r\n+                logger.debug(f\"Input tensors: {[(b.device, b.dtype) for b in batch_input]}\")\r\n+            else:\r\n+                logger.debug(f\"Input tensor: device={batch_input.device}, dtype={batch_input.dtype}\")\r\n+            logger.debug(f\"Target tensor: device={batch_target.device}, dtype={batch_target.dtype}\")\r\n+            raise\r\n+\r\n+    def validation_step(\r\n+        self,\r\n+        batch_input: Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]],\r\n+        batch_target: torch.Tensor,\r\n+        **kwargs: Any\r\n+    ) -> float:\r\n+        \"\"\"Process a single validation batch.\r\n+        \r\n+        Args:\r\n+            batch_input: Input tensor or tuple of tensors\r\n+            batch_target: Target tensor\r\n+            **kwargs: Additional arguments like masks for transformers\r\n+            \r\n+        Returns:\r\n+            float: Loss value for this batch\r\n+        \"\"\"\r\n+        try:\r\n+            # Handle transformer models\r\n+            if self.model_type.is_transformer and isinstance(batch_input, tuple):\r\n+                src, tgt = batch_input\r\n+                # Fix mask handling - don't use get() directly on kwargs\r\n+                src_mask = kwargs.get('src_mask')\r\n+                tgt_mask = kwargs.get('tgt_mask')\r\n+                \r\n+                if src_mask is None:\r\n+                    src_mask = self.model.generate_square_subsequent_mask(src.size(1)).to(self.device)\r\n+                if tgt_mask is None:\r\n+                    tgt_mask = self.model.generate_square_subsequent_mask(tgt.size(1)).to(self.device)\r\n+                \r\n+                with torch.no_grad():\r\n+                    with autocast('cuda') if self.use_amp else nullcontext():\r\n+                        output = self.model(src, tgt, src_mask=src_mask, tgt_mask=tgt_mask)\r\n+            else:\r\n+                if isinstance(batch_input, tuple):\r\n+                    batch_input = batch_input[0]\r\n+                with torch.no_grad():\r\n+                    with autocast('cuda') if self.use_amp else nullcontext():\r\n+                        output = self.model(batch_input)\r\n+                \r\n+                loss = self.criterion(output, batch_target)\r\n+\r\n+            loss = self.criterion(output, batch_target)\r\n+            return loss.item()\r\n+                \r\n+        except RuntimeError as e:\r\n+            logger.error(f\"Validation step failed: {str(e)}\")\r\n+            logger.debug(\"Device mapping:\")\r\n+            logger.debug(f\"Model: {next(self.model.parameters()).device}\")\r\n+            if isinstance(batch_input, tuple):\r\n+                logger.debug(f\"Input tensors: {[b.device for b in batch_input]}\")\r\n+            else:\r\n+                logger.debug(f\"Input tensor: {batch_input.device}\")\r\n+            logger.debug(f\"Target tensor: {batch_target.device}\")\r\n+            raise\r\n"
                },
                {
                    "date": 1733266118341,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,589 @@\n+from __future__ import annotations\r\n+import os\r\n+from pathlib import Path\r\n+from typing import Union, Any, Dict, List, Optional, Tuple, Type, cast\r\n+from contextlib import nullcontext\r\n+import torch\r\n+from torch import nn\r\n+from os import PathLike\r\n+from torch.optim.adam import Adam\r\n+from torch.optim.adamw import AdamW\r\n+from torch.optim.sgd import SGD\r\n+from torch.optim.rmsprop import RMSprop\r\n+from torch.optim import lr_scheduler\r\n+from torch.optim.optimizer import Optimizer\r\n+from torch.utils.data import Dataset as TorchDataset\r\n+from torch.utils.data import DataLoader\r\n+from torch.amp.autocast_mode import autocast  # Updated import for autocast\r\n+from torch.amp.grad_scaler import GradScaler  # Updated import for GradScaler\r\n+\r\n+from models.losses.custom_losses import MAPE\r\n+from training.base.base_trainer import TrainingEpoch\r\n+from training.reports.training_report import TrainingReport\r\n+\r\n+from ..interfaces import WrapperInterface\r\n+from ..base.base_model import BaseModel\r\n+from ..registry.model_types import ModelType\r\n+\r\n+from torch.optim.lr_scheduler import (\r\n+    OneCycleLR,\r\n+    CosineAnnealingLR,\r\n+    ReduceLROnPlateau,\r\n+    _LRScheduler,\r\n+    LRScheduler\r\n+)\r\n+\r\n+from utils.logging.logger import Logger\r\n+\r\n+# Get module logger\r\n+logger = Logger.get_logger(__name__)\r\n+\r\n+class PyTorchWrapper(WrapperInterface):\r\n+    \"\"\"Wrapper for PyTorch models providing consistent training and inference interface.\"\"\"\r\n+\r\n+    def __init__(self, model: BaseModel, model_type: ModelType, config: Dict[str, Any]):\r\n+        self.model = model\r\n+        self.model_type = model_type\r\n+        self.config = config\r\n+\r\n+        # Device handling with improved CUDA settings\r\n+        self.device = torch.device(config.get('device', 'cuda' if torch.cuda.is_available() else 'cpu'))\r\n+        if self.device.type == 'cuda':\r\n+            # Enable TF32 for better performance on Ampere GPUs (like RTX 4060)\r\n+            torch.backends.cuda.matmul.allow_tf32 = True\r\n+            torch.backends.cudnn.allow_tf32 = True\r\n+            # Enable cuDNN autotuner\r\n+            torch.backends.cudnn.benchmark = True\r\n+\r\n+        logger.info(f\"Using device: {self.device}\")\r\n+        logger.debug(f\"CUDA available: {torch.cuda.is_available()}\")\r\n+\r\n+        if torch.cuda.is_available():\r\n+            logger.debug(f\"CUDA device count: {torch.cuda.device_count()}\")\r\n+            logger.debug(f\"Current CUDA device: {torch.cuda.current_device()}\")\r\n+\r\n+        # Update mixed precision settings\r\n+        self.use_amp = config.get('use_mixed_precision', True) and self.device.type == 'cuda'\r\n+        self.dtype = torch.float32  # Base dtype for model parameters\r\n+        self.compute_dtype = torch.float16 if self.use_amp else torch.float32  # dtype for computations\r\n+        \r\n+        # Move model to device with correct dtype\r\n+        self.model = self.model.to(device=self.device, dtype=self.dtype)\r\n+        \r\n+        # Initialize grad scaler exactly once\r\n+        self.grad_scaler = GradScaler(enabled=True) if self.use_amp else None\r\n+            \r\n+        # Set default tensor type for the model\r\n+        torch.set_default_dtype(self.dtype)\r\n+\r\n+        # Move model to device\r\n+        self.model = self.model.to(self.device)\r\n+        logger.debug(f\"Model device after moving: {next(self.model.parameters()).device}\")\r\n+\r\n+        # Training configuration\r\n+        self.batch_size = config.get('batch_size', 128)  # Increased for RTX 4060\r\n+        self.learning_rate = config.get('learning_rate', 1e-3)\r\n+        self.max_epochs = config.get('max_epochs', 100)\r\n+        self.gradient_clip_val = config.get('gradient_clip_val', 1.0)\r\n+        self.accumulation_steps = config.get('accumulation_steps', 4)\r\n+\r\n+        # Setup optimizer and criterion\r\n+        self.optimizer = self._setup_optimizer()\r\n+        self.criterion = self._setup_criterion()\r\n+\r\n+        # Memory management settings\r\n+        if self.device.type == 'cuda':\r\n+            # Set memory allocator settings for RTX 4060 (8GB VRAM)\r\n+            torch.cuda.set_per_process_memory_fraction(0.95)  # Use 95% of available VRAM\r\n+            self.empty_cache_frequency = config.get('empty_cache_frequency', 100)\r\n+            self.max_memory_allocated = 0.0\r\n+            \r\n+        \r\n+\r\n+    def _setup_data_loader(self, dataset: TorchDataset, shuffle: bool = True) -> DataLoader:\r\n+        \"\"\"Create an optimized DataLoader for GPU training.\"\"\"\r\n+        cpu_count = os.cpu_count() or 4\r\n+        num_workers = min(4, cpu_count // 2)  # Optimized for 32GB RAM\r\n+\r\n+        data_loader_kwargs = {\r\n+            'batch_size': self.batch_size,\r\n+            'shuffle': shuffle,\r\n+            'num_workers': num_workers,\r\n+            'pin_memory': True,\r\n+            'persistent_workers': True,\r\n+            'prefetch_factor': 2,\r\n+        }\r\n+\r\n+        if self.device.type == 'cuda':\r\n+            data_loader_kwargs['pin_memory_device'] = 'cuda'  # Only pass when using CUDA\r\n+\r\n+        return DataLoader(dataset, **data_loader_kwargs)\r\n+        \r\n+    def _setup_scheduler(self, train_loader: DataLoader) -> Optional[Union[LRScheduler, ReduceLROnPlateau]]:\r\n+        \"\"\"Initialize learning rate scheduler with improved defaults.\"\"\"\r\n+        scheduler_name = self.config.get('scheduler', 'one_cycle').lower()\r\n+        scheduler_config = self.config.get('scheduler_config', {})\r\n+\r\n+        if scheduler_name == 'one_cycle':\r\n+            total_steps = self.max_epochs * len(train_loader)\r\n+            steps_per_epoch = len(train_loader)\r\n+\r\n+            return cast(LRScheduler, OneCycleLR(\r\n+                self.optimizer,\r\n+                max_lr=self.learning_rate,\r\n+                total_steps=total_steps,\r\n+                epochs=self.max_epochs,\r\n+                steps_per_epoch=steps_per_epoch,\r\n+                pct_start=scheduler_config.get('pct_start', 0.3),\r\n+                div_factor=scheduler_config.get('div_factor', 25.0),\r\n+                final_div_factor=scheduler_config.get('final_div_factor', 1000.0),\r\n+                anneal_strategy=scheduler_config.get('anneal_strategy', 'cos')\r\n+            ))\r\n+\r\n+        elif scheduler_name == 'cosine':\r\n+            return cast(LRScheduler, CosineAnnealingLR(\r\n+                self.optimizer,\r\n+                T_max=self.max_epochs,\r\n+                eta_min=scheduler_config.get('eta_min', 1e-6)\r\n+            ))\r\n+\r\n+        elif scheduler_name == 'plateau':\r\n+            return ReduceLROnPlateau(\r\n+                self.optimizer,\r\n+                mode='min',\r\n+                factor=scheduler_config.get('factor', 0.5),\r\n+                patience=scheduler_config.get('patience', 5),\r\n+                min_lr=scheduler_config.get('min_lr', 1e-6)\r\n+            )\r\n+\r\n+        elif scheduler_name == 'cosineannealinglr':\r\n+            return cast(LRScheduler, CosineAnnealingLR(\r\n+                self.optimizer,\r\n+                T_max=self.max_epochs,\r\n+                eta_min=scheduler_config.get('eta_min', 1e-6)\r\n+            ))\r\n+\r\n+        elif scheduler_name == 'steplr':\r\n+            return cast(LRScheduler, lr_scheduler.StepLR(\r\n+                self.optimizer,\r\n+                step_size=scheduler_config.get('step_size', 10),\r\n+                gamma=scheduler_config.get('gamma', 0.1)\r\n+            ))\r\n+\r\n+        else:\r\n+            logger.warning(f\"Unknown scheduler: {scheduler_name}. No scheduler will be used.\")\r\n+            return None\r\n+\r\n+    def _setup_optimizer(self) -> Optimizer:\r\n+        \"\"\"Initialize optimizer with improved defaults.\"\"\"\r\n+        optimizer_name = self.config.get('optimizer', 'adamw').lower()\r\n+        optimizer_config = self.config.get('optimizer_config', {})\r\n+\r\n+        # Base parameters all optimizers support\r\n+        base_params = {\r\n+            'lr': self.learning_rate,\r\n+            'weight_decay': optimizer_config.get('weight_decay', 0.01)  # Updated default\r\n+        }\r\n+\r\n+        # Create optimizer with appropriate parameters\r\n+        if optimizer_name == 'sgd':\r\n+            sgd_params = {\r\n+                'momentum': optimizer_config.get('momentum', 0.9),\r\n+                'dampening': optimizer_config.get('dampening', 0),\r\n+                'nesterov': optimizer_config.get('nesterov', True)  # Enable Nesterov by default\r\n+            }\r\n+            return SGD(self.model.parameters(), **base_params, **sgd_params)\r\n+\r\n+        elif optimizer_name == 'adam':\r\n+            adam_params = {\r\n+                'betas': optimizer_config.get('betas', (0.9, 0.98)),  # Updated for transformer\r\n+                'eps': optimizer_config.get('eps', 1e-8),\r\n+                'amsgrad': optimizer_config.get('amsgrad', False)  # Typically False\r\n+            }\r\n+            return Adam(self.model.parameters(), **base_params, **adam_params)\r\n+\r\n+        elif optimizer_name == 'adamw':\r\n+            adamw_params = {\r\n+                'betas': optimizer_config.get('betas', (0.9, 0.98)),  # Updated for transformer\r\n+                'eps': optimizer_config.get('eps', 1e-8),\r\n+                'amsgrad': optimizer_config.get('amsgrad', False)  # Typically False\r\n+            }\r\n+            return AdamW(self.model.parameters(), **base_params, **adamw_params)\r\n+\r\n+        elif optimizer_name == 'rmsprop':\r\n+            rmsprop_params = {\r\n+                'alpha': optimizer_config.get('alpha', 0.99),\r\n+                'eps': optimizer_config.get('eps', 1e-8),\r\n+                'momentum': optimizer_config.get('momentum', 0.9),\r\n+                'centered': optimizer_config.get('centered', False)\r\n+            }\r\n+            return RMSprop(self.model.parameters(), **base_params, **rmsprop_params)\r\n+\r\n+        else:\r\n+            raise ValueError(f\"Unknown optimizer: {optimizer_name}\")\r\n+\r\n+    def _setup_criterion(self) -> nn.Module:\r\n+        \"\"\"Initialize loss function based on config.\"\"\"\r\n+        criterion_name = self.config.get('criterion', 'mse').lower()\r\n+        criterion_config = self.config.get('criterion_config', {})\r\n+\r\n+        criteria: Dict[str, nn.Module] = {\r\n+            'mse': nn.MSELoss(**criterion_config),\r\n+            'mae': nn.L1Loss(**criterion_config),\r\n+            'mape': MAPE(**criterion_config)\r\n+        }\r\n+\r\n+        if criterion_name not in criteria:\r\n+            raise ValueError(f\"Unknown criterion: {criterion_name}\")\r\n+\r\n+        return criteria[criterion_name]\r\n+\r\n+    def train(self, train_dataset: TorchDataset, validation_dataset: Optional[TorchDataset] = None) -> TrainingReport:\r\n+        \"\"\"Train the model with modern mixed precision and memory optimization.\"\"\"\r\n+        logger.info(\"Starting training\")\r\n+        \r\n+        # Clear GPU cache before training\r\n+        if self.device.type == 'cuda':\r\n+            torch.cuda.empty_cache()\r\n+            logger.debug(f\"Initial GPU memory allocated: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\r\n+        \r\n+        self.train_loader = self._setup_data_loader(train_dataset, shuffle=True)\r\n+        val_loader = self._setup_data_loader(validation_dataset, shuffle=False) if validation_dataset else None\r\n+\r\n+        # Initialize scheduler\r\n+        self.scheduler = self._setup_scheduler(self.train_loader)\r\n+\r\n+        # Training state\r\n+        train_losses = []\r\n+        val_losses = []\r\n+        learning_rates = []\r\n+        best_val_loss = float('inf')\r\n+        patience_counter = 0\r\n+        early_stopping_patience = self.config.get('early_stopping_patience', 10)\r\n+\r\n+        for epoch in range(1, self.max_epochs + 1):\r\n+            self.model.train()\r\n+            epoch_loss = 0.0\r\n+            num_batches = 0\r\n+\r\n+            for batch_idx, (data, target) in enumerate(self.train_loader):\r\n+                try:\r\n+                    # Move data to device efficiently\r\n+                    if isinstance(data, tuple):\r\n+                        data = tuple(d.to(self.device, non_blocking=True) for d in data)\r\n+                    else:\r\n+                        data = data.to(self.device, non_blocking=True)\r\n+                    target = target.to(self.device, non_blocking=True)\r\n+\r\n+                    # Forward pass with automatic mixed precision\r\n+                    with autocast('cuda') if self.use_amp else nullcontext():\r\n+                        outputs = self.model(data)\r\n+                        loss = self.criterion(outputs, target)\r\n+                        loss = loss / self.accumulation_steps\r\n+\r\n+                    # Backward pass with gradient scaling\r\n+                    if self.use_amp and self.grad_scaler is not None:\r\n+                        self.grad_scaler.scale(loss).backward()\r\n+                    else:\r\n+                        loss.backward()\r\n+\r\n+                    # Gradient accumulation step\r\n+                    if (batch_idx + 1) % self.accumulation_steps == 0:\r\n+                        if self.gradient_clip_val > 0:\r\n+                            if self.use_amp and self.grad_scaler is not None:\r\n+                                self.grad_scaler.unscale_(self.optimizer)\r\n+                            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.gradient_clip_val)\r\n+\r\n+                        # Optimizer step with modern AMP\r\n+                        if self.use_amp and self.grad_scaler is not None:\r\n+                            self.grad_scaler.step(self.optimizer)\r\n+                            self.grad_scaler.update()\r\n+                        else:\r\n+                            self.optimizer.step()\r\n+\r\n+                        self.optimizer.zero_grad(set_to_none=True)\r\n+\r\n+                    # Memory management for RTX 4060\r\n+                    if self.device.type == 'cuda' and batch_idx % self.empty_cache_frequency == 0:\r\n+                        current_memory = torch.cuda.memory_allocated() / 1024**3\r\n+                        self.max_memory_allocated = max(self.max_memory_allocated, current_memory)\r\n+                        \r\n+                        if current_memory > 7.0:  # Conservative threshold for 8GB VRAM\r\n+                            torch.cuda.empty_cache()\r\n+\r\n+                    epoch_loss += loss.item() * self.accumulation_steps\r\n+                    num_batches += 1\r\n+\r\n+                except RuntimeError as e:\r\n+                    logger.error(f\"Error in batch {batch_idx}: {str(e)}\")\r\n+                    if \"out of memory\" in str(e):\r\n+                        torch.cuda.empty_cache()\r\n+                    continue\r\n+\r\n+            # Calculate average loss and update metrics\r\n+            avg_train_loss = epoch_loss / num_batches if num_batches > 0 else float('inf')\r\n+            train_losses.append(avg_train_loss)\r\n+            current_lr = self.optimizer.param_groups[0]['lr']\r\n+            learning_rates.append(current_lr)\r\n+\r\n+            # Validation phase\r\n+            if val_loader:\r\n+                val_loss = self._validate(val_loader)\r\n+                val_losses.append(val_loss)\r\n+\r\n+                # Early stopping logic\r\n+                if val_loss < best_val_loss:\r\n+                    best_val_loss = val_loss\r\n+                    patience_counter = 0\r\n+                    self.save('best_model.pth')\r\n+                else:\r\n+                    patience_counter += 1\r\n+                    if patience_counter >= early_stopping_patience:\r\n+                        logger.info(f\"Early stopping triggered after epoch {epoch}\")\r\n+                        break\r\n+\r\n+            # Scheduler step\r\n+            if self.scheduler:\r\n+                if isinstance(self.scheduler, ReduceLROnPlateau):\r\n+                    self.scheduler.step(val_loss if val_loader else avg_train_loss)\r\n+                else:\r\n+                    self.scheduler.step()\r\n+\r\n+            # Log progress\r\n+            logger.info(\r\n+                f\"Epoch {epoch}/{self.max_epochs} - \"\r\n+                f\"Train Loss: {avg_train_loss:.6f}\"\r\n+                + (f\", Val Loss: {val_loss:.6f}\" if val_loader else \"\")\r\n+                + f\" - LR: {current_lr:.6f}\"\r\n+            )\r\n+\r\n+        return TrainingReport(\r\n+            train_losses=train_losses,\r\n+            val_losses=val_losses,\r\n+            learning_rates=learning_rates,\r\n+            epochs=epoch,\r\n+            additional_metrics={'best_val_loss': [best_val_loss]}  # Updated to use list\r\n+        )\r\n+        \r\n+        \r\n+    def _validate(self, val_loader: DataLoader) -> float:\r\n+        \"\"\"Validate the model.\"\"\"\r\n+        self.model.eval()\r\n+        val_loss = 0.0\r\n+        num_batches = 0\r\n+\r\n+        with torch.no_grad():\r\n+            for data, target in val_loader:\r\n+                try:\r\n+                    # Move data to device\r\n+                    if isinstance(data, tuple):\r\n+                        data = tuple(d.to(self.device, non_blocking=True) for d in data)\r\n+                    else:\r\n+                        data = data.to(self.device, non_blocking=True)\r\n+                    target = target.to(self.device, non_blocking=True)\r\n+\r\n+                    # Forward pass with autocast if using mixed precision\r\n+                    with autocast('cuda') if self.use_amp else nullcontext():\r\n+                        outputs = self.model(data)\r\n+                        loss = self.criterion(outputs, target)\r\n+\r\n+                    val_loss += loss.item()\r\n+                    num_batches += 1\r\n+\r\n+                except RuntimeError as e:\r\n+                    logger.error(f\"Runtime error during validation: {str(e)}\")\r\n+                    torch.cuda.empty_cache()\r\n+                    continue  # Skip this batch\r\n+\r\n+        avg_val_loss = val_loss / num_batches if num_batches > 0 else float('inf')\r\n+        return avg_val_loss\r\n+\r\n+    def predict(self, dataset: TorchDataset) -> Tuple[torch.Tensor, torch.Tensor]:\r\n+        \"\"\"Make predictions using the model.\"\"\"\r\n+        data_loader = DataLoader(\r\n+            dataset, \r\n+            batch_size=self.batch_size,\r\n+            num_workers=min(8, (os.cpu_count() or 4) // 2),\r\n+            pin_memory=torch.cuda.is_available(),\r\n+            shuffle=False,\r\n+            persistent_workers=True,\r\n+            prefetch_factor=4\r\n+        )\r\n+\r\n+        self.model.eval()\r\n+        predictions: List[torch.Tensor] = []\r\n+        targets: List[torch.Tensor] = []\r\n+\r\n+        with torch.no_grad():\r\n+            for data, target in data_loader:\r\n+                try:\r\n+                    # Move data to device\r\n+                    if isinstance(data, tuple):\r\n+                        data = tuple(d.to(self.device, non_blocking=True) for d in data)\r\n+                    else:\r\n+                        data = data.to(self.device, non_blocking=True)\r\n+                    target = target.to(self.device, non_blocking=True)\r\n+\r\n+                    # Forward pass with autocast if using mixed precision\r\n+                    with autocast('cuda') if self.use_amp else nullcontext():\r\n+                        output = self.model(data)\r\n+\r\n+                    predictions.append(output.cpu())\r\n+                    targets.append(target.cpu())\r\n+\r\n+                except RuntimeError as e:\r\n+                    logger.error(f\"Runtime error during prediction: {str(e)}\")\r\n+                    torch.cuda.empty_cache()\r\n+                    continue  # Skip this batch\r\n+\r\n+        return torch.cat(predictions), torch.cat(targets)\r\n+\r\n+    def save(self, path: Union[str, Path]) -> None:\r\n+        \"\"\"Save model state.\"\"\"\r\n+        torch.save({\r\n+            'model_state_dict': self.model.state_dict(),\r\n+            'optimizer_state_dict': self.optimizer.state_dict(),\r\n+            'scheduler_state_dict': self.scheduler.state_dict() if self.scheduler else None,\r\n+            'grad_scaler_state_dict': self.grad_scaler.state_dict() if self.grad_scaler else None,\r\n+            'config': self.config\r\n+        }, path)\r\n+        logger.info(f\"Model saved to {path}\")\r\n+\r\n+    def load(self, path: Union[str, Path]) -> None:\r\n+        \"\"\"Load model state.\"\"\"\r\n+        checkpoint = torch.load(path, map_location=self.device)\r\n+        self.model.load_state_dict(checkpoint['model_state_dict'])\r\n+        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\r\n+        if self.scheduler and checkpoint.get('scheduler_state_dict'):\r\n+            self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\r\n+        if self.grad_scaler and checkpoint.get('grad_scaler_state_dict'):\r\n+            self.grad_scaler.load_state_dict(checkpoint['grad_scaler_state_dict'])\r\n+        logger.info(f\"Model loaded from {path}\")\r\n+\r\n+    def training_step(\r\n+        self,\r\n+        batch_input: Union[torch.Tensor, Tuple[torch.Tensor, ...]],  # Changed type hint\r\n+        batch_target: torch.Tensor,\r\n+        src_mask: Optional[torch.Tensor] = None,\r\n+        tgt_mask: Optional[torch.Tensor] = None,\r\n+        **kwargs: Any\r\n+    ) -> float:\r\n+        \"\"\"Process a single training batch with optimized GPU handling.\"\"\"\r\n+        self.optimizer.zero_grad(set_to_none=True)\r\n+        \r\n+        try:\r\n+            # Convert inputs to correct dtype (always float32 for parameters)\r\n+            if isinstance(batch_input, tuple):\r\n+                batch_input = tuple(b.to(device=self.device, dtype=self.dtype) for b in batch_input)\r\n+                if len(batch_input) != 2:\r\n+                    raise ValueError(f\"Expected tuple of 2 tensors but got {len(batch_input)}\")\r\n+                batch_input = cast(Tuple[torch.Tensor, torch.Tensor], batch_input)  # Add explicit cast\r\n+            else:\r\n+                batch_input = batch_input.to(device=self.device, dtype=self.dtype)\r\n+            \r\n+            batch_target = batch_target.to(device=self.device, dtype=self.dtype)\r\n+            \r\n+            # Handle transformer models\r\n+            if self.model_type.is_transformer and isinstance(batch_input, tuple):\r\n+                src, tgt = batch_input\r\n+                src_mask = (src_mask.to(device=self.device, dtype=self.dtype) \r\n+                           if src_mask is not None \r\n+                           else self.model.generate_square_subsequent_mask(src.size(1)).to(device=self.device, dtype=self.dtype))\r\n+                tgt_mask = (tgt_mask.to(device=self.device, dtype=self.dtype)\r\n+                           if tgt_mask is not None\r\n+                           else self.model.generate_square_subsequent_mask(tgt.size(1)).to(device=self.device, dtype=self.dtype))\r\n+                \r\n+                with autocast(device_type='cuda', dtype=self.compute_dtype) if self.use_amp else nullcontext():\r\n+                    output = self.model(src, tgt, src_mask=src_mask, tgt_mask=tgt_mask)\r\n+                    loss = self.criterion(output, batch_target)\r\n+            else:\r\n+                if isinstance(batch_input, tuple):\r\n+                    batch_input = batch_input[0]\r\n+                with autocast(device_type='cuda', dtype=self.compute_dtype) if self.use_amp else nullcontext():\r\n+                    output = self.model(batch_input)\r\n+                    loss = self.criterion(output, batch_target)\r\n+            \r\n+            # Modified gradient handling with proper checks\r\n+            if self.use_amp and self.grad_scaler is not None:\r\n+                assert self.grad_scaler is not None  # For type checker\r\n+                self.grad_scaler.scale(loss).backward()\r\n+                \r\n+                if self.gradient_clip_val > 0:\r\n+                    self.grad_scaler.unscale_(self.optimizer)\r\n+                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.gradient_clip_val)\r\n+                \r\n+                self.grad_scaler.step(self.optimizer)\r\n+                self.grad_scaler.update()\r\n+            else:\r\n+                loss.backward()\r\n+                if self.gradient_clip_val > 0:\r\n+                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.gradient_clip_val)\r\n+                self.optimizer.step()\r\n+            \r\n+            return loss.item()\r\n+                \r\n+        except RuntimeError as e:\r\n+            logger.error(f\"Training step failed: {str(e)}\")\r\n+            logger.debug(\"Device and dtype mapping:\")\r\n+            logger.debug(f\"Model: device={next(self.model.parameters()).device}, dtype={next(self.model.parameters()).dtype}\")\r\n+            if isinstance(batch_input, tuple):\r\n+                logger.debug(f\"Input tensors: {[(b.device, b.dtype) for b in batch_input]}\")\r\n+            else:\r\n+                logger.debug(f\"Input tensor: device={batch_input.device}, dtype={batch_input.dtype}\")\r\n+            logger.debug(f\"Target tensor: device={batch_target.device}, dtype={batch_target.dtype}\")\r\n+            raise\r\n+\r\n+    def validation_step(\r\n+        self,\r\n+        batch_input: Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]],\r\n+        batch_target: torch.Tensor,\r\n+        **kwargs: Any\r\n+    ) -> float:\r\n+        \"\"\"Process a single validation batch.\r\n+        \r\n+        Args:\r\n+            batch_input: Input tensor or tuple of tensors\r\n+            batch_target: Target tensor\r\n+            **kwargs: Additional arguments like masks for transformers\r\n+            \r\n+        Returns:\r\n+            float: Loss value for this batch\r\n+        \"\"\"\r\n+        try:\r\n+            # Handle transformer models\r\n+            if self.model_type.is_transformer and isinstance(batch_input, tuple):\r\n+                src, tgt = batch_input\r\n+                # Fix mask handling - don't use get() directly on kwargs\r\n+                src_mask = kwargs.get('src_mask')\r\n+                tgt_mask = kwargs.get('tgt_mask')\r\n+                \r\n+                if src_mask is None:\r\n+                    src_mask = self.model.generate_square_subsequent_mask(src.size(1)).to(self.device)\r\n+                if tgt_mask is None:\r\n+                    tgt_mask = self.model.generate_square_subsequent_mask(tgt.size(1)).to(self.device)\r\n+                \r\n+                with torch.no_grad():\r\n+                    with autocast('cuda') if self.use_amp else nullcontext():\r\n+                        output = self.model(src, tgt, src_mask=src_mask, tgt_mask=tgt_mask)\r\n+            else:\r\n+                if isinstance(batch_input, tuple):\r\n+                    batch_input = batch_input[0]\r\n+                with torch.no_grad():\r\n+                    with autocast('cuda') if self.use_amp else nullcontext():\r\n+                        output = self.model(batch_input)\r\n+                \r\n+                loss = self.criterion(output, batch_target)\r\n+\r\n+            loss = self.criterion(output, batch_target)\r\n+            return loss.item()\r\n+                \r\n+        except RuntimeError as e:\r\n+            logger.error(f\"Validation step failed: {str(e)}\")\r\n+            logger.debug(\"Device mapping:\")\r\n+            logger.debug(f\"Model: {next(self.model.parameters()).device}\")\r\n+            if isinstance(batch_input, tuple):\r\n+                logger.debug(f\"Input tensors: {[b.device for b in batch_input]}\")\r\n+            else:\r\n+                logger.debug(f\"Input tensor: {batch_input.device}\")\r\n+            logger.debug(f\"Target tensor: {batch_target.device}\")\r\n+            raise\r\n"
                }
            ],
            "date": 1733261789213,
            "name": "Commit-0",
            "content": "# models/wrappers/pytorch_wrapper.py\r\n\r\nfrom __future__ import annotations\r\nimport os\r\nfrom pathlib import Path\r\nfrom typing import Union, Any, Dict, List, Optional, Tuple, Type, cast\r\nimport torch\r\nfrom torch import nn\r\nfrom os import PathLike\r\nfrom torch.optim.adam import Adam\r\nfrom torch.optim.adamw import AdamW\r\nfrom torch.optim.sgd import SGD\r\nfrom torch.optim.rmsprop import RMSprop\r\nfrom torch.optim import lr_scheduler\r\nfrom torch.optim.optimizer import Optimizer\r\nfrom torch.utils.data import Dataset as TorchDataset  # Rename to avoid conflict\r\nfrom torch.utils.data import DataLoader\r\nfrom torch.cuda.amp import GradScaler, autocast\r\nimport gc\r\n\r\nfrom models.losses.custom_losses import MAPE\r\nfrom training.base.base_trainer import TrainingEpoch\r\nfrom training.reports.training_report import TrainingReport\r\n\r\nfrom ..interfaces import WrapperInterface\r\nfrom ..base.base_model import BaseModel\r\nfrom ..registry.model_types import ModelType\r\nfrom torch.optim.lr_scheduler import (\r\n    OneCycleLR,\r\n    CosineAnnealingLR,\r\n    ReduceLROnPlateau,\r\n    _LRScheduler,\r\n    LRScheduler\r\n)\r\n\r\nfrom utils.logging.logger import Logger\r\n\r\n# Get module logger\r\nlogger = Logger.get_logger(__name__)\r\n\r\nclass PyTorchWrapper(WrapperInterface):\r\n    \"\"\"Wrapper for PyTorch models providing consistent training and inference interface.\"\"\"\r\n\r\n    def __init__(self, model: BaseModel, model_type: ModelType, config: Dict[str, Any]):\r\n        self.model = model\r\n        self.model_type = model_type\r\n        self.config = config\r\n\r\n        # Device handling\r\n        self.device = torch.device(\r\n            config.get('device', 'cuda' if torch.cuda.is_available() else 'cpu')\r\n        )\r\n        logger.info(f\"Using device: {self.device}\")\r\n        logger.debug(f\"CUDA available: {torch.cuda.is_available()}\")\r\n        if torch.cuda.is_available():\r\n            logger.debug(f\"CUDA device count: {torch.cuda.device_count()}\")\r\n            logger.debug(f\"Current CUDA device: {torch.cuda.current_device()}\")\r\n\r\n        # Move model to device\r\n        self.model = self.model.to(self.device)\r\n        logger.debug(f\"Model device after moving: {next(self.model.parameters()).device}\")\r\n\r\n        # Training configuration\r\n        self.batch_size = config.get('batch_size', 32)\r\n        self.learning_rate = config.get('learning_rate', 1e-3)\r\n        self.max_epochs = config.get('max_epochs', 100)\r\n        self.gradient_clip_val = config.get('gradient_clip_val', 1.0)\r\n        self.accumulation_steps = config.get('accumulation_steps', 1)  # For gradient accumulation\r\n\r\n        # Setup optimizer and criterion\r\n        self.optimizer = self._setup_optimizer()\r\n        self.criterion = self._setup_criterion()\r\n\r\n        # Setup scheduler\r\n        self.scheduler = None  # Will be initialized in train()\r\n\r\n        # Initialize GradScaler for mixed precision\r\n        self.use_mixed_precision = config.get('use_mixed_precision', True)\r\n        if self.use_mixed_precision:\r\n            self.scaler = amp.GradScaler()\r\n            self.autocast = torch.amp.autocast('cuda', enabled=True)\r\n        else:\r\n            self.scaler = None\r\n            self.autocast = None\r\n\r\n        # Optimized batch and memory settings\r\n        self.batch_size = config.get('batch_size', 128)  # Increased for RTX 4060\r\n        self.accumulation_steps = config.get('accumulation_steps', 4)  # Added gradient accumulation\r\n        self.prefetch_factor = config.get('prefetch_factor', 2)\r\n        \r\n        # Memory optimization settings\r\n        self.empty_cache_frequency = config.get('empty_cache_frequency', 100)\r\n        self.max_memory_allocated = 0.0\r\n        \r\n        # Configure optimizer with larger batch size\r\n        self.learning_rate = config.get('learning_rate', 2e-4)  # Adjusted for larger batch size\r\n        \r\n        if torch.cuda.is_available():\r\n            # Set memory allocator settings for better efficiency\r\n            torch.cuda.set_per_process_memory_fraction(0.95)  # Use 95% of available VRAM\r\n            torch.backends.cudnn.benchmark = True  # Enable cuDNN autotuner\r\n            torch.backends.cuda.matmul.allow_tf32 = True  # Enable TF32 for faster training\r\n\r\n    def _setup_scheduler(self, train_loader: DataLoader) -> Optional[Union[LRScheduler, ReduceLROnPlateau]]:\r\n        \"\"\"Initialize learning rate scheduler with improved defaults.\"\"\"\r\n        scheduler_name = self.config.get('scheduler', 'one_cycle').lower()\r\n        scheduler_config = self.config.get('scheduler_config', {})\r\n\r\n        if scheduler_name == 'one_cycle':\r\n            total_steps = self.max_epochs * len(train_loader)\r\n            steps_per_epoch = len(train_loader)\r\n\r\n            return cast(LRScheduler, OneCycleLR(\r\n                self.optimizer,\r\n                max_lr=self.learning_rate,\r\n                total_steps=total_steps,\r\n                epochs=self.max_epochs,\r\n                steps_per_epoch=steps_per_epoch,\r\n                pct_start=scheduler_config.get('pct_start', 0.3),\r\n                div_factor=scheduler_config.get('div_factor', 25.0),\r\n                final_div_factor=scheduler_config.get('final_div_factor', 1000.0),\r\n                anneal_strategy=scheduler_config.get('anneal_strategy', 'cos')\r\n            ))\r\n\r\n        elif scheduler_name == 'cosine':\r\n            return cast(LRScheduler, CosineAnnealingLR(\r\n                self.optimizer,\r\n                T_max=self.max_epochs,\r\n                eta_min=scheduler_config.get('eta_min', 1e-6)\r\n            ))\r\n\r\n        elif scheduler_name == 'plateau':\r\n            return ReduceLROnPlateau(\r\n                self.optimizer,\r\n                mode='min',\r\n                factor=scheduler_config.get('factor', 0.5),\r\n                patience=scheduler_config.get('patience', 5),\r\n                min_lr=scheduler_config.get('min_lr', 1e-6)\r\n            )\r\n\r\n        elif scheduler_name == 'cosineannealinglr':\r\n            return cast(LRScheduler, CosineAnnealingLR(\r\n                self.optimizer,\r\n                T_max=self.max_epochs,\r\n                eta_min=scheduler_config.get('eta_min', 1e-6)\r\n            ))\r\n\r\n        elif scheduler_name == 'steplr':\r\n            return cast(LRScheduler, lr_scheduler.StepLR(\r\n                self.optimizer,\r\n                step_size=scheduler_config.get('step_size', 10),\r\n                gamma=scheduler_config.get('gamma', 0.1)\r\n            ))\r\n\r\n        else:\r\n            logger.warning(f\"Unknown scheduler: {scheduler_name}. No scheduler will be used.\")\r\n            return None\r\n\r\n    def _setup_optimizer(self) -> Optimizer:\r\n        \"\"\"Initialize optimizer with improved defaults.\"\"\"\r\n        optimizer_name = self.config.get('optimizer', 'adamw').lower()\r\n        optimizer_config = self.config.get('optimizer_config', {})\r\n\r\n        # Base parameters all optimizers support\r\n        base_params = {\r\n            'lr': self.learning_rate,\r\n            'weight_decay': optimizer_config.get('weight_decay', 0.01)  # Updated default\r\n        }\r\n\r\n        # Create optimizer with appropriate parameters\r\n        if optimizer_name == 'sgd':\r\n            sgd_params = {\r\n                'momentum': optimizer_config.get('momentum', 0.9),\r\n                'dampening': optimizer_config.get('dampening', 0),\r\n                'nesterov': optimizer_config.get('nesterov', True)  # Enable Nesterov by default\r\n            }\r\n            return SGD(self.model.parameters(), **base_params, **sgd_params)\r\n\r\n        elif optimizer_name == 'adam':\r\n            adam_params = {\r\n                'betas': optimizer_config.get('betas', (0.9, 0.98)),  # Updated for transformer\r\n                'eps': optimizer_config.get('eps', 1e-8),\r\n                'amsgrad': optimizer_config.get('amsgrad', False)  # Typically False\r\n            }\r\n            return Adam(self.model.parameters(), **base_params, **adam_params)\r\n\r\n        elif optimizer_name == 'adamw':\r\n            adamw_params = {\r\n                'betas': optimizer_config.get('betas', (0.9, 0.98)),  # Updated for transformer\r\n                'eps': optimizer_config.get('eps', 1e-8),\r\n                'amsgrad': optimizer_config.get('amsgrad', False)  # Typically False\r\n            }\r\n            return AdamW(self.model.parameters(), **base_params, **adamw_params)\r\n\r\n        elif optimizer_name == 'rmsprop':\r\n            rmsprop_params = {\r\n                'alpha': optimizer_config.get('alpha', 0.99),\r\n                'eps': optimizer_config.get('eps', 1e-8),\r\n                'momentum': optimizer_config.get('momentum', 0.9),\r\n                'centered': optimizer_config.get('centered', False)\r\n            }\r\n            return RMSprop(self.model.parameters(), **base_params, **rmsprop_params)\r\n\r\n        else:\r\n            raise ValueError(f\"Unknown optimizer: {optimizer_name}\")\r\n\r\n    def _setup_criterion(self) -> nn.Module:\r\n        \"\"\"Initialize loss function based on config.\"\"\"\r\n        criterion_name = self.config.get('criterion', 'mse').lower()\r\n        criterion_config = self.config.get('criterion_config', {})\r\n\r\n        criteria: Dict[str, nn.Module] = {\r\n            'mse': nn.MSELoss(**criterion_config),\r\n            'mae': nn.L1Loss(**criterion_config),\r\n            'mape': MAPE(**criterion_config)\r\n        }\r\n\r\n        if criterion_name not in criteria:\r\n            raise ValueError(f\"Unknown criterion: {criterion_name}\")\r\n\r\n        return criteria[criterion_name]\r\n\r\n    def train(\r\n            self,\r\n            train_dataset: TorchDataset,\r\n            validation_dataset: Optional[TorchDataset] = None\r\n    ) -> TrainingReport:\r\n        \"\"\"Train the model with proper device handling.\"\"\"\r\n        \r\n        logger.info(\"Starting training\")\r\n        logger.debug(f\"Training device setup: CUDA available: {torch.cuda.is_available()}, Using device: {self.device}\")\r\n        \r\n        # Clear GPU cache before training\r\n        if torch.cuda.is_available():\r\n            torch.cuda.empty_cache()\r\n            logger.debug(f\"Initial GPU memory allocated: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\r\n        \r\n        # Ensure model is on correct device\r\n        self.model = self.model.to(self.device)\r\n        \r\n        # Setup DataLoader with optimized parameters\r\n        cpu_count = os.cpu_count() or 4  # Use 4 as fallback if cpu_count is None\r\n        num_workers = min(8, cpu_count // 2)  # Dynamic determination\r\n        self.train_loader = DataLoader(\r\n            train_dataset,\r\n            batch_size=self.batch_size,\r\n            shuffle=True,\r\n            num_workers=num_workers,\r\n            pin_memory=torch.cuda.is_available(),\r\n            persistent_workers=True,\r\n            prefetch_factor=4\r\n        )\r\n\r\n        val_loader = None\r\n        if validation_dataset is not None:\r\n            val_loader = DataLoader(\r\n                validation_dataset,\r\n                batch_size=self.batch_size,\r\n                shuffle=False,\r\n                num_workers=num_workers,\r\n                pin_memory=torch.cuda.is_available(),\r\n                persistent_workers=True,\r\n                prefetch_factor=4\r\n            )\r\n\r\n        # Initialize scheduler\r\n        self.scheduler = self._setup_scheduler(self.train_loader)\r\n\r\n        # Initialize training loop variables\r\n        train_losses = []\r\n        val_losses = []\r\n        learning_rates = []\r\n        best_val_loss = float('inf')\r\n        patience_counter = 0\r\n        early_stopping_patience = self.config.get('early_stopping_patience', 10)\r\n\r\n        # Initialize GradScaler if using mixed precision\r\n        scaler = self.scaler\r\n\r\n        for epoch in range(1, self.max_epochs + 1):\r\n            self.model.train()\r\n            epoch_loss = 0.0\r\n            num_batches = 0\r\n\r\n            for batch_idx, (data, target) in enumerate(self.train_loader, 1):\r\n                try:\r\n                    # Move data to device\r\n                    if isinstance(data, tuple):\r\n                        data = tuple(d.to(self.device, non_blocking=True) for d in data)\r\n                    else:\r\n                        data = data.to(self.device, non_blocking=True)\r\n                    target = target.to(self.device, non_blocking=True)\r\n\r\n                    # Forward pass with autocast for mixed precision\r\n                    with autocast() if scaler else torch.no_grad():\r\n                        outputs = self.model(data)\r\n                        loss = self.criterion(outputs, target)\r\n                        loss = loss / self.accumulation_steps  # Normalize loss for accumulation\r\n\r\n                    # Backward pass\r\n                    if scaler:\r\n                        scaler.scale(loss).backward()\r\n                    else:\r\n                        loss.backward()\r\n\r\n                    # Gradient accumulation\r\n                    if batch_idx % self.accumulation_steps == 0:\r\n                        # Gradient clipping\r\n                        if self.gradient_clip_val > 0:\r\n                            if scaler:\r\n                                scaler.unscale_(self.optimizer)\r\n                            nn.utils.clip_grad_norm_(self.model.parameters(), self.gradient_clip_val)\r\n                        \r\n                        # Optimizer step\r\n                        if scaler:\r\n                            scaler.step(self.optimizer)\r\n                            scaler.update()\r\n                        else:\r\n                            self.optimizer.step()\r\n                        self.optimizer.zero_grad()\r\n\r\n                        # Scheduler step for OneCycleLR\r\n                        if self.scheduler and isinstance(self.scheduler, OneCycleLR):\r\n                            self.scheduler.step()\r\n\r\n                    # Accumulate loss\r\n                    epoch_loss += loss.item() * self.accumulation_steps\r\n                    num_batches += 1\r\n\r\n                    # Logging every 50 batches\r\n                    if batch_idx % 50 == 0:\r\n                        current_lr = self.optimizer.param_groups[0]['lr']\r\n                        logger.info(\r\n                            f\"Epoch [{epoch}/{self.max_epochs}] Batch [{batch_idx}/{len(self.train_loader)}] - \"\r\n                            f\"Loss: {loss.item() * self.accumulation_steps:.6f} - LR: {current_lr:.6f}\"\r\n                        )\r\n                        if torch.cuda.is_available():\r\n                            logger.debug(f\"GPU memory allocated: {torch.cuda.memory_allocated(self.device) / 1e9:.2f} GB\")\r\n\r\n                except RuntimeError as e:\r\n                    logger.error(f\"Runtime error in Epoch [{epoch}/{self.max_epochs}] Batch [{batch_idx}/{len(self.train_loader)}]: {str(e)}\")\r\n                    torch.cuda.empty_cache()\r\n                    continue  # Skip this batch\r\n\r\n            # Calculate average training loss for the epoch\r\n            avg_train_loss = epoch_loss / num_batches if num_batches > 0 else float('inf')\r\n            train_losses.append(avg_train_loss)\r\n\r\n            # Scheduler step for non-OneCycleLR schedulers\r\n            if self.scheduler and not isinstance(self.scheduler, OneCycleLR):\r\n                if isinstance(self.scheduler, ReduceLROnPlateau):\r\n                    self.scheduler.step(avg_train_loss)\r\n                else:\r\n                    self.scheduler.step()\r\n\r\n            # Validation phase\r\n            if val_loader:\r\n                val_loss = self._validate(val_loader)\r\n                val_losses.append(val_loss)\r\n\r\n                # Scheduler step for ReduceLROnPlateau\r\n                if self.scheduler and isinstance(self.scheduler, ReduceLROnPlateau):\r\n                    self.scheduler.step(val_loss)\r\n\r\n                # Early Stopping\r\n                if val_loss < best_val_loss - 1e-4:  # Adding a small delta to prevent frequent updates\r\n                    best_val_loss = val_loss\r\n                    patience_counter = 0\r\n                    # Save the best model\r\n                    self.save('best_model.pth')\r\n                    logger.info(f\"Epoch [{epoch}/{self.max_epochs}] - New best validation loss: {val_loss:.6f}. Model saved.\")\r\n                else:\r\n                    patience_counter += 1\r\n                    logger.info(f\"Epoch [{epoch}/{self.max_epochs}] - Validation loss: {val_loss:.6f}. Patience: {patience_counter}/{early_stopping_patience}\")\r\n\r\n                # Early stopping condition\r\n                if patience_counter >= early_stopping_patience:\r\n                    logger.warning(f\"Early stopping triggered after Epoch [{epoch}/{self.max_epochs}] with best Val Loss: {best_val_loss:.6f}\")\r\n                    # Load the best model\r\n                    self.load('best_model.pth')\r\n                    break\r\n\r\n                logger.info(f\"Epoch [{epoch}/{self.max_epochs}] - Train Loss: {avg_train_loss:.6f}, Val Loss: {val_loss:.6f}\")\r\n            else:\r\n                logger.info(f\"Epoch [{epoch}/{self.max_epochs}] - Train Loss: {avg_train_loss:.6f}\")\r\n\r\n            # Record current learning rate\r\n            current_lr = self.optimizer.param_groups[0]['lr']\r\n            learning_rates.append(current_lr)\r\n\r\n        # Compile training report\r\n        additional_metrics = {\r\n            'best_val_loss': best_val_loss if val_losses else None,\r\n            'final_train_loss': train_losses[-1] if train_losses else None,\r\n            'final_val_loss': val_losses[-1] if val_losses else None,\r\n            'final_learning_rate': learning_rates[-1] if learning_rates else None\r\n        }\r\n\r\n        return TrainingReport(\r\n            train_losses=train_losses,\r\n            val_losses=val_losses,\r\n            learning_rates=learning_rates,\r\n            epochs=epoch,\r\n            additional_metrics=additional_metrics\r\n        )\r\n\r\n    def _validate(self, val_loader: DataLoader) -> float:\r\n        \"\"\"Validate the model.\"\"\"\r\n        self.model.eval()\r\n        val_loss = 0.0\r\n        num_batches = 0\r\n\r\n        with torch.no_grad():\r\n            for data, target in val_loader:\r\n                try:\r\n                    # Move data to device\r\n                    if isinstance(data, tuple):\r\n                        data = tuple(d.to(self.device, non_blocking=True) for d in data)\r\n                    else:\r\n                        data = data.to(self.device, non_blocking=True)\r\n                    target = target.to(self.device, non_blocking=True)\r\n\r\n                    # Forward pass with autocast if using mixed precision\r\n                    if self.scaler:\r\n                        with autocast():\r\n                            outputs = self.model(data)\r\n                            loss = self.criterion(outputs, target)\r\n                    else:\r\n                        outputs = self.model(data)\r\n                        loss = self.criterion(outputs, target)\r\n\r\n                    val_loss += loss.item()\r\n                    num_batches += 1\r\n\r\n                except RuntimeError as e:\r\n                    logger.error(f\"Runtime error during validation: {str(e)}\")\r\n                    torch.cuda.empty_cache()\r\n                    continue  # Skip this batch\r\n\r\n        avg_val_loss = val_loss / num_batches if num_batches > 0 else float('inf')\r\n        return avg_val_loss\r\n\r\n    def predict(self, dataset: TorchDataset) -> Tuple[torch.Tensor, torch.Tensor]:\r\n        \"\"\"Make predictions using the model.\"\"\"\r\n        data_loader = DataLoader(\r\n            dataset, \r\n            batch_size=self.batch_size,\r\n            num_workers=min(8, (os.cpu_count() or 4) // 2),\r\n            pin_memory=torch.cuda.is_available(),\r\n            shuffle=False,\r\n            persistent_workers=True,\r\n            prefetch_factor=4\r\n        )\r\n\r\n        self.model.eval()\r\n        predictions: List[torch.Tensor] = []\r\n        targets: List[torch.Tensor] = []\r\n\r\n        with torch.no_grad():\r\n            for data, target in data_loader:\r\n                try:\r\n                    # Move data to device\r\n                    if isinstance(data, tuple):\r\n                        data = tuple(d.to(self.device, non_blocking=True) for d in data)\r\n                    else:\r\n                        data = data.to(self.device, non_blocking=True)\r\n                    target = target.to(self.device, non_blocking=True)\r\n\r\n                    # Forward pass with autocast if using mixed precision\r\n                    if self.scaler:\r\n                        with autocast():\r\n                            output = self.model(data)\r\n                    else:\r\n                        output = self.model(data)\r\n\r\n                    predictions.append(output.cpu())\r\n                    targets.append(target.cpu())\r\n\r\n                except RuntimeError as e:\r\n                    logger.error(f\"Runtime error during prediction: {str(e)}\")\r\n                    torch.cuda.empty_cache()\r\n                    continue  # Skip this batch\r\n\r\n        return torch.cat(predictions), torch.cat(targets)\r\n\r\n    def save(self, path: Union[str, Path]) -> None:\r\n        \"\"\"Save model state.\"\"\"\r\n        torch.save({\r\n            'model_state_dict': self.model.state_dict(),\r\n            'optimizer_state_dict': self.optimizer.state_dict(),\r\n            'scheduler_state_dict': self.scheduler.state_dict() if self.scheduler else None,\r\n            'scaler_state_dict': self.scaler.state_dict() if self.scaler else None,\r\n            'config': self.config\r\n        }, path)\r\n        logger.info(f\"Model saved to {path}\")\r\n\r\n    def load(self, path: Union[str, Path]) -> None:\r\n        \"\"\"Load model state.\"\"\"\r\n        checkpoint = torch.load(path, map_location=self.device)\r\n        self.model.load_state_dict(checkpoint['model_state_dict'])\r\n        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\r\n        if self.scheduler and checkpoint.get('scheduler_state_dict'):\r\n            self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\r\n        if self.scaler and checkpoint.get('scaler_state_dict'):\r\n            self.scaler.load_state_dict(checkpoint['scaler_state_dict'])\r\n        logger.info(f\"Model loaded from {path}\")\r\n\r\n    def training_step(\r\n        self,\r\n        batch_input: Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]],\r\n        batch_target: torch.Tensor,\r\n        **kwargs\r\n    ) -> float:\r\n        \"\"\"Process a single training batch with optimized GPU handling.\"\"\"\r\n        self.optimizer.zero_grad()\r\n        \r\n        try:\r\n            # Handle transformer models\r\n            if self.model_type.is_transformer and isinstance(batch_input, tuple):\r\n                src, tgt = batch_input\r\n                # Use masks from kwargs if provided, else generate\r\n                src_mask = kwargs.get('src_mask', self.model.generate_square_subsequent_mask(src.size(1)).to(self.device))\r\n                tgt_mask = kwargs.get('tgt_mask', self.model.generate_square_subsequent_mask(tgt.size(1)).to(self.device))\r\n                \r\n                output = self.model(src, tgt, src_mask=src_mask, tgt_mask=tgt_mask)\r\n            else:\r\n                if isinstance(batch_input, tuple):\r\n                    batch_input = batch_input[0]\r\n                output = self.model(batch_input)\r\n            \r\n            loss = self.criterion(output, batch_target)\r\n            loss.backward()\r\n            \r\n            # Gradient clipping\r\n            if self.gradient_clip_val > 0:\r\n                torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.gradient_clip_val)\r\n                \r\n            self.optimizer.step()\r\n            \r\n            return loss.item()\r\n                \r\n        except RuntimeError as e:\r\n            logger.error(f\"Training step failed: {str(e)}\")\r\n            logger.debug(\"Device mapping:\")\r\n            logger.debug(f\"Model: {next(self.model.parameters()).device}\")\r\n            if isinstance(batch_input, tuple):\r\n                logger.debug(f\"Input tensors: {[b.device for b in batch_input]}\")\r\n            else:\r\n                logger.debug(f\"Input tensor: {batch_input.device}\")\r\n            logger.debug(f\"Target tensor: {batch_target.device}\")\r\n            raise\r\n\r\n    def validation_step(\r\n        self,\r\n        batch_input: Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]],\r\n        batch_target: torch.Tensor,\r\n        **kwargs\r\n    ) -> float:\r\n        \"\"\"Process a single validation batch.\r\n        \r\n        Args:\r\n            batch_input: Input tensor or tuple of tensors\r\n            batch_target: Target tensor\r\n            **kwargs: Additional arguments like masks for transformers\r\n            \r\n        Returns:\r\n            float: Loss value for this batch\r\n        \"\"\"\r\n        try:\r\n            with torch.no_grad():\r\n                # Handle transformer models\r\n                if self.model_type.is_transformer and isinstance(batch_input, tuple):\r\n                    src, tgt = batch_input\r\n                    # Use masks from kwargs if provided, else generate\r\n                    src_mask = kwargs.get('src_mask', self.model.generate_square_subsequent_mask(src.size(1)).to(self.device))\r\n                    tgt_mask = kwargs.get('tgt_mask', self.model.generate_square_subsequent_mask(tgt.size(1)).to(self.device))\r\n                    \r\n                    output = self.model(src, tgt, src_mask=src_mask, tgt_mask=tgt_mask)\r\n                else:\r\n                    if isinstance(batch_input, tuple):\r\n                        batch_input = batch_input[0]\r\n                    output = self.model(batch_input)\r\n                \r\n                loss = self.criterion(output, batch_target)\r\n                return loss.item()\r\n                \r\n        except RuntimeError as e:\r\n            logger.error(f\"Validation step failed: {str(e)}\")\r\n            logger.debug(\"Device mapping:\")\r\n            logger.debug(f\"Model: {next(self.model.parameters()).device}\")\r\n            if isinstance(batch_input, tuple):\r\n                logger.debug(f\"Input tensors: {[b.device for b in batch_input]}\")\r\n            else:\r\n                logger.debug(f\"Input tensor: {batch_input.device}\")\r\n            logger.debug(f\"Target tensor: {batch_target.device}\")\r\n            raise\r\n"
        }
    ]
}