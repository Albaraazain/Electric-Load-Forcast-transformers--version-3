{
    "sourceFile": "models/wrappers/sklearn_wrapper.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 1,
            "patches": [
                {
                    "date": 1733181072687,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1733182196278,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -8,8 +8,9 @@\n \r\n from models.base.base_wrapper import BaseWrapper\r\n from models.registry.model_types import ModelType\r\n from training.reports.training_report import TrainingReport\r\n+from models.interfaces import WrapperInterface\r\n \r\n \r\n class SklearnEstimator(Protocol):\r\n     \"\"\"Protocol defining the required interface for sklearn estimators.\"\"\"\r\n@@ -17,14 +18,14 @@\n     def predict(self, X: np.ndarray) -> np.ndarray: ...\r\n     def partial_fit(self, X: np.ndarray, y: np.ndarray) -> \"SklearnEstimator\": ...\r\n \r\n \r\n-class SklearnWrapper(BaseWrapper):\r\n+class SklearnWrapper(BaseWrapper, WrapperInterface):\r\n     \"\"\"Wrapper for scikit-learn models providing consistent interface.\"\"\"\r\n \r\n     def __init__(\r\n             self,\r\n-            model: SklearnEstimator,  # Updated type hint using the Protocol\r\n+            model: SklearnEstimator,\r\n             model_type: ModelType,\r\n             config: Dict[str, Any]\r\n     ):\r\n         super().__init__(model_type, config)\r\n@@ -96,37 +97,81 @@\n             report.val_losses.append(val_mse)\r\n \r\n         return report\r\n \r\n-    def training_step(self, batch_input: torch.Tensor, batch_target: torch.Tensor) -> float:\r\n+    def training_step(\r\n+            self,\r\n+            batch_input: Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]],\r\n+            batch_target: torch.Tensor\r\n+    ) -> float:\r\n         \"\"\"Perform single training step and return loss.\"\"\"\r\n         # Convert to numpy for sklearn\r\n+        if isinstance(batch_input, tuple):\r\n+            # For compatibility, extract the first element\r\n+            batch_input = batch_input[0]\r\n         X = batch_input.numpy()\r\n         y = batch_target.numpy()\r\n         \r\n+        # Scale data if needed\r\n+        if self.scaler_x is not None:\r\n+            X = self.scaler_x.transform(X)\r\n+        if self.scaler_y is not None:\r\n+            y = self.scaler_y.transform(y.reshape(-1, 1)).ravel()\r\n+\r\n         # Fit the model on this batch\r\n-        self.model.partial_fit(X, y)\r\n+        if hasattr(self.model, 'partial_fit'):\r\n+            self.model.partial_fit(X, y)\r\n+        else:\r\n+            self.model.fit(X, y)\r\n+        self.is_fitted = True\r\n         \r\n         # Calculate loss\r\n         y_pred = self.model.predict(X)\r\n         loss = np.mean((y_pred - y) ** 2)  # MSE loss\r\n         return float(loss)\r\n \r\n+    def validation_step(\r\n+            self,\r\n+            batch_input: Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]],\r\n+            batch_target: torch.Tensor\r\n+    ) -> float:\r\n+        \"\"\"Perform single validation step and return loss.\"\"\"\r\n+        # Convert to numpy for sklearn\r\n+        if isinstance(batch_input, tuple):\r\n+            # For compatibility, extract the first element\r\n+            batch_input = batch_input[0]\r\n+        X = batch_input.numpy()\r\n+        y = batch_target.numpy()\r\n+        \r\n+        # Scale data if needed\r\n+        if self.scaler_x is not None:\r\n+            X = self.scaler_x.transform(X)\r\n+        if self.scaler_y is not None:\r\n+            y = self.scaler_y.transform(y.reshape(-1, 1)).ravel()\r\n+\r\n+        # Make predictions\r\n+        y_pred = self.model.predict(X)\r\n+        \r\n+        # Calculate loss\r\n+        loss = np.mean((y_pred - y) ** 2)  # MSE loss\r\n+        return float(loss)\r\n+\r\n     def predict(self, dataset: Dataset) -> Tuple[torch.Tensor, torch.Tensor]:\r\n         \"\"\"Make predictions using the scikit-learn model.\"\"\"\r\n         if not self.is_fitted:\r\n             raise RuntimeError(\"Model must be trained before making predictions\")\r\n \r\n         # Prepare data\r\n         X, y = self._prepare_data(dataset)\r\n-        X, _ = self._scale_data(X, y, fit=False)\r\n+        X, y = self._scale_data(X, y, fit=False)\r\n \r\n         # Make predictions\r\n         y_pred = self.model.predict(X)\r\n \r\n         # Inverse transform predictions if needed\r\n         if self.scaler_y is not None:\r\n             y_pred = self.scaler_y.inverse_transform(y_pred.reshape(-1, 1)).ravel()\r\n+            y = self.scaler_y.inverse_transform(y.reshape(-1, 1)).ravel()\r\n \r\n         return torch.tensor(y_pred), torch.tensor(y)\r\n \r\n     def save(self, path: str) -> None:\r\n@@ -149,5 +194,5 @@\n         self.model = load_dict['model']\r\n         self.scaler_x = load_dict['scaler_x']\r\n         self.scaler_y = load_dict['scaler_y']\r\n         self.is_fitted = load_dict['is_fitted']\r\n-        self.config.update(load_dict['config'])\n\\ No newline at end of file\n+        self.config.update(load_dict['config'])\r\n"
                }
            ],
            "date": 1733181072687,
            "name": "Commit-0",
            "content": "# models/wrappers/sklearn_wrapper.py\r\nfrom typing import Optional, Dict, Any, Tuple, Union, Protocol\r\nimport torch\r\nimport numpy as np\r\nfrom torch.utils.data import Dataset\r\nfrom sklearn.base import BaseEstimator, RegressorMixin\r\nfrom sklearn.preprocessing import StandardScaler\r\n\r\nfrom models.base.base_wrapper import BaseWrapper\r\nfrom models.registry.model_types import ModelType\r\nfrom training.reports.training_report import TrainingReport\r\n\r\n\r\nclass SklearnEstimator(Protocol):\r\n    \"\"\"Protocol defining the required interface for sklearn estimators.\"\"\"\r\n    def fit(self, X: np.ndarray, y: np.ndarray) -> \"SklearnEstimator\": ...\r\n    def predict(self, X: np.ndarray) -> np.ndarray: ...\r\n    def partial_fit(self, X: np.ndarray, y: np.ndarray) -> \"SklearnEstimator\": ...\r\n\r\n\r\nclass SklearnWrapper(BaseWrapper):\r\n    \"\"\"Wrapper for scikit-learn models providing consistent interface.\"\"\"\r\n\r\n    def __init__(\r\n            self,\r\n            model: SklearnEstimator,  # Updated type hint using the Protocol\r\n            model_type: ModelType,\r\n            config: Dict[str, Any]\r\n    ):\r\n        super().__init__(model_type, config)\r\n        self.model = model\r\n\r\n        # Optional preprocessing\r\n        self.scaler_x = StandardScaler() if config.get('scale_features', True) else None\r\n        self.scaler_y = StandardScaler() if config.get('scale_target', True) else None\r\n\r\n        # Track if the model has been fitted\r\n        self.is_fitted = False\r\n\r\n    def _prepare_data(\r\n            self,\r\n            dataset: Dataset\r\n    ) -> Tuple[np.ndarray, np.ndarray]:\r\n        \"\"\"Convert PyTorch dataset to numpy arrays.\"\"\"\r\n        X, y = [], []\r\n\r\n        for features, target in dataset:\r\n            X.append(features.numpy())\r\n            y.append(target.numpy())\r\n\r\n        return np.array(X), np.array(y)\r\n\r\n    def _scale_data(\r\n            self,\r\n            X: np.ndarray,\r\n            y: np.ndarray,\r\n            fit: bool = False\r\n    ) -> Tuple[np.ndarray, np.ndarray]:\r\n        \"\"\"Scale features and target if scalers are enabled.\"\"\"\r\n        if self.scaler_x is not None:\r\n            X = self.scaler_x.fit_transform(X) if fit else self.scaler_x.transform(X)\r\n\r\n        if self.scaler_y is not None:\r\n            y = self.scaler_y.fit_transform(y.reshape(-1, 1)) if fit else self.scaler_y.transform(y.reshape(-1, 1))\r\n            y = y.ravel()\r\n\r\n        return X, y\r\n\r\n    def train(\r\n            self,\r\n            train_dataset: Dataset,\r\n            validation_dataset: Optional[Dataset] = None\r\n    ) -> TrainingReport:\r\n        \"\"\"Train the scikit-learn model.\"\"\"\r\n        # Prepare data\r\n        X_train, y_train = self._prepare_data(train_dataset)\r\n\r\n        # Scale data if needed\r\n        X_train, y_train = self._scale_data(X_train, y_train, fit=True)\r\n\r\n        # Fit model\r\n        self.model.fit(X_train, y_train)\r\n        self.is_fitted = True\r\n\r\n        # Create training report with initial empty lists\r\n        report = TrainingReport(train_losses=[], val_losses=[])\r\n        \r\n        # Add the training score - convert numpy float to Python float\r\n        train_mse = float(np.mean((self.model.predict(X_train) - y_train) ** 2))\r\n        report.train_losses.append(train_mse)\r\n\r\n        if validation_dataset:\r\n            X_val, y_val = self._prepare_data(validation_dataset)\r\n            X_val, y_val = self._scale_data(X_val, y_val, fit=False)\r\n            val_mse = float(np.mean((self.model.predict(X_val) - y_val) ** 2))\r\n            report.val_losses.append(val_mse)\r\n\r\n        return report\r\n\r\n    def training_step(self, batch_input: torch.Tensor, batch_target: torch.Tensor) -> float:\r\n        \"\"\"Perform single training step and return loss.\"\"\"\r\n        # Convert to numpy for sklearn\r\n        X = batch_input.numpy()\r\n        y = batch_target.numpy()\r\n        \r\n        # Fit the model on this batch\r\n        self.model.partial_fit(X, y)\r\n        \r\n        # Calculate loss\r\n        y_pred = self.model.predict(X)\r\n        loss = np.mean((y_pred - y) ** 2)  # MSE loss\r\n        return float(loss)\r\n\r\n    def predict(self, dataset: Dataset) -> Tuple[torch.Tensor, torch.Tensor]:\r\n        \"\"\"Make predictions using the scikit-learn model.\"\"\"\r\n        if not self.is_fitted:\r\n            raise RuntimeError(\"Model must be trained before making predictions\")\r\n\r\n        # Prepare data\r\n        X, y = self._prepare_data(dataset)\r\n        X, _ = self._scale_data(X, y, fit=False)\r\n\r\n        # Make predictions\r\n        y_pred = self.model.predict(X)\r\n\r\n        # Inverse transform predictions if needed\r\n        if self.scaler_y is not None:\r\n            y_pred = self.scaler_y.inverse_transform(y_pred.reshape(-1, 1)).ravel()\r\n\r\n        return torch.tensor(y_pred), torch.tensor(y)\r\n\r\n    def save(self, path: str) -> None:\r\n        \"\"\"Save model state.\"\"\"\r\n        import joblib\r\n        save_dict = {\r\n            'model': self.model,\r\n            'scaler_x': self.scaler_x,\r\n            'scaler_y': self.scaler_y,\r\n            'is_fitted': self.is_fitted,\r\n            'config': self.config\r\n        }\r\n        joblib.dump(save_dict, path)\r\n\r\n    def load(self, path: str) -> None:\r\n        \"\"\"Load model state.\"\"\"\r\n        import joblib\r\n        load_dict = joblib.load(path)\r\n\r\n        self.model = load_dict['model']\r\n        self.scaler_x = load_dict['scaler_x']\r\n        self.scaler_y = load_dict['scaler_y']\r\n        self.is_fitted = load_dict['is_fitted']\r\n        self.config.update(load_dict['config'])"
        }
    ]
}