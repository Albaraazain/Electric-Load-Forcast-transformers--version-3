{
    "sourceFile": "pipeline/config/pipeline_config.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 10,
            "patches": [
                {
                    "date": 1733061971709,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1733067741402,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,8 +1,8 @@\n # pipeline/config/pipeline_config.py\r\n-from dataclasses import dataclass\r\n+from dataclasses import asdict, dataclass\r\n from pathlib import Path\r\n-from typing import Optional, Tuple\r\n+from typing import Any, Optional, Tuple\r\n from datetime import date\r\n from data_loading.base.base_dataset import DatasetConfig\r\n from models.config.model_config import ModelConfig\r\n from training.config import TrainingConfig\r\n@@ -35,5 +35,14 @@\n         date(2017, 3, 12)    # End date of your data\r\n     )\r\n \r\n     # Add data format configuration\r\n-    time_resolution_minutes: int = 15  # New field to specify data granularity\n\\ No newline at end of file\n+    time_resolution_minutes: int = 15  # New field to specify data granularity\r\n+    \r\n+    def get(self, key: str, default: Any = None) -> Any:\r\n+        \"\"\"Helper method to safely get configuration values.\"\"\"\r\n+        config_dict = asdict(self)\r\n+        # Check in all nested configs\r\n+        for config in [self.dataset_config, self.model_config, self.training_config]:\r\n+            if hasattr(config, key):\r\n+                return getattr(config, key)\r\n+        return config_dict.get(key, default)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1733177052586,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,17 +1,18 @@\n # pipeline/config/pipeline_config.py\r\n-from dataclasses import asdict, dataclass\r\n+from dataclasses import dataclass, field\r\n from pathlib import Path\r\n from typing import Any, Optional, Tuple\r\n-from datetime import date\r\n+from datetime import date, timedelta\r\n+\r\n from data_loading.base.base_dataset import DatasetConfig\r\n from models.config.model_config import ModelConfig\r\n-from training.config import TrainingConfig\r\n+from models.registry.model_types import ModelType\r\n+from training.config import TrainingConfig, TransformerTrainingConfig\r\n \r\n @dataclass\r\n class PipelineConfig:\r\n     \"\"\"Pipeline configuration combining dataset, model, and training settings.\"\"\"\r\n-\r\n     # Core configurations\r\n     dataset_config: DatasetConfig\r\n     model_config: ModelConfig\r\n     training_config: TrainingConfig\r\n@@ -21,27 +22,88 @@\n     model_save_path: Optional[Path] = None\r\n     experiment_save_path: Path = Path(\"experiments\")\r\n \r\n     # Data split dates\r\n-    train_dates: Tuple[date, date] = (\r\n-        date(2015, 10, 29),  # Start date of your data\r\n-        date(2016, 10, 28)   # ~70% of data\r\n-    )\r\n-    val_dates: Tuple[date, date] = (\r\n-        date(2016, 10, 29),  # ~15% of data\r\n+    train_dates: Tuple[date, date] = field(default_factory=lambda: (\r\n+        date(2015, 10, 29),\r\n+        date(2016, 10, 28)\r\n+    ))\r\n+    val_dates: Tuple[date, date] = field(default_factory=lambda: (\r\n+        date(2016, 10, 29),\r\n         date(2017, 1, 28)\r\n-    )\r\n-    test_dates: Tuple[date, date] = (\r\n-        date(2017, 1, 29),   # ~15% of data\r\n-        date(2017, 3, 12)    # End date of your data\r\n-    )\r\n+    ))\r\n+    test_dates: Tuple[date, date] = field(default_factory=lambda: (\r\n+        date(2017, 1, 29),\r\n+        date(2017, 3, 12)\r\n+    ))\r\n \r\n-    # Add data format configuration\r\n-    time_resolution_minutes: int = 15  # New field to specify data granularity\r\n-    \r\n+    # Resolution configuration\r\n+    input_resolution_minutes: int = field(default=15)\r\n+    forecast_resolution_minutes: int = field(default=15)\r\n+\r\n+    def __post_init__(self):\r\n+        \"\"\"Validate and adjust configuration based on resolutions.\"\"\"\r\n+        self._validate_resolutions()\r\n+        self._adjust_split_dates()\r\n+        self._synchronize_configs()\r\n+\r\n+    def _validate_resolutions(self) -> None:\r\n+        \"\"\"Validate resolution settings.\"\"\"\r\n+        if self.input_resolution_minutes <= 0:\r\n+            raise ValueError(\"Input resolution must be positive\")\r\n+        if self.forecast_resolution_minutes <= 0:\r\n+            raise ValueError(\"Forecast resolution must be positive\")\r\n+        if self.forecast_resolution_minutes < self.input_resolution_minutes:\r\n+            raise ValueError(\"Forecast resolution cannot be finer than input resolution\")\r\n+\r\n+    def _adjust_split_dates(self) -> None:\r\n+        \"\"\"Adjust split dates based on resolution.\"\"\"\r\n+        # For monthly predictions, ensure splits align with month boundaries\r\n+        if self.forecast_resolution_minutes >= 43200:  # Monthly\r\n+            self.train_dates = (\r\n+                self.train_dates[0].replace(day=1),\r\n+                self.train_dates[1].replace(day=1) + self._get_month_delta()\r\n+            )\r\n+            self.val_dates = (\r\n+                self.val_dates[0].replace(day=1),\r\n+                self.val_dates[1].replace(day=1) + self._get_month_delta()\r\n+            )\r\n+            self.test_dates = (\r\n+                self.test_dates[0].replace(day=1),\r\n+                self.test_dates[1].replace(day=1) + self._get_month_delta()\r\n+            )\r\n+\r\n+    def _synchronize_configs(self) -> None:\r\n+        \"\"\"Ensure resolution settings are synchronized across all configs.\"\"\"\r\n+        # Update dataset config\r\n+        if isinstance(self.dataset_config, DatasetConfig):\r\n+            self.dataset_config.input_resolution_minutes = self.input_resolution_minutes\r\n+            self.dataset_config.forecast_resolution_minutes = self.forecast_resolution_minutes\r\n+\r\n+        # Update model config\r\n+        if self.model_config.model_type.is_resolution_specific:\r\n+            self.model_config = self._get_resolution_specific_model_config()\r\n+\r\n+        # Update training config\r\n+        if isinstance(self.training_config, TransformerTrainingConfig):\r\n+            self.training_config.input_resolution_minutes = self.input_resolution_minutes\r\n+            self.training_config.forecast_resolution_minutes = self.forecast_resolution_minutes\r\n+\r\n+    def _get_month_delta(self) -> timedelta:\r\n+        \"\"\"Get a month delta for date calculations.\"\"\"\r\n+        return timedelta(days=30)  # Approximation\r\n+\r\n+    def _get_resolution_specific_model_config(self) -> ModelConfig:\r\n+        \"\"\"Get model configuration optimized for the current resolution.\"\"\"\r\n+        return ModelConfig.get_default_config(\r\n+            model_type=ModelType.get_for_resolution(self.forecast_resolution_minutes),\r\n+            input_resolution_minutes=self.input_resolution_minutes,\r\n+            forecast_resolution_minutes=self.forecast_resolution_minutes\r\n+        )\r\n+\r\n     def get(self, key: str, default: Any = None) -> Any:\r\n         \"\"\"Helper method to safely get configuration values.\"\"\"\r\n-        config_dict = asdict(self)\r\n+        config_dict = self.__dict__\r\n         # Check in all nested configs\r\n         for config in [self.dataset_config, self.model_config, self.training_config]:\r\n             if hasattr(config, key):\r\n                 return getattr(config, key)\r\n"
                },
                {
                    "date": 1733177367455,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -6,30 +6,30 @@\n \r\n from data_loading.base.base_dataset import DatasetConfig\r\n from models.config.model_config import ModelConfig\r\n from models.registry.model_types import ModelType\r\n-from training.config import TrainingConfig, TransformerTrainingConfig\r\n-\r\n-@dataclass\r\n-class PipelineConfig:\r\n-    \"\"\"Pipeline configuration combining dataset, model, and training settings.\"\"\"\r\n+from training.config import (\r\n+    TrainingConfig,\r\n+    TransformerTrainingConfig,\r\n+    ResolutionBasedTrainingConfig\r\n+)\r\n     # Core configurations\r\n     dataset_config: DatasetConfig\r\n     model_config: ModelConfig\r\n     training_config: TrainingConfig\r\n \r\n+    dataset_config: DatasetConfig\r\n+    model_config: ModelConfig\r\n+    training_config: TrainingConfig\r\n+\r\n     # Data paths and settings\r\n     data_path: Path\r\n     model_save_path: Optional[Path] = None\r\n     experiment_save_path: Path = Path(\"experiments\")\r\n \r\n     # Data split dates\r\n     train_dates: Tuple[date, date] = field(default_factory=lambda: (\r\n         date(2015, 10, 29),\r\n-        date(2016, 10, 28)\r\n-    ))\r\n-    val_dates: Tuple[date, date] = field(default_factory=lambda: (\r\n-        date(2016, 10, 29),\r\n         date(2017, 1, 28)\r\n     ))\r\n     test_dates: Tuple[date, date] = field(default_factory=lambda: (\r\n         date(2017, 1, 29),\r\n@@ -93,10 +93,11 @@\n         return timedelta(days=30)  # Approximation\r\n \r\n     def _get_resolution_specific_model_config(self) -> ModelConfig:\r\n         \"\"\"Get model configuration optimized for the current resolution.\"\"\"\r\n+        model_type = ModelType.get_for_resolution(self.forecast_resolution_minutes)\r\n         return ModelConfig.get_default_config(\r\n-            model_type=ModelType.get_for_resolution(self.forecast_resolution_minutes),\r\n+            model_type=model_type,  # Pass ModelType directly\r\n             input_resolution_minutes=self.input_resolution_minutes,\r\n             forecast_resolution_minutes=self.forecast_resolution_minutes\r\n         )\r\n \r\n@@ -106,5 +107,9 @@\n         # Check in all nested configs\r\n         for config in [self.dataset_config, self.model_config, self.training_config]:\r\n             if hasattr(config, key):\r\n                 return getattr(config, key)\r\n+        for config in [self.dataset_config, self.model_config, self.training_config]:\r\n+        return config_dict.get(key, default)\r\n+            if hasattr(config, key):\r\n+                return getattr(config, key)\r\n         return config_dict.get(key, default)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1733177657487,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,27 +1,26 @@\n-# pipeline/config/pipeline_config.py\r\n from dataclasses import dataclass, field\r\n from pathlib import Path\r\n from typing import Any, Optional, Tuple\r\n from datetime import date, timedelta\r\n \r\n from data_loading.base.base_dataset import DatasetConfig\r\n from models.config.model_config import ModelConfig\r\n from models.registry.model_types import ModelType\r\n-from training.config import (\r\n+from training.config.training_config import (  # Fix import path\r\n     TrainingConfig,\r\n     TransformerTrainingConfig,\r\n     ResolutionBasedTrainingConfig\r\n )\r\n+\r\n+@dataclass\r\n+class PipelineConfig:\r\n+    \"\"\"Pipeline configuration combining dataset, model, and training settings.\"\"\"\r\n     # Core configurations\r\n     dataset_config: DatasetConfig\r\n     model_config: ModelConfig\r\n     training_config: TrainingConfig\r\n \r\n-    dataset_config: DatasetConfig\r\n-    model_config: ModelConfig\r\n-    training_config: TrainingConfig\r\n-\r\n     # Data paths and settings\r\n     data_path: Path\r\n     model_save_path: Optional[Path] = None\r\n     experiment_save_path: Path = Path(\"experiments\")\r\n@@ -95,9 +94,9 @@\n     def _get_resolution_specific_model_config(self) -> ModelConfig:\r\n         \"\"\"Get model configuration optimized for the current resolution.\"\"\"\r\n         model_type = ModelType.get_for_resolution(self.forecast_resolution_minutes)\r\n         return ModelConfig.get_default_config(\r\n-            model_type=model_type,  # Pass ModelType directly\r\n+            model_type=str(model_type),  # Convert ModelType to string\r\n             input_resolution_minutes=self.input_resolution_minutes,\r\n             forecast_resolution_minutes=self.forecast_resolution_minutes\r\n         )\r\n \r\n@@ -107,9 +106,5 @@\n         # Check in all nested configs\r\n         for config in [self.dataset_config, self.model_config, self.training_config]:\r\n             if hasattr(config, key):\r\n                 return getattr(config, key)\r\n-        for config in [self.dataset_config, self.model_config, self.training_config]:\r\n-        return config_dict.get(key, default)\r\n-            if hasattr(config, key):\r\n-                return getattr(config, key)\r\n         return config_dict.get(key, default)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1733179309294,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -5,10 +5,10 @@\n \r\n from data_loading.base.base_dataset import DatasetConfig\r\n from models.config.model_config import ModelConfig\r\n from models.registry.model_types import ModelType\r\n-from training.config.training_config import (  # Fix import path\r\n-    TrainingConfig,\r\n+from training.config.training_config import (\r\n+    BaseConfig,\r\n     TransformerTrainingConfig,\r\n     ResolutionBasedTrainingConfig\r\n )\r\n \r\n@@ -17,9 +17,9 @@\n     \"\"\"Pipeline configuration combining dataset, model, and training settings.\"\"\"\r\n     # Core configurations\r\n     dataset_config: DatasetConfig\r\n     model_config: ModelConfig\r\n-    training_config: TrainingConfig\r\n+    training_config: BaseConfig  # Changed from TrainingConfig to BaseConfig\r\n \r\n     # Data paths and settings\r\n     data_path: Path\r\n     model_save_path: Optional[Path] = None\r\n"
                },
                {
                    "date": 1733180517819,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -94,9 +94,9 @@\n     def _get_resolution_specific_model_config(self) -> ModelConfig:\r\n         \"\"\"Get model configuration optimized for the current resolution.\"\"\"\r\n         model_type = ModelType.get_for_resolution(self.forecast_resolution_minutes)\r\n         return ModelConfig.get_default_config(\r\n-            model_type=str(model_type),  # Convert ModelType to string\r\n+            model_type=model_type,  # Pass ModelType enum directly, don't convert to string\r\n             input_resolution_minutes=self.input_resolution_minutes,\r\n             forecast_resolution_minutes=self.forecast_resolution_minutes\r\n         )\r\n \r\n"
                },
                {
                    "date": 1733180575643,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -24,11 +24,15 @@\n     data_path: Path\r\n     model_save_path: Optional[Path] = None\r\n     experiment_save_path: Path = Path(\"experiments\")\r\n \r\n-    # Data split dates\r\n+    # Data split dates - updated to include validation dates\r\n     train_dates: Tuple[date, date] = field(default_factory=lambda: (\r\n         date(2015, 10, 29),\r\n+        date(2016, 10, 28)  # Adjusted to leave room for validation\r\n+    ))\r\n+    val_dates: Tuple[date, date] = field(default_factory=lambda: (\r\n+        date(2016, 10, 29),\r\n         date(2017, 1, 28)\r\n     ))\r\n     test_dates: Tuple[date, date] = field(default_factory=lambda: (\r\n         date(2017, 1, 29),\r\n"
                },
                {
                    "date": 1733238489683,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -100,9 +100,9 @@\n         model_type = ModelType.get_for_resolution(self.forecast_resolution_minutes)\r\n         return ModelConfig.get_default_config(\r\n             model_type=model_type,  # Pass ModelType enum directly, don't convert to string\r\n             input_resolution_minutes=self.input_resolution_minutes,\r\n-            forecast_resolution_minutes=self.forecast_resolution_minutes\r\n+            forecast_resolution_minutes=self.forecast_resolution_minutes,\r\n         )\r\n \r\n     def get(self, key: str, default: Any = None) -> Any:\r\n         \"\"\"Helper method to safely get configuration values.\"\"\"\r\n"
                },
                {
                    "date": 1733238635804,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -41,8 +41,9 @@\n \r\n     # Resolution configuration\r\n     input_resolution_minutes: int = field(default=15)\r\n     forecast_resolution_minutes: int = field(default=15)\r\n+    \r\n \r\n     def __post_init__(self):\r\n         \"\"\"Validate and adjust configuration based on resolutions.\"\"\"\r\n         self._validate_resolutions()\r\n@@ -95,14 +96,19 @@\n         \"\"\"Get a month delta for date calculations.\"\"\"\r\n         return timedelta(days=30)  # Approximation\r\n \r\n     def _get_resolution_specific_model_config(self) -> ModelConfig:\r\n+        \r\n         \"\"\"Get model configuration optimized for the current resolution.\"\"\"\r\n         model_type = ModelType.get_for_resolution(self.forecast_resolution_minutes)\r\n+        \r\n+        current_features = self.model_config.input_features\r\n+\r\n         return ModelConfig.get_default_config(\r\n-            model_type=model_type,  # Pass ModelType enum directly, don't convert to string\r\n+            model_type=model_type,\r\n             input_resolution_minutes=self.input_resolution_minutes,\r\n             forecast_resolution_minutes=self.forecast_resolution_minutes,\r\n+            input_features=current_features  # Pass the current feature count\r\n         )\r\n \r\n     def get(self, key: str, default: Any = None) -> Any:\r\n         \"\"\"Helper method to safely get configuration values.\"\"\"\r\n"
                },
                {
                    "date": 1733238653327,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -77,16 +77,23 @@\n             )\r\n \r\n     def _synchronize_configs(self) -> None:\r\n         \"\"\"Ensure resolution settings are synchronized across all configs.\"\"\"\r\n+        # Store original feature dimensions\r\n+        original_features = self.model_config.input_features\r\n+        \r\n         # Update dataset config\r\n         if isinstance(self.dataset_config, DatasetConfig):\r\n             self.dataset_config.input_resolution_minutes = self.input_resolution_minutes\r\n             self.dataset_config.forecast_resolution_minutes = self.forecast_resolution_minutes\r\n \r\n-        # Update model config\r\n+        # Update model config with preserved features\r\n         if self.model_config.model_type.is_resolution_specific:\r\n             self.model_config = self._get_resolution_specific_model_config()\r\n+            # Ensure features are preserved\r\n+            self.model_config.input_features = original_features\r\n+            self.model_config.time_features = original_features - 1\r\n+            self.model_config.value_features = 1\r\n \r\n         # Update training config\r\n         if isinstance(self.training_config, TransformerTrainingConfig):\r\n             self.training_config.input_resolution_minutes = self.input_resolution_minutes\r\n"
                }
            ],
            "date": 1733061971709,
            "name": "Commit-0",
            "content": "# pipeline/config/pipeline_config.py\r\nfrom dataclasses import dataclass\r\nfrom pathlib import Path\r\nfrom typing import Optional, Tuple\r\nfrom datetime import date\r\nfrom data_loading.base.base_dataset import DatasetConfig\r\nfrom models.config.model_config import ModelConfig\r\nfrom training.config import TrainingConfig\r\n\r\n@dataclass\r\nclass PipelineConfig:\r\n    \"\"\"Pipeline configuration combining dataset, model, and training settings.\"\"\"\r\n\r\n    # Core configurations\r\n    dataset_config: DatasetConfig\r\n    model_config: ModelConfig\r\n    training_config: TrainingConfig\r\n\r\n    # Data paths and settings\r\n    data_path: Path\r\n    model_save_path: Optional[Path] = None\r\n    experiment_save_path: Path = Path(\"experiments\")\r\n\r\n    # Data split dates\r\n    train_dates: Tuple[date, date] = (\r\n        date(2015, 10, 29),  # Start date of your data\r\n        date(2016, 10, 28)   # ~70% of data\r\n    )\r\n    val_dates: Tuple[date, date] = (\r\n        date(2016, 10, 29),  # ~15% of data\r\n        date(2017, 1, 28)\r\n    )\r\n    test_dates: Tuple[date, date] = (\r\n        date(2017, 1, 29),   # ~15% of data\r\n        date(2017, 3, 12)    # End date of your data\r\n    )\r\n\r\n    # Add data format configuration\r\n    time_resolution_minutes: int = 15  # New field to specify data granularity"
        }
    ]
}