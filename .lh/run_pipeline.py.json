{
    "sourceFile": "run_pipeline.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 0,
            "patches": [
                {
                    "date": 1733004949775,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                }
            ],
            "date": 1733004949775,
            "name": "Commit-0",
            "content": "# # run_pipeline.py\r\n# from pathlib import Path\r\n# from sklearn.preprocessing import StandardScaler\r\n\r\n# from data_loading.base.base_dataset import DatasetConfig\r\n# from models.registry.model_types import ModelType\r\n# from pipeline.implementations.time_series_pipeline import TimeSeriesPipeline\r\n# from pipeline.utils.config_utils import create_pipeline_config\r\n# from training.config import TrainingConfig\r\n\r\n\r\n# def _run_pipeline_and_evaluate(pipeline):\r\n#     experiment = pipeline.run()\r\n#     print(\"Pipeline executed successfully!\")\r\n#     print(f\"Training time: {experiment.training_time:.2f} seconds\")\r\n#     print(f\"Test time: {experiment.test_time:.2f} seconds\")\r\n#     print(\"\\nModel Evaluation Metrics:\")\r\n#     print(experiment.evaluation.total_metrics)\r\n\r\n# def main():\r\n#     # 1. Define Dataset Configuration\r\n#     dataset_config = DatasetConfig(\r\n#         time_variable=\"utc_timestamp\",\r\n#         target_variable=\"DE_KN_residential1_grid_import\",\r\n#         time_series_window_in_hours=24,\r\n#         forecasting_horizon_in_hours=24,\r\n#         is_single_time_point_prediction=False,\r\n#         include_time_information=True,\r\n#         time_series_scaler=StandardScaler(),\r\n#         is_training_set=True,\r\n#         labels_count=1,\r\n#         one_hot_time_variables=False\r\n#     )\r\n\r\n#     # 2. Define Model Parameters\r\n#     model_params = {\r\n#         \"input_features\": 10,  # Adjust based on your feature count\r\n#         \"output_dim\": 1,\r\n#         \"hidden_dims\": [64, 32],\r\n#         \"d_model\": 512,\r\n#         \"n_heads\": 8,\r\n#         \"n_encoder_layers\": 3,\r\n#         \"n_decoder_layers\": 3,\r\n#         \"d_ff\": 2048,\r\n#         \"dropout\": 0.1\r\n#     }\r\n\r\n#     # 3. Define Training Parameters\r\n#     training_params = {\r\n#         \"learning_rate\": 0.001,\r\n#         \"max_epochs\": 100,\r\n#         \"batch_size\": 32,\r\n#         \"use_early_stopping\": True,\r\n#         \"early_stopping_patience\": 10,\r\n#         # \"transformer_labels_count\": 1,\r\n#         # \"transformer_use_teacher_forcing\": False,\r\n#         # \"transformer_use_auto_regression\": False,\r\n#         # \"learning_rate_scheduler_step\": 30,\r\n#         # \"learning_rate_scheduler_gamma\": 0.1,\r\n#         # \"attention_dropout\": 0.1\r\n#     }\r\n\r\n#     # 4. Create Pipeline Configuration\r\n#     config = create_pipeline_config(\r\n#         data_path=Path(\"data/household_15min.csv\"),\r\n#         model_type=ModelType.TIME_SERIES_TRANSFORMER,\r\n#         model_params=model_params,\r\n#         training_params=training_params,\r\n#         dataset_params=dataset_config.__dict__\r\n#     )\r\n\r\n#     # 5. Create and Run Pipeline\r\n#     pipeline = TimeSeriesPipeline(config)\r\n#     try:\r\n#         _run_pipeline_and_evaluate(pipeline)\r\n#     except Exception as e:\r\n#         print(f\"Pipeline execution failed: {str(e)}\")\r\n\r\n\r\n\r\n# if __name__ == \"__main__\":\r\n#     main()"
        }
    ]
}