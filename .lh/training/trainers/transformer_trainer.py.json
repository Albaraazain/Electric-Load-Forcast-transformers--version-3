{
    "sourceFile": "training/trainers/transformer_trainer.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 2,
            "patches": [
                {
                    "date": 1733003226930,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1733003423311,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -16,30 +16,16 @@\n \r\n class TransformerTrainer(BaseTrainer):\r\n     \"\"\"Trainer implementation for transformer models.\"\"\"\r\n \r\n-    def __init__(\r\n-            self,\r\n-            train_data_loader: DataLoader,\r\n-            validation_data_loader: DataLoader,\r\n-            model: nn.Module,\r\n-            loss_criterion,\r\n-            optimizer,\r\n-            epochs_count: int,\r\n-            learning_rate_scheduler: StepLR,\r\n-            args\r\n-    ):\r\n-        super().__init__(\r\n-            train_data_loader,\r\n-            validation_data_loader,\r\n-            model,\r\n-            loss_criterion,\r\n-            optimizer,\r\n-            epochs_count,\r\n-            learning_rate_scheduler,\r\n-            args\r\n+    def __init__(self, *args, **kwargs):\r\n+        super().__init__(*args, **kwargs)\r\n+        self.checkpoint_callback = ModelCheckpoint(\r\n+            filepath='checkpoints/transformer-{epoch:02d}-{val_loss:.2f}.pt',\r\n+            monitor='val_loss',\r\n+            save_best_only=True\r\n         )\r\n-        \r\n+        self.checkpoint_callback.on_training_begin(self.model, vars(self.args))\r\n \r\n     def execute_model_on_batch(\r\n             self,\r\n             encoder_input: torch.Tensor,\r\n@@ -183,5 +169,18 @@\n             predicted = torch.cat([new_predicted, known_decoder_input], dim=2).to(device)\r\n             start_decoder_input = torch.cat([start_decoder_input, predicted], dim=1).to(device)\r\n \r\n         predicted = start_decoder_input[:, self.args.transformer_labels_count + 1:, 0].to(device)\r\n-        return predicted, expected\n\\ No newline at end of file\n+        return predicted, expected\r\n+\r\n+    def train(self) -> TrainingReport:\r\n+        # ...existing code...\r\n+        for epoch in range(self.epochs_count):\r\n+            # ...existing training loop code...\r\n+            \r\n+            # Add checkpoint saving\r\n+            self.checkpoint_callback.on_epoch_end(epoch, {\r\n+                'val_loss': validation_loss,\r\n+                'train_loss': training_loss\r\n+            })\r\n+            \r\n+        # ...rest of existing code...\n\\ No newline at end of file\n"
                },
                {
                    "date": 1733003523951,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,229 @@\n+# training/trainers/transformer_trainer.py\r\n+import torch\r\n+from torch import nn\r\n+from torch.optim.lr_scheduler import StepLR\r\n+from torch.utils.data import DataLoader\r\n+from typing import Tuple\r\n+\r\n+from training.callbacks.model_checkpoint import ModelCheckpoint\r\n+from training.reports.training_report import TrainingReport\r\n+\r\n+from ..base.base_trainer import BaseTrainer\r\n+\r\n+def create_mask(size: int) -> torch.Tensor:\r\n+    # sourcery skip: remove-unnecessary-cast\r\n+    \"\"\"Create attention mask for transformer.\"\"\"\r\n+    mask = (torch.triu(torch.ones(size, size)) == 1).transpose(0, 1)\r\n+    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\r\n+    return mask\r\n+\r\n+class TransformerTrainer(BaseTrainer):\r\n+    \"\"\"Trainer implementation for transformer models.\"\"\"\r\n+\r\n+    def __init__(self, *args, **kwargs):\r\n+        super().__init__(*args, **kwargs)\r\n+        self.checkpoint_callback = ModelCheckpoint(\r\n+            filepath='checkpoints/transformer-{epoch:02d}-{val_loss:.2f}.pt',\r\n+            monitor='val_loss',\r\n+            save_best_only=True\r\n+        )\r\n+        self.checkpoint_callback.on_training_begin(self.model, vars(self.args))\r\n+\r\n+    def execute_model_on_batch(\r\n+            self,\r\n+            encoder_input: torch.Tensor,\r\n+            decoder_input: torch.Tensor,\r\n+            device: str\r\n+    ) -> Tuple[torch.Tensor, torch.Tensor]:\r\n+        \"\"\"Execute model using generative approach.\"\"\"\r\n+        batch_size = encoder_input.shape[0]\r\n+        decoder_sequence_length = self.args.transformer_labels_count + self.args.forecasting_horizon\r\n+\r\n+        # Prepare decoder input\r\n+        expected = decoder_input[:, :decoder_sequence_length, 0]\r\n+        u = decoder_input[:, :decoder_sequence_length, 1:]\r\n+        o1 = decoder_input[:, :self.args.transformer_labels_count, 0:1]\r\n+        o2 = torch.zeros([batch_size, self.args.forecasting_horizon, 1]).to(device)\r\n+        adjusted_decoder_input = torch.cat([torch.cat([o1, o2], dim=1), u], dim=2).to(device)\r\n+\r\n+        # Create mask and forward pass\r\n+        target_mask = create_mask(decoder_sequence_length).to(device)\r\n+        predicted = self.model(encoder_input, adjusted_decoder_input, tgt_mask=target_mask)\r\n+        predicted = torch.reshape(predicted, torch.Size([batch_size, decoder_sequence_length]))\r\n+\r\n+        return predicted, expected\r\n+\r\n+    def execute_model_one_step_ahead(\r\n+            self,\r\n+            encoder_input: torch.Tensor,\r\n+            decoder_input: torch.Tensor,\r\n+            device: str\r\n+    ) -> Tuple[torch.Tensor, torch.Tensor]:\r\n+        \"\"\"Execute model using one-step-ahead approach.\"\"\"\r\n+        batch_size = encoder_input.shape[0]\r\n+        expected = decoder_input[:, 1:self.args.transformer_labels_count + 1, 0]\r\n+\r\n+        # Prepare decoder input\r\n+        u = decoder_input[:, 1:-self.args.forecasting_horizon + 1, 1:]\r\n+        o1 = decoder_input[:, :self.args.transformer_labels_count, 0:1]\r\n+        adjusted_decoder_input = torch.cat([o1, u], dim=2).to(device)\r\n+\r\n+        # Create mask and forward pass\r\n+        target_mask = create_mask(self.args.transformer_labels_count).to(device)\r\n+        predicted = self.model(encoder_input, adjusted_decoder_input, tgt_mask=target_mask)\r\n+        predicted = torch.reshape(predicted, torch.Size([batch_size, self.args.transformer_labels_count]))\r\n+\r\n+        return predicted, expected\r\n+\r\n+    def train_phase(self, device: str) -> float:\r\n+        self.model.train()\r\n+        total_training_loss = 0.0\r\n+\r\n+        for encoder_input, decoder_input in self.train_data_loader:\r\n+            encoder_input = encoder_input.to(device)\r\n+            decoder_input = decoder_input.to(device)\r\n+\r\n+            self.optimizer.zero_grad()\r\n+\r\n+            if self.args.transformer_use_teacher_forcing:\r\n+                expected = decoder_input[:, self.args.transformer_labels_count:, 0].detach().clone()\r\n+                decoder_input[:, 1:, 0:1] = decoder_input[:, :-1, 0:1]\r\n+\r\n+                target_mask = create_mask(decoder_input.shape[1]).to(device)\r\n+                predicted = self.model(encoder_input, decoder_input, tgt_mask=target_mask)\r\n+                predicted = torch.reshape(\r\n+                    predicted,\r\n+                    torch.Size([encoder_input.shape[0], self.args.transformer_labels_count + self.args.forecasting_horizon])\r\n+                )\r\n+                predicted = predicted[:, self.args.transformer_labels_count:]\r\n+\r\n+            elif self.args.transformer_use_auto_regression:\r\n+                predicted, expected = self.execute_model_one_step_ahead(encoder_input, decoder_input, device)\r\n+                predicted = predicted[:, self.args.transformer_labels_count - 1:]\r\n+                expected = expected[:, self.args.transformer_labels_count - 1:]\r\n+\r\n+            else:  # generative approach\r\n+                predicted, expected = self.execute_model_on_batch(encoder_input, decoder_input, device)\r\n+\r\n+            training_loss = self.loss_criterion(predicted, expected)\r\n+            training_loss.backward()\r\n+            self.optimizer.step()\r\n+            total_training_loss += training_loss.item()\r\n+\r\n+        return total_training_loss / len(self.train_data_loader)\r\n+\r\n+    def validation_phase(self, device: str) -> float:\r\n+        self.model.eval()\r\n+        total_validation_loss = 0.0\r\n+\r\n+        with torch.no_grad():\r\n+            for encoder_input, decoder_input in self.validation_data_loader:\r\n+                encoder_input = encoder_input.to(device)\r\n+                decoder_input = decoder_input.to(device)\r\n+\r\n+                if self.args.transformer_use_teacher_forcing:\r\n+                    predicted, expected = self._teacher_forcing_validation(encoder_input, decoder_input, device)\r\n+                elif self.args.transformer_use_auto_regression:\r\n+                    predicted, expected = self.execute_model_one_step_ahead(encoder_input, decoder_input, device)\r\n+                    predicted = predicted[:, self.args.transformer_labels_count - 1:]\r\n+                    expected = expected[:, self.args.transformer_labels_count - 1:]\r\n+                else:  # generative approach\r\n+                    predicted, expected = self.execute_model_on_batch(encoder_input, decoder_input, device)\r\n+                    predicted = predicted[:, self.args.transformer_labels_count:]\r\n+                    expected = expected[:, self.args.transformer_labels_count:]\r\n+\r\n+                validation_loss = self.loss_criterion(predicted, expected)\r\n+                total_validation_loss += validation_loss.item()\r\n+\r\n+        return total_validation_loss / len(self.validation_data_loader)\r\n+\r\n+    def _teacher_forcing_validation(\r\n+            self,\r\n+            encoder_input: torch.Tensor,\r\n+            decoder_input: torch.Tensor,\r\n+            device: str\r\n+    ) -> Tuple[torch.Tensor, torch.Tensor]:\r\n+        \"\"\"Validation step for teacher forcing approach.\"\"\"\r\n+        expected = decoder_input[:, self.args.transformer_labels_count:, 0].detach().clone().to(device)\r\n+        decoder_input[:, 1:, 0] = decoder_input[:, :-1, 0]\r\n+\r\n+        start_decoder_input = decoder_input[:, :self.args.transformer_labels_count + 1, :].to(device)\r\n+\r\n+        for i in range(1, 1 + self.args.forecasting_horizon):\r\n+            target_mask = create_mask(start_decoder_input.shape[1]).to(device)\r\n+            predicted = self.model(encoder_input, start_decoder_input, tgt_mask=target_mask).to(device)\r\n+\r\n+            if i == self.args.forecasting_horizon:\r\n+                known_decoder_input = torch.zeros(\r\n+                    start_decoder_input.shape[0], 1, start_decoder_input.shape[2] - 1\r\n+                ).to(device)\r\n+            else:\r\n+                known_decoder_input = decoder_input[\r\n+                                    :,\r\n+                                    self.args.transformer_labels_count + i:self.args.transformer_labels_count + i + 1,\r\n+                                    1:\r\n+                                    ].to(device)\r\n+            new_predicted = predicted[\r\n+                            :,\r\n+                            self.args.transformer_labels_count + i - 1:self.args.transformer_labels_count + i,\r\n+                            0:1\r\n+                            ].to(device)\r\n+\r\n+            predicted = torch.cat([new_predicted, known_decoder_input], dim=2).to(device)\r\n+            start_decoder_input = torch.cat([start_decoder_input, predicted], dim=1).to(device)\r\n+\r\n+        predicted = start_decoder_input[:, self.args.transformer_labels_count + 1:, 0].to(device)\r\n+        return predicted, expected\r\n+\r\n+    def train(self) -> TrainingReport:\r\n+        device = 'cuda' if torch.cuda.is_available() else 'cpu'\r\n+        print('Used device: ', device)\r\n+        self.model = self.model.to(device)\r\n+\r\n+        train_losses = []\r\n+        val_losses = []\r\n+        learning_rates = []\r\n+        epochs_without_validation_loss_decrease = 0\r\n+        minimum_average_validation_loss = float('inf')\r\n+\r\n+        for epoch in range(self.epochs_count):\r\n+            # Training phase\r\n+            training_loss = self.train_phase(device)\r\n+            train_losses.append(training_loss)\r\n+\r\n+            # Validation phase\r\n+            validation_loss = self.validation_phase(device)\r\n+            val_losses.append(validation_loss)\r\n+            learning_rates.append(self.optimizer.param_groups[0]['lr'])\r\n+\r\n+            # Save checkpoint\r\n+            self.checkpoint_callback.on_epoch_end(epoch, {\r\n+                'val_loss': validation_loss,\r\n+                'train_loss': training_loss\r\n+            })\r\n+\r\n+            if self.args.use_early_stopping:\r\n+                if minimum_average_validation_loss <= validation_loss:\r\n+                    epochs_without_validation_loss_decrease += 1\r\n+                else:\r\n+                    epochs_without_validation_loss_decrease = 0\r\n+                    minimum_average_validation_loss = validation_loss\r\n+                    self.best_model_state = self.model.state_dict().copy()\r\n+\r\n+                if epochs_without_validation_loss_decrease > self.args.early_stopping_patience:\r\n+                    print('Early stopping has happened at epoch', epoch)\r\n+                    break\r\n+\r\n+            print(f'Epoch {epoch}: training_loss={training_loss:.4f}, validation_loss={validation_loss:.4f}')\r\n+\r\n+        # Load best model and move to CPU\r\n+        self.model.load_state_dict(self.best_model_state)\r\n+        self.model = self.model.to('cpu')\r\n+\r\n+        return TrainingReport(\r\n+            train_losses=train_losses,\r\n+            val_losses=val_losses,\r\n+            learning_rates=learning_rates,\r\n+            epochs=self.epochs_count,\r\n+            early_stopping_epoch=epoch if epochs_without_validation_loss_decrease > self.args.early_stopping_patience else None\r\n+        )\n\\ No newline at end of file\n"
                }
            ],
            "date": 1733003226930,
            "name": "Commit-0",
            "content": "# training/trainers/transformer_trainer.py\r\nimport torch\r\nfrom torch import nn\r\nfrom torch.optim.lr_scheduler import StepLR\r\nfrom torch.utils.data import DataLoader\r\nfrom typing import Tuple\r\n\r\nfrom ..base.base_trainer import BaseTrainer\r\n\r\ndef create_mask(size: int) -> torch.Tensor:\r\n    # sourcery skip: remove-unnecessary-cast\r\n    \"\"\"Create attention mask for transformer.\"\"\"\r\n    mask = (torch.triu(torch.ones(size, size)) == 1).transpose(0, 1)\r\n    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\r\n    return mask\r\n\r\nclass TransformerTrainer(BaseTrainer):\r\n    \"\"\"Trainer implementation for transformer models.\"\"\"\r\n\r\n    def __init__(\r\n            self,\r\n            train_data_loader: DataLoader,\r\n            validation_data_loader: DataLoader,\r\n            model: nn.Module,\r\n            loss_criterion,\r\n            optimizer,\r\n            epochs_count: int,\r\n            learning_rate_scheduler: StepLR,\r\n            args\r\n    ):\r\n        super().__init__(\r\n            train_data_loader,\r\n            validation_data_loader,\r\n            model,\r\n            loss_criterion,\r\n            optimizer,\r\n            epochs_count,\r\n            learning_rate_scheduler,\r\n            args\r\n        )\r\n        \r\n\r\n    def execute_model_on_batch(\r\n            self,\r\n            encoder_input: torch.Tensor,\r\n            decoder_input: torch.Tensor,\r\n            device: str\r\n    ) -> Tuple[torch.Tensor, torch.Tensor]:\r\n        \"\"\"Execute model using generative approach.\"\"\"\r\n        batch_size = encoder_input.shape[0]\r\n        decoder_sequence_length = self.args.transformer_labels_count + self.args.forecasting_horizon\r\n\r\n        # Prepare decoder input\r\n        expected = decoder_input[:, :decoder_sequence_length, 0]\r\n        u = decoder_input[:, :decoder_sequence_length, 1:]\r\n        o1 = decoder_input[:, :self.args.transformer_labels_count, 0:1]\r\n        o2 = torch.zeros([batch_size, self.args.forecasting_horizon, 1]).to(device)\r\n        adjusted_decoder_input = torch.cat([torch.cat([o1, o2], dim=1), u], dim=2).to(device)\r\n\r\n        # Create mask and forward pass\r\n        target_mask = create_mask(decoder_sequence_length).to(device)\r\n        predicted = self.model(encoder_input, adjusted_decoder_input, tgt_mask=target_mask)\r\n        predicted = torch.reshape(predicted, torch.Size([batch_size, decoder_sequence_length]))\r\n\r\n        return predicted, expected\r\n\r\n    def execute_model_one_step_ahead(\r\n            self,\r\n            encoder_input: torch.Tensor,\r\n            decoder_input: torch.Tensor,\r\n            device: str\r\n    ) -> Tuple[torch.Tensor, torch.Tensor]:\r\n        \"\"\"Execute model using one-step-ahead approach.\"\"\"\r\n        batch_size = encoder_input.shape[0]\r\n        expected = decoder_input[:, 1:self.args.transformer_labels_count + 1, 0]\r\n\r\n        # Prepare decoder input\r\n        u = decoder_input[:, 1:-self.args.forecasting_horizon + 1, 1:]\r\n        o1 = decoder_input[:, :self.args.transformer_labels_count, 0:1]\r\n        adjusted_decoder_input = torch.cat([o1, u], dim=2).to(device)\r\n\r\n        # Create mask and forward pass\r\n        target_mask = create_mask(self.args.transformer_labels_count).to(device)\r\n        predicted = self.model(encoder_input, adjusted_decoder_input, tgt_mask=target_mask)\r\n        predicted = torch.reshape(predicted, torch.Size([batch_size, self.args.transformer_labels_count]))\r\n\r\n        return predicted, expected\r\n\r\n    def train_phase(self, device: str) -> float:\r\n        self.model.train()\r\n        total_training_loss = 0.0\r\n\r\n        for encoder_input, decoder_input in self.train_data_loader:\r\n            encoder_input = encoder_input.to(device)\r\n            decoder_input = decoder_input.to(device)\r\n\r\n            self.optimizer.zero_grad()\r\n\r\n            if self.args.transformer_use_teacher_forcing:\r\n                expected = decoder_input[:, self.args.transformer_labels_count:, 0].detach().clone()\r\n                decoder_input[:, 1:, 0:1] = decoder_input[:, :-1, 0:1]\r\n\r\n                target_mask = create_mask(decoder_input.shape[1]).to(device)\r\n                predicted = self.model(encoder_input, decoder_input, tgt_mask=target_mask)\r\n                predicted = torch.reshape(\r\n                    predicted,\r\n                    torch.Size([encoder_input.shape[0], self.args.transformer_labels_count + self.args.forecasting_horizon])\r\n                )\r\n                predicted = predicted[:, self.args.transformer_labels_count:]\r\n\r\n            elif self.args.transformer_use_auto_regression:\r\n                predicted, expected = self.execute_model_one_step_ahead(encoder_input, decoder_input, device)\r\n                predicted = predicted[:, self.args.transformer_labels_count - 1:]\r\n                expected = expected[:, self.args.transformer_labels_count - 1:]\r\n\r\n            else:  # generative approach\r\n                predicted, expected = self.execute_model_on_batch(encoder_input, decoder_input, device)\r\n\r\n            training_loss = self.loss_criterion(predicted, expected)\r\n            training_loss.backward()\r\n            self.optimizer.step()\r\n            total_training_loss += training_loss.item()\r\n\r\n        return total_training_loss / len(self.train_data_loader)\r\n\r\n    def validation_phase(self, device: str) -> float:\r\n        self.model.eval()\r\n        total_validation_loss = 0.0\r\n\r\n        with torch.no_grad():\r\n            for encoder_input, decoder_input in self.validation_data_loader:\r\n                encoder_input = encoder_input.to(device)\r\n                decoder_input = decoder_input.to(device)\r\n\r\n                if self.args.transformer_use_teacher_forcing:\r\n                    predicted, expected = self._teacher_forcing_validation(encoder_input, decoder_input, device)\r\n                elif self.args.transformer_use_auto_regression:\r\n                    predicted, expected = self.execute_model_one_step_ahead(encoder_input, decoder_input, device)\r\n                    predicted = predicted[:, self.args.transformer_labels_count - 1:]\r\n                    expected = expected[:, self.args.transformer_labels_count - 1:]\r\n                else:  # generative approach\r\n                    predicted, expected = self.execute_model_on_batch(encoder_input, decoder_input, device)\r\n                    predicted = predicted[:, self.args.transformer_labels_count:]\r\n                    expected = expected[:, self.args.transformer_labels_count:]\r\n\r\n                validation_loss = self.loss_criterion(predicted, expected)\r\n                total_validation_loss += validation_loss.item()\r\n\r\n        return total_validation_loss / len(self.validation_data_loader)\r\n\r\n    def _teacher_forcing_validation(\r\n            self,\r\n            encoder_input: torch.Tensor,\r\n            decoder_input: torch.Tensor,\r\n            device: str\r\n    ) -> Tuple[torch.Tensor, torch.Tensor]:\r\n        \"\"\"Validation step for teacher forcing approach.\"\"\"\r\n        expected = decoder_input[:, self.args.transformer_labels_count:, 0].detach().clone().to(device)\r\n        decoder_input[:, 1:, 0] = decoder_input[:, :-1, 0]\r\n\r\n        start_decoder_input = decoder_input[:, :self.args.transformer_labels_count + 1, :].to(device)\r\n\r\n        for i in range(1, 1 + self.args.forecasting_horizon):\r\n            target_mask = create_mask(start_decoder_input.shape[1]).to(device)\r\n            predicted = self.model(encoder_input, start_decoder_input, tgt_mask=target_mask).to(device)\r\n\r\n            if i == self.args.forecasting_horizon:\r\n                known_decoder_input = torch.zeros(\r\n                    start_decoder_input.shape[0], 1, start_decoder_input.shape[2] - 1\r\n                ).to(device)\r\n            else:\r\n                known_decoder_input = decoder_input[\r\n                                    :,\r\n                                    self.args.transformer_labels_count + i:self.args.transformer_labels_count + i + 1,\r\n                                    1:\r\n                                    ].to(device)\r\n            new_predicted = predicted[\r\n                            :,\r\n                            self.args.transformer_labels_count + i - 1:self.args.transformer_labels_count + i,\r\n                            0:1\r\n                            ].to(device)\r\n\r\n            predicted = torch.cat([new_predicted, known_decoder_input], dim=2).to(device)\r\n            start_decoder_input = torch.cat([start_decoder_input, predicted], dim=1).to(device)\r\n\r\n        predicted = start_decoder_input[:, self.args.transformer_labels_count + 1:, 0].to(device)\r\n        return predicted, expected"
        }
    ]
}